21:18:21,71 <kafka.producer.kafka>[DEBUG]: Starting the Kafka producer
21:18:21,72 <kafka.metrics.metrics>[DEBUG]: Added sensor with name connections-closed
21:18:21,72 <kafka.metrics.metrics>[DEBUG]: Added sensor with name connections-created
21:18:21,72 <kafka.metrics.metrics>[DEBUG]: Added sensor with name select-time
21:18:21,72 <kafka.metrics.metrics>[DEBUG]: Added sensor with name io-time
21:18:21,72 <kafka.client>[DEBUG]: Initiating connection to node bootstrap-0 at localhost:19092
21:18:21,72 <kafka.metrics.metrics>[DEBUG]: Added sensor with name bytes-sent-received
21:18:21,72 <kafka.metrics.metrics>[DEBUG]: Added sensor with name bytes-sent
21:18:21,73 <kafka.metrics.metrics>[DEBUG]: Added sensor with name bytes-received
21:18:21,73 <kafka.metrics.metrics>[DEBUG]: Added sensor with name request-latency
21:18:21,73 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-bootstrap-0.bytes-sent
21:18:21,73 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-bootstrap-0.bytes-received
21:18:21,73 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-bootstrap-0.latency
21:18:21,76 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <disconnected> [unspecified None]>: creating new socket
21:18:21,77 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <disconnected> [IPv6 ('::1', 19092, 0, 0)]>: setting socket option (6, 1, 1)
21:18:21,77 <kafka.conn>[INFO]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connecting> [IPv6 ('::1', 19092, 0, 0)]>: connecting to localhost:19092 [('::1', 19092, 0, 0) IPv6]
21:18:21,77 <kafka.conn>[INFO]: Probing node bootstrap-0 broker version
21:18:21,78 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connecting> [IPv6 ('::1', 19092, 0, 0)]>: established TCP connection
21:18:21,78 <kafka.conn>[INFO]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connecting> [IPv6 ('::1', 19092, 0, 0)]>: Connection complete.
21:18:21,78 <kafka.client>[DEBUG]: Node bootstrap-0 connected
21:18:21,78 <kafka.protocol.parser>[DEBUG]: Sending request ApiVersionRequest_v0()
21:18:21,79 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Request 1: ApiVersionRequest_v0()
21:18:21,188 <kafka.protocol.parser>[DEBUG]: Sending request MetadataRequest_v0(topics=[])
21:18:21,188 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Request 2: MetadataRequest_v0(topics=[])
21:18:21,188 <kafka.protocol.parser>[DEBUG]: Received correlation id: 1
21:18:21,188 <kafka.protocol.parser>[DEBUG]: Processing response ApiVersionResponse_v0
21:18:21,189 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Response 1 (110.58473587036133 ms): ApiVersionResponse_v0(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=11), (api_key=1, min_version=0, max_version=16), (api_key=2, min_version=0, max_version=8), (api_key=3, min_version=0, max_version=12), (api_key=4, min_version=0, max_version=7), (api_key=5, min_version=0, max_version=4), (api_key=6, min_version=0, max_version=8), (api_key=7, min_version=0, max_version=3), (api_key=8, min_version=0, max_version=9), (api_key=9, min_version=0, max_version=9), (api_key=10, min_version=0, max_version=5), (api_key=11, min_version=0, max_version=9), (api_key=12, min_version=0, max_version=4), (api_key=13, min_version=0, max_version=5), (api_key=14, min_version=0, max_version=5), (api_key=15, min_version=0, max_version=5), (api_key=16, min_version=0, max_version=5), (api_key=17, min_version=0, max_version=1), (api_key=18, min_version=0, max_version=3), (api_key=19, min_version=0, max_version=7), (api_key=20, min_version=0, max_version=6), (api_key=21, min_version=0, max_version=2), (api_key=22, min_version=0, max_version=5), (api_key=23, min_version=0, max_version=4), (api_key=24, min_version=0, max_version=5), (api_key=25, min_version=0, max_version=4), (api_key=26, min_version=0, max_version=4), (api_key=27, min_version=0, max_version=1), (api_key=28, min_version=0, max_version=4), (api_key=29, min_version=0, max_version=3), (api_key=30, min_version=0, max_version=3), (api_key=31, min_version=0, max_version=3), (api_key=32, min_version=0, max_version=4), (api_key=33, min_version=0, max_version=2), (api_key=34, min_version=0, max_version=2), (api_key=35, min_version=0, max_version=4), (api_key=36, min_version=0, max_version=2), (api_key=37, min_version=0, max_version=3), (api_key=38, min_version=0, max_version=3), (api_key=39, min_version=0, max_version=2), (api_key=40, min_version=0, max_version=2), (api_key=41, min_version=0, max_version=3), (api_key=42, min_version=0, max_version=2), (api_key=43, min_version=0, max_version=2), (api_key=44, min_version=0, max_version=1), (api_key=45, min_version=0, max_version=0), (api_key=46, min_version=0, max_version=0), (api_key=47, min_version=0, max_version=0), (api_key=48, min_version=0, max_version=1), (api_key=49, min_version=0, max_version=1), (api_key=50, min_version=0, max_version=0), (api_key=51, min_version=0, max_version=0), (api_key=56, min_version=0, max_version=3), (api_key=57, min_version=0, max_version=1), (api_key=58, min_version=0, max_version=0), (api_key=60, min_version=0, max_version=1), (api_key=61, min_version=0, max_version=0), (api_key=65, min_version=0, max_version=0), (api_key=66, min_version=0, max_version=1), (api_key=67, min_version=0, max_version=0), (api_key=68, min_version=0, max_version=0), (api_key=69, min_version=0, max_version=0)])
21:18:21,191 <kafka.protocol.parser>[DEBUG]: Received correlation id: 2
21:18:21,191 <kafka.protocol.parser>[DEBUG]: Processing response MetadataResponse_v0
21:18:21,192 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Response 2 (3.993988037109375 ms): MetadataResponse_v0(brokers=[(node_id=2, host='localhost', port=29092), (node_id=3, host='localhost', port=39092), (node_id=1, host='localhost', port=19092)], topics=[(error_code=0, topic='stockData', partitions=[(error_code=0, partition=0, leader=3, replicas=[3], isr=[3])]), (error_code=0, topic='realtimeStockData', partitions=[(error_code=0, partition=0, leader=2, replicas=[2], isr=[2])]), (error_code=0, topic='__consumer_offsets', partitions=[(error_code=0, partition=0, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=10, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=20, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=40, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=30, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=9, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=11, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=31, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=39, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=13, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=18, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=22, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=8, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=32, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=43, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=29, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=34, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=1, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=6, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=41, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=27, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=48, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=5, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=15, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=35, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=25, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=46, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=26, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=36, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=44, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=16, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=37, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=17, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=45, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=3, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=24, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=38, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=33, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=23, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=28, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=2, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=12, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=19, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=14, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=4, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=47, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=49, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=42, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=7, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=21, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2])])])
21:18:21,193 <kafka.conn>[INFO]: Broker version identified as 2.5.0
21:18:21,193 <kafka.conn>[INFO]: Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
21:18:21,194 <kafka.metrics.metrics>[DEBUG]: Added sensor with name bufferpool-wait-time
21:18:21,194 <kafka.metrics.metrics>[DEBUG]: Added sensor with name batch-size
21:18:21,194 <kafka.metrics.metrics>[DEBUG]: Added sensor with name compression-rate
21:18:21,194 <kafka.metrics.metrics>[DEBUG]: Added sensor with name queue-time
21:18:21,194 <kafka.metrics.metrics>[DEBUG]: Added sensor with name produce-throttle-time
21:18:21,194 <kafka.metrics.metrics>[DEBUG]: Added sensor with name records-per-request
21:18:21,194 <kafka.metrics.metrics>[DEBUG]: Added sensor with name bytes
21:18:21,195 <kafka.metrics.metrics>[DEBUG]: Added sensor with name record-retries
21:18:21,195 <kafka.metrics.metrics>[DEBUG]: Added sensor with name errors
21:18:21,195 <kafka.metrics.metrics>[DEBUG]: Added sensor with name record-size-max
21:18:21,196 <kafka.producer.sender>[DEBUG]: Starting Kafka producer I/O thread.
21:18:21,196 <kafka.client>[DEBUG]: Sending metadata request MetadataRequest_v1(topics=NULL) to node bootstrap-0
21:18:21,196 <kafka.producer.kafka>[DEBUG]: Kafka producer started
21:18:21,196 <kafka.protocol.parser>[DEBUG]: Sending request MetadataRequest_v1(topics=NULL)
21:18:21,196 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Request 3: MetadataRequest_v1(topics=NULL)
21:18:21,197 <realtimeProducer>[INFO]: Start running realtime stock producer...
21:18:21,199 <kafka.protocol.parser>[DEBUG]: Received correlation id: 3
21:18:21,199 <kafka.protocol.parser>[DEBUG]: Processing response MetadataResponse_v1
21:18:21,200 <kafka.conn>[DEBUG]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Response 3 (4.016637802124023 ms): MetadataResponse_v1(brokers=[(node_id=2, host='localhost', port=29092, rack=None), (node_id=3, host='localhost', port=39092, rack=None), (node_id=1, host='localhost', port=19092, rack=None)], controller_id=1, topics=[(error_code=0, topic='stockData', is_internal=False, partitions=[(error_code=0, partition=0, leader=3, replicas=[3], isr=[3])]), (error_code=0, topic='realtimeStockData', is_internal=False, partitions=[(error_code=0, partition=0, leader=2, replicas=[2], isr=[2])]), (error_code=0, topic='__consumer_offsets', is_internal=True, partitions=[(error_code=0, partition=0, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=10, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=20, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=40, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=30, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=9, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=11, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=31, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=39, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=13, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=18, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=22, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=8, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=32, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=43, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=29, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=34, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=1, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=6, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=41, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=27, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=48, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=5, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=15, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=35, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=25, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=46, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=26, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=36, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=44, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=16, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=37, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=17, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=45, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=3, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=24, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=38, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=33, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2]), (error_code=0, partition=23, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=28, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=2, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=12, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=19, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=14, leader=3, replicas=[3, 1, 2], isr=[3, 1, 2]), (error_code=0, partition=4, leader=2, replicas=[2, 1, 3], isr=[2, 1, 3]), (error_code=0, partition=47, leader=3, replicas=[3, 2, 1], isr=[3, 2, 1]), (error_code=0, partition=49, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=42, leader=1, replicas=[1, 2, 3], isr=[1, 2, 3]), (error_code=0, partition=7, leader=2, replicas=[2, 3, 1], isr=[2, 3, 1]), (error_code=0, partition=21, leader=1, replicas=[1, 3, 2], isr=[1, 3, 2])])])
21:18:21,201 <kafka.cluster>[DEBUG]: Updated cluster metadata to ClusterMetadata(brokers: 3, topics: 3, groups: 0)
21:18:21,202 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:22,131 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VVS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:22,136 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'VVS,16000.0,100,-200.0,0.0,0.0,0.0,False,-900.0,14:53:27' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:22,136 <kafka.client>[DEBUG]: Initializing connection to node 1 for metadata request
21:18:22,137 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:22,137 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:22,137 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:22,137 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:22,137 <kafka.producer.sender>[DEBUG]: Node 2 not ready; delaying produce of accumulated batch
21:18:22,137 <kafka.client>[DEBUG]: Initiating connection to node 1 at localhost:19092
21:18:22,138 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-1.bytes-sent
21:18:22,138 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-1.bytes-received
21:18:22,138 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-1.latency
21:18:22,138 <kafka.conn>[DEBUG]: <BrokerConnection node_id=1 host=localhost:19092 <disconnected> [unspecified None]>: creating new socket
21:18:22,138 <kafka.conn>[DEBUG]: <BrokerConnection node_id=1 host=localhost:19092 <disconnected> [IPv6 ('::1', 19092, 0, 0)]>: setting socket option (6, 1, 1)
21:18:22,138 <kafka.conn>[INFO]: <BrokerConnection node_id=1 host=localhost:19092 <connecting> [IPv6 ('::1', 19092, 0, 0)]>: connecting to localhost:19092 [('::1', 19092, 0, 0) IPv6]
21:18:22,139 <kafka.client>[DEBUG]: Initiating connection to node 2 at localhost:29092
21:18:22,139 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-2.bytes-sent
21:18:22,139 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-2.bytes-received
21:18:22,139 <kafka.metrics.metrics>[DEBUG]: Added sensor with name node-2.latency
21:18:22,139 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <disconnected> [unspecified None]>: creating new socket
21:18:22,140 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <disconnected> [IPv6 ('::1', 29092, 0, 0)]>: setting socket option (6, 1, 1)
21:18:22,140 <kafka.conn>[INFO]: <BrokerConnection node_id=2 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
21:18:22,140 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: established TCP connection
21:18:22,140 <kafka.conn>[INFO]: <BrokerConnection node_id=2 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
21:18:22,140 <kafka.client>[DEBUG]: Node 2 connected
21:18:22,140 <kafka.conn>[INFO]: <BrokerConnection node_id=bootstrap-0 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]>: Closing connection. 
21:18:22,141 <kafka.conn>[DEBUG]: <BrokerConnection node_id=1 host=localhost:19092 <connecting> [IPv6 ('::1', 19092, 0, 0)]>: established TCP connection
21:18:22,141 <kafka.conn>[INFO]: <BrokerConnection node_id=1 host=localhost:19092 <connecting> [IPv6 ('::1', 19092, 0, 0)]>: Connection complete.
21:18:22,141 <kafka.client>[DEBUG]: Node 1 connected
21:18:22,141 <kafka.producer.sender>[DEBUG]: Node 2 not ready; delaying produce of accumulated batch
21:18:22,142 <kafka.client>[DEBUG]: Sending metadata request MetadataRequest_v1(topics=['realtimeStockData']) to node 2
21:18:22,142 <kafka.protocol.parser>[DEBUG]: Sending request MetadataRequest_v1(topics=['realtimeStockData'])
21:18:22,142 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 1: MetadataRequest_v1(topics=['realtimeStockData'])
21:18:22,143 <kafka.producer.sender>[DEBUG]: Node 2 not ready; delaying produce of accumulated batch
21:18:22,145 <kafka.protocol.parser>[DEBUG]: Received correlation id: 1
21:18:22,145 <kafka.protocol.parser>[DEBUG]: Processing response MetadataResponse_v1
21:18:22,145 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 1 (2.515077590942383 ms): MetadataResponse_v1(brokers=[(node_id=2, host='localhost', port=29092, rack=None), (node_id=3, host='localhost', port=39092, rack=None), (node_id=1, host='localhost', port=19092, rack=None)], controller_id=1, topics=[(error_code=0, topic='realtimeStockData', is_internal=False, partitions=[(error_code=0, partition=0, leader=2, replicas=[2], isr=[2])])])
21:18:22,146 <kafka.cluster>[DEBUG]: Updated cluster metadata to ClusterMetadata(brokers: 3, topics: 1, groups: 0)
21:18:22,146 <kafka.metrics.metrics>[DEBUG]: Added sensor with name topic.realtimeStockData.records-per-batch
21:18:22,146 <kafka.metrics.metrics>[DEBUG]: Added sensor with name topic.realtimeStockData.bytes
21:18:22,146 <kafka.metrics.metrics>[DEBUG]: Added sensor with name topic.realtimeStockData.compression-rate
21:18:22,146 <kafka.metrics.metrics>[DEBUG]: Added sensor with name topic.realtimeStockData.record-retries
21:18:22,146 <kafka.metrics.metrics>[DEBUG]: Added sensor with name topic.realtimeStockData.record-errors
21:18:22,146 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:22,146 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x023[g\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8D9\x00\x00\x01\x94\x12\xc8D9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVVS,16000.0,100,-200.0,0.0,0.0,0....')])])}
21:18:22,146 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x023[g\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8D9\x00\x00\x01\x94\x12\xc8D9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVVS,16000.0,100,-200.0,0.0,0.0,0....')])])
21:18:22,147 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x023[g\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8D9\x00\x00\x01\x94\x12\xc8D9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVVS,16000.0,100,-200.0,0.0,0.0,0....')])])
21:18:22,147 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x023[g\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8D9\x00\x00\x01\x94\x12\xc8D9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVVS,16000.0,100,-200.0,0.0,0.0,0....')])])
21:18:22,157 <kafka.protocol.parser>[DEBUG]: Received correlation id: 2
21:18:22,157 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:22,157 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 2 (9.961843490600586 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=0, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:22,157 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=0, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:22,157 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 0 log start offset 0 and error None.
21:18:22,159 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:23,97 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/XDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:23,100 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:23,407 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HSV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:23,409 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HSV,4000.0,3000,0.0,0.0,0.0,0.0,False,0.0,14:55:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:23,409 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:23,409 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:23,409 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:23,409 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:23,410 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02nvw\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8I1\x00\x00\x01\x94\x12\xc8I1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSV,4000.0,3000,0.0,0.0,0.0,0.0,F...')])])}
21:18:23,410 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02nvw\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8I1\x00\x00\x01\x94\x12\xc8I1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSV,4000.0,3000,0.0,0.0,0.0,0.0,F...')])])
21:18:23,410 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02nvw\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8I1\x00\x00\x01\x94\x12\xc8I1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSV,4000.0,3000,0.0,0.0,0.0,0.0,F...')])])
21:18:23,410 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 3: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02nvw\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8I1\x00\x00\x01\x94\x12\xc8I1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSV,4000.0,3000,0.0,0.0,0.0,0.0,F...')])])
21:18:23,410 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:23,413 <kafka.protocol.parser>[DEBUG]: Received correlation id: 3
21:18:23,413 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:23,413 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 3 (3.0028820037841797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=1, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:23,413 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=1, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:23,413 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 1 log start offset 0 and error None.
21:18:23,415 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:26,16 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CST/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:26,18 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CST,25100.0,100,0.0,0.0,0.0,0.0,False,200.0,14:45:16' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:26,18 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:26,18 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:26,18 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:26,19 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:26,19 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02R0ua\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8Sb\x00\x00\x01\x94\x12\xc8Sb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCST,25100.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:18:26,19 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02R0ua\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8Sb\x00\x00\x01\x94\x12\xc8Sb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCST,25100.0,100,0.0,0.0,0.0,0.0,F...')])])
21:18:26,19 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02R0ua\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8Sb\x00\x00\x01\x94\x12\xc8Sb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCST,25100.0,100,0.0,0.0,0.0,0.0,F...')])])
21:18:26,19 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:26,19 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 4: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02R0ua\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8Sb\x00\x00\x01\x94\x12\xc8Sb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCST,25100.0,100,0.0,0.0,0.0,0.0,F...')])])
21:18:26,22 <kafka.protocol.parser>[DEBUG]: Received correlation id: 4
21:18:26,22 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:26,22 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 4 (2.9671192169189453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=2, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:26,22 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=2, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:26,23 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 2 log start offset 0 and error None.
21:18:26,24 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:26,299 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BVL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:26,301 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BVL,9300.0,200,-200.0,0.0,0.0,0.0,False,0.0,14:08:23' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:26,301 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:26,301 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:26,301 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:26,302 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:26,302 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x93\xa7\tW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8T}\x00\x00\x01\x94\x12\xc8T}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBVL,9300.0,200,-200.0,0.0,0.0,0.0...')])])}
21:18:26,302 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x93\xa7\tW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8T}\x00\x00\x01\x94\x12\xc8T}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBVL,9300.0,200,-200.0,0.0,0.0,0.0...')])])
21:18:26,302 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x93\xa7\tW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8T}\x00\x00\x01\x94\x12\xc8T}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBVL,9300.0,200,-200.0,0.0,0.0,0.0...')])])
21:18:26,302 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:26,302 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 5: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x93\xa7\tW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8T}\x00\x00\x01\x94\x12\xc8T}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBVL,9300.0,200,-200.0,0.0,0.0,0.0...')])])
21:18:26,305 <kafka.protocol.parser>[DEBUG]: Received correlation id: 5
21:18:26,305 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:26,305 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 5 (2.031087875366211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=3, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:26,305 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=3, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:26,306 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 3 log start offset 0 and error None.
21:18:26,307 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:26,672 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/SGI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:26,768 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:28,65 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TOS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:28,68 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'TOS,74200.0,100,0.0,0.0,0.0,0.0,False,100.0,14:21:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:28,68 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:28,68 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:28,68 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:28,68 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:28,69 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x10F\x88\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8[d\x00\x00\x01\x94\x12\xc8[d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hTOS,74200.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:18:28,69 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x10F\x88\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8[d\x00\x00\x01\x94\x12\xc8[d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hTOS,74200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:18:28,69 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x10F\x88\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8[d\x00\x00\x01\x94\x12\xc8[d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hTOS,74200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:18:28,69 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:28,69 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 6: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x10F\x88\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8[d\x00\x00\x01\x94\x12\xc8[d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hTOS,74200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:18:28,72 <kafka.protocol.parser>[DEBUG]: Received correlation id: 6
21:18:28,72 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:28,72 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 6 (2.9990673065185547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=4, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:28,73 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=4, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:28,73 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 4 log start offset 0 and error None.
21:18:28,74 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:28,444 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VTZ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:28,446 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'VTZ,17400.0,14100,0.0,0.0,0.0,0.0,True,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:28,446 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:28,446 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:28,446 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:28,447 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:28,447 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02.\xd2\x1c&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\\\xde\x00\x00\x01\x94\x12\xc8\\\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVTZ,17400.0,14100,0.0,0.0,0.0,0.0...')])])}
21:18:28,447 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02.\xd2\x1c&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\\\xde\x00\x00\x01\x94\x12\xc8\\\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVTZ,17400.0,14100,0.0,0.0,0.0,0.0...')])])
21:18:28,447 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02.\xd2\x1c&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\\\xde\x00\x00\x01\x94\x12\xc8\\\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVTZ,17400.0,14100,0.0,0.0,0.0,0.0...')])])
21:18:28,447 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 7: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02.\xd2\x1c&\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\\\xde\x00\x00\x01\x94\x12\xc8\\\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVTZ,17400.0,14100,0.0,0.0,0.0,0.0...')])])
21:18:28,447 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:28,450 <kafka.protocol.parser>[DEBUG]: Received correlation id: 7
21:18:28,450 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:28,450 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 7 (2.9959678649902344 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=5, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:28,450 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=5, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:28,451 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 5 log start offset 0 and error None.
21:18:28,452 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:29,208 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/SSH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:29,210 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'SSH,67100.0,400,100.0,0.0,0.0,0.0,False,0.0,14:25:58' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,211 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,211 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:29,211 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:29,211 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,211 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:29,211 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe1,5j\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8_\xdb\x00\x00\x01\x94\x12\xc8_\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hSSH,67100.0,400,100.0,0.0,0.0,0.0...')])])}
21:18:29,211 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe1,5j\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8_\xdb\x00\x00\x01\x94\x12\xc8_\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hSSH,67100.0,400,100.0,0.0,0.0,0.0...')])])
21:18:29,212 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe1,5j\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8_\xdb\x00\x00\x01\x94\x12\xc8_\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hSSH,67100.0,400,100.0,0.0,0.0,0.0...')])])
21:18:29,212 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 8: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe1,5j\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8_\xdb\x00\x00\x01\x94\x12\xc8_\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hSSH,67100.0,400,100.0,0.0,0.0,0.0...')])])
21:18:29,215 <kafka.protocol.parser>[DEBUG]: Received correlation id: 8
21:18:29,215 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:29,215 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 8 (3.014087677001953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=6, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:29,215 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=6, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:29,215 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 6 log start offset 0 and error None.
21:18:29,216 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:29,555 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:29,557 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BCA,12000.0,800,-200.0,0.0,0.0,0.0,False,200.0,14:23:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,557 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,557 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:29,557 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:29,557 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:29,557 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\r\xce\xe9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8a5\x00\x00\x01\x94\x12\xc8a5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCA,12000.0,800,-200.0,0.0,0.0,0....')])])}
21:18:29,557 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\r\xce\xe9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8a5\x00\x00\x01\x94\x12\xc8a5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCA,12000.0,800,-200.0,0.0,0.0,0....')])])
21:18:29,558 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,558 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\r\xce\xe9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8a5\x00\x00\x01\x94\x12\xc8a5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCA,12000.0,800,-200.0,0.0,0.0,0....')])])
21:18:29,558 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 9: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\r\xce\xe9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8a5\x00\x00\x01\x94\x12\xc8a5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCA,12000.0,800,-200.0,0.0,0.0,0....')])])
21:18:29,561 <kafka.protocol.parser>[DEBUG]: Received correlation id: 9
21:18:29,561 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:29,561 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 9 (3.0007362365722656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=7, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:29,562 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=7, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:29,562 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 7 log start offset 0 and error None.
21:18:29,563 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:29,953 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUCTVGF3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:29,955 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUCTVGF3,16000.0,100,350.0,0.0,0.0,0.0,False,0.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,955 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,956 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:29,956 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:29,956 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:29,956 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb2TS\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8b\xc3\x00\x00\x01\x94\x12\xc8b\xc3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF3,16000.0,100,350.0,0.0,0....')])])}
21:18:29,956 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb2TS\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8b\xc3\x00\x00\x01\x94\x12\xc8b\xc3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF3,16000.0,100,350.0,0.0,0....')])])
21:18:29,956 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:29,956 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb2TS\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8b\xc3\x00\x00\x01\x94\x12\xc8b\xc3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF3,16000.0,100,350.0,0.0,0....')])])
21:18:29,957 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 10: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb2TS\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8b\xc3\x00\x00\x01\x94\x12\xc8b\xc3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF3,16000.0,100,350.0,0.0,0....')])])
21:18:29,959 <kafka.protocol.parser>[DEBUG]: Received correlation id: 10
21:18:29,960 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:29,960 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 10 (3.0002593994140625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=8, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:29,960 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=8, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:29,960 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 8 log start offset 0 and error None.
21:18:29,961 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:30,263 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUEIP100/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:30,265 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUEIP100,8350.0,200,370.0,0.0,0.0,0.0,False,50.0,13:53:24' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,266 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,266 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:30,266 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:30,266 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:30,266 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02U\x1a\x0e\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8c\xfa\x00\x00\x01\x94\x12\xc8c\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEIP100,8350.0,200,370.0,0.0,0.0...')])])}
21:18:30,266 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02U\x1a\x0e\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8c\xfa\x00\x00\x01\x94\x12\xc8c\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEIP100,8350.0,200,370.0,0.0,0.0...')])])
21:18:30,266 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02U\x1a\x0e\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8c\xfa\x00\x00\x01\x94\x12\xc8c\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEIP100,8350.0,200,370.0,0.0,0.0...')])])
21:18:30,267 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 11: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02U\x1a\x0e\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8c\xfa\x00\x00\x01\x94\x12\xc8c\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEIP100,8350.0,200,370.0,0.0,0.0...')])])
21:18:30,267 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,269 <kafka.protocol.parser>[DEBUG]: Received correlation id: 11
21:18:30,269 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:30,270 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 11 (2.971172332763672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=9, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:30,270 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=9, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:30,270 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 9 log start offset 0 and error None.
21:18:30,271 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:30,586 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GMH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:30,588 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GMH,8090.0,200,290.0,0.0,0.0,0.0,False,40.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,588 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,589 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:30,589 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:30,589 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:30,589 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x86$\t|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8e=\x00\x00\x01\x94\x12\xc8e=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGMH,8090.0,200,290.0,0.0,0.0,0.0,...')])])}
21:18:30,589 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x86$\t|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8e=\x00\x00\x01\x94\x12\xc8e=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGMH,8090.0,200,290.0,0.0,0.0,0.0,...')])])
21:18:30,590 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x86$\t|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8e=\x00\x00\x01\x94\x12\xc8e=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGMH,8090.0,200,290.0,0.0,0.0,0.0,...')])])
21:18:30,589 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,590 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 12: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x86$\t|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8e=\x00\x00\x01\x94\x12\xc8e=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGMH,8090.0,200,290.0,0.0,0.0,0.0,...')])])
21:18:30,594 <kafka.protocol.parser>[DEBUG]: Received correlation id: 12
21:18:30,594 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:30,594 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 12 (3.251791000366211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=10, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:30,594 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=10, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:30,595 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 10 log start offset 0 and error None.
21:18:30,596 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:30,874 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BIG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:30,876 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BIG,6800.0,400,-600.0,-0.1,0.0,0.0,False,0.0,14:56:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,876 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,877 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:30,877 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:30,877 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe5u{\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8f]\x00\x00\x01\x94\x12\xc8f]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBIG,6800.0,400,-600.0,-0.1,0.0,0....')])])}
21:18:30,877 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe5u{\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8f]\x00\x00\x01\x94\x12\xc8f]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBIG,6800.0,400,-600.0,-0.1,0.0,0....')])])
21:18:30,877 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe5u{\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8f]\x00\x00\x01\x94\x12\xc8f]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBIG,6800.0,400,-600.0,-0.1,0.0,0....')])])
21:18:30,878 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 13: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe5u{\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8f]\x00\x00\x01\x94\x12\xc8f]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBIG,6800.0,400,-600.0,-0.1,0.0,0....')])])
21:18:30,878 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:30,878 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:30,880 <kafka.protocol.parser>[DEBUG]: Received correlation id: 13
21:18:30,880 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:30,880 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 13 (2.0008087158203125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=11, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:30,881 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=11, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:30,881 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 11 log start offset 0 and error None.
21:18:30,882 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:31,558 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:31,560 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMM,9200.0,100,100.0,0.0,0.0,0.0,False,0.0,09:19:37' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:31,560 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:31,560 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:31,560 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:31,561 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:31,561 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcc+\xf3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8i\x08\x00\x00\x01\x94\x12\xc8i\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMM,9200.0,100,100.0,0.0,0.0,0.0,...')])])}
21:18:31,561 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcc+\xf3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8i\x08\x00\x00\x01\x94\x12\xc8i\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMM,9200.0,100,100.0,0.0,0.0,0.0,...')])])
21:18:31,561 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcc+\xf3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8i\x08\x00\x00\x01\x94\x12\xc8i\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMM,9200.0,100,100.0,0.0,0.0,0.0,...')])])
21:18:31,561 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:31,561 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 14: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcc+\xf3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8i\x08\x00\x00\x01\x94\x12\xc8i\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMM,9200.0,100,100.0,0.0,0.0,0.0,...')])])
21:18:31,564 <kafka.protocol.parser>[DEBUG]: Received correlation id: 14
21:18:31,564 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:31,564 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 14 (2.0055770874023438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=12, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:31,565 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=12, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:31,565 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 12 log start offset 0 and error None.
21:18:31,566 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:31,878 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CNA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:31,880 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:32,803 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUEKIV30/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:32,805 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUEKIV30,8970.0,100,0.0,0.0,0.0,0.0,False,-30.0,13:28:58' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:32,805 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:32,805 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:32,805 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:32,806 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:32,806 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xabz\xf6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8m\xe5\x00\x00\x01\x94\x12\xc8m\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUEKIV30,8970.0,100,0.0,0.0,0.0,0...')])])}
21:18:32,806 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xabz\xf6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8m\xe5\x00\x00\x01\x94\x12\xc8m\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUEKIV30,8970.0,100,0.0,0.0,0.0,0...')])])
21:18:32,806 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:32,806 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xabz\xf6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8m\xe5\x00\x00\x01\x94\x12\xc8m\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUEKIV30,8970.0,100,0.0,0.0,0.0,0...')])])
21:18:32,806 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 15: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xabz\xf6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8m\xe5\x00\x00\x01\x94\x12\xc8m\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUEKIV30,8970.0,100,0.0,0.0,0.0,0...')])])
21:18:32,809 <kafka.protocol.parser>[DEBUG]: Received correlation id: 15
21:18:32,809 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:32,810 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 15 (3.994464874267578 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=13, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:32,810 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=13, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:32,810 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 13 log start offset 0 and error None.
21:18:32,813 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:33,109 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ODE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:33,111 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ODE,44200.0,500,200.0,0.0,0.0,0.0,False,0.0,14:44:43' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:33,111 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:33,111 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:33,112 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:33,112 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:33,112 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:33,112 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8e\xd8\xf1,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8o\x17\x00\x00\x01\x94\x12\xc8o\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hODE,44200.0,500,200.0,0.0,0.0,0.0...')])])}
21:18:33,112 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8e\xd8\xf1,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8o\x17\x00\x00\x01\x94\x12\xc8o\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hODE,44200.0,500,200.0,0.0,0.0,0.0...')])])
21:18:33,112 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8e\xd8\xf1,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8o\x17\x00\x00\x01\x94\x12\xc8o\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hODE,44200.0,500,200.0,0.0,0.0,0.0...')])])
21:18:33,113 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 16: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8e\xd8\xf1,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8o\x17\x00\x00\x01\x94\x12\xc8o\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hODE,44200.0,500,200.0,0.0,0.0,0.0...')])])
21:18:33,115 <kafka.protocol.parser>[DEBUG]: Received correlation id: 16
21:18:33,115 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:33,116 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 16 (3.032207489013672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=14, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:33,116 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=14, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:33,116 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 14 log start offset 0 and error None.
21:18:33,117 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:34,487 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HMR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:34,489 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HMR,11600.0,500,-200.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:34,489 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:34,489 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:34,489 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:34,489 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:34,490 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:34,490 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02A\x04\xc1>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8ty\x00\x00\x01\x94\x12\xc8ty\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHMR,11600.0,500,-200.0,0.0,0.0,0....')])])}
21:18:34,490 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02A\x04\xc1>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8ty\x00\x00\x01\x94\x12\xc8ty\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHMR,11600.0,500,-200.0,0.0,0.0,0....')])])
21:18:34,490 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02A\x04\xc1>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8ty\x00\x00\x01\x94\x12\xc8ty\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHMR,11600.0,500,-200.0,0.0,0.0,0....')])])
21:18:34,490 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 17: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02A\x04\xc1>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8ty\x00\x00\x01\x94\x12\xc8ty\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHMR,11600.0,500,-200.0,0.0,0.0,0....')])])
21:18:34,493 <kafka.protocol.parser>[DEBUG]: Received correlation id: 17
21:18:34,493 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:34,493 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 17 (2.999544143676758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=15, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:34,493 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=15, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:34,494 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 15 log start offset 0 and error None.
21:18:34,496 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:35,168 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PCH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:35,170 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PCH,12900.0,300,100.0,0.0,0.0,0.0,False,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:35,170 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:35,170 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:35,170 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:35,171 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:35,171 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1v;\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8w"\x00\x00\x01\x94\x12\xc8w"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hPCH,12900.0,300,100.0,0.0,0.0,0.0...')])])}
21:18:35,171 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1v;\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8w"\x00\x00\x01\x94\x12\xc8w"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hPCH,12900.0,300,100.0,0.0,0.0,0.0...')])])
21:18:35,171 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1v;\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8w"\x00\x00\x01\x94\x12\xc8w"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hPCH,12900.0,300,100.0,0.0,0.0,0.0...')])])
21:18:35,171 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 18: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1v;\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8w"\x00\x00\x01\x94\x12\xc8w"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hPCH,12900.0,300,100.0,0.0,0.0,0.0...')])])
21:18:35,171 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:35,174 <kafka.protocol.parser>[DEBUG]: Received correlation id: 18
21:18:35,174 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:35,174 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 18 (3.1690597534179688 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=16, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:35,174 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=16, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:35,174 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 16 log start offset 0 and error None.
21:18:35,175 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:40,195 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DSD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:40,283 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DSD,16400.0,100,400.0,0.0,0.0,0.0,False,0.0,13:54:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:40,283 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:40,284 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:40,284 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:40,284 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\x80E\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8b\x1c\x00\x00\x01\x94\x12\xc8\x8b\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDSD,16400.0,100,400.0,0.0,0.0,0.0...')])])}
21:18:40,284 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\x80E\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8b\x1c\x00\x00\x01\x94\x12\xc8\x8b\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDSD,16400.0,100,400.0,0.0,0.0,0.0...')])])
21:18:40,284 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:40,285 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\x80E\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8b\x1c\x00\x00\x01\x94\x12\xc8\x8b\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDSD,16400.0,100,400.0,0.0,0.0,0.0...')])])
21:18:40,285 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:40,285 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 19: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\x80E\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8b\x1c\x00\x00\x01\x94\x12\xc8\x8b\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDSD,16400.0,100,400.0,0.0,0.0,0.0...')])])
21:18:40,288 <kafka.protocol.parser>[DEBUG]: Received correlation id: 19
21:18:40,288 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:40,288 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 19 (3.0012130737304688 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=17, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:40,288 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=17, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:40,288 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 17 log start offset 0 and error None.
21:18:40,290 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:40,582 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NO1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:40,584 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NO1,11200.0,200,-800.0,-0.1,0.0,0.0,False,0.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:40,584 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:40,584 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:40,584 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:40,585 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:40,585 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:40,585 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x0240I\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8cH\x00\x00\x01\x94\x12\xc8\x8cH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNO1,11200.0,200,-800.0,-0.1,0.0,0...')])])}
21:18:40,585 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x0240I\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8cH\x00\x00\x01\x94\x12\xc8\x8cH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNO1,11200.0,200,-800.0,-0.1,0.0,0...')])])
21:18:40,585 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x0240I\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8cH\x00\x00\x01\x94\x12\xc8\x8cH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNO1,11200.0,200,-800.0,-0.1,0.0,0...')])])
21:18:40,585 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 20: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x0240I\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x8cH\x00\x00\x01\x94\x12\xc8\x8cH\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNO1,11200.0,200,-800.0,-0.1,0.0,0...')])])
21:18:40,588 <kafka.protocol.parser>[DEBUG]: Received correlation id: 20
21:18:40,588 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:40,588 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 20 (3.6242008209228516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=18, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:40,588 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=18, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:40,588 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 18 log start offset 0 and error None.
21:18:40,589 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:40,910 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MGR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:40,912 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:42,706 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PPT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:42,708 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PPT,13400.0,800,0.0,0.0,0.0,0.0,False,0.0,14:29:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:42,708 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:42,708 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:42,709 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:42,709 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:42,709 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xf5\xf2\x05?\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x94\x94\x00\x00\x01\x94\x12\xc8\x94\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPPT,13400.0,800,0.0,0.0,0.0,0.0,F...')])])}
21:18:42,709 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xf5\xf2\x05?\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x94\x94\x00\x00\x01\x94\x12\xc8\x94\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPPT,13400.0,800,0.0,0.0,0.0,0.0,F...')])])
21:18:42,709 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:42,709 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xf5\xf2\x05?\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x94\x94\x00\x00\x01\x94\x12\xc8\x94\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPPT,13400.0,800,0.0,0.0,0.0,0.0,F...')])])
21:18:42,710 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 21: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xf5\xf2\x05?\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\x94\x94\x00\x00\x01\x94\x12\xc8\x94\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPPT,13400.0,800,0.0,0.0,0.0,0.0,F...')])])
21:18:42,712 <kafka.protocol.parser>[DEBUG]: Received correlation id: 21
21:18:42,713 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:42,713 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 21 (3.214120864868164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=19, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:42,713 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=19, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:42,713 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 19 log start offset 0 and error None.
21:18:42,714 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:44,660 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CVP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:44,663 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:45,112 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CAR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:45,114 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:47,701 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GPC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:47,703 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GPC,2900.0,1000,0.0,0.0,0.0,0.0,False,0.0,14:55:42' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:47,703 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:47,704 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:47,704 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:47,704 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:47,704 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02t\x88+*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa8\x18\x00\x00\x01\x94\x12\xc8\xa8\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dGPC,2900.0,1000,0.0,0.0,0.0,0.0,F...')])])}
21:18:47,704 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02t\x88+*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa8\x18\x00\x00\x01\x94\x12\xc8\xa8\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dGPC,2900.0,1000,0.0,0.0,0.0,0.0,F...')])])
21:18:47,704 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02t\x88+*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa8\x18\x00\x00\x01\x94\x12\xc8\xa8\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dGPC,2900.0,1000,0.0,0.0,0.0,0.0,F...')])])
21:18:47,705 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 22: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02t\x88+*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa8\x18\x00\x00\x01\x94\x12\xc8\xa8\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dGPC,2900.0,1000,0.0,0.0,0.0,0.0,F...')])])
21:18:47,705 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:47,707 <kafka.protocol.parser>[DEBUG]: Received correlation id: 22
21:18:47,707 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:47,708 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 22 (3.001689910888672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=20, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:47,708 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=20, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:47,708 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 20 log start offset 0 and error None.
21:18:47,709 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:48,28 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUCTVGF4/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:48,30 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUCTVGF4,16900.0,100,900.0,0.1,0.0,0.0,False,0.0,10:08:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:48,30 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:48,30 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:48,30 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:48,31 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:48,31 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xbc[\xae\xce\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa9^\x00\x00\x01\x94\x12\xc8\xa9^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF4,16900.0,100,900.0,0.1,0....')])])}
21:18:48,31 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xbc[\xae\xce\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa9^\x00\x00\x01\x94\x12\xc8\xa9^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF4,16900.0,100,900.0,0.1,0....')])])
21:18:48,31 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xbc[\xae\xce\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa9^\x00\x00\x01\x94\x12\xc8\xa9^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF4,16900.0,100,900.0,0.1,0....')])])
21:18:48,31 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 23: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xbc[\xae\xce\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xa9^\x00\x00\x01\x94\x12\xc8\xa9^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUCTVGF4,16900.0,100,900.0,0.1,0....')])])
21:18:48,32 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:48,34 <kafka.protocol.parser>[DEBUG]: Received correlation id: 23
21:18:48,34 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:48,34 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 23 (2.995014190673828 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=21, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:48,34 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=21, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:48,34 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 21 log start offset 0 and error None.
21:18:48,36 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:48,702 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUEDCMID/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:48,704 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUEDCMID,11900.0,300,20.0,0.0,0.0,0.0,False,-40.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:48,704 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:48,704 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:48,704 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:48,705 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:48,705 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeeK'\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xac\x00\x00\x00\x01\x94\x12\xc8\xac\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEDCMID,11900.0,300,20.0,0.0,0....")])])}
21:18:48,705 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeeK'\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xac\x00\x00\x00\x01\x94\x12\xc8\xac\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEDCMID,11900.0,300,20.0,0.0,0....")])])
21:18:48,705 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:48,705 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeeK'\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xac\x00\x00\x00\x01\x94\x12\xc8\xac\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEDCMID,11900.0,300,20.0,0.0,0....")])])
21:18:48,705 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 24: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeeK'\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xac\x00\x00\x00\x01\x94\x12\xc8\xac\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEDCMID,11900.0,300,20.0,0.0,0....")])])
21:18:48,708 <kafka.protocol.parser>[DEBUG]: Received correlation id: 24
21:18:48,708 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:48,708 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 24 (2.9976367950439453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=22, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:48,708 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=22, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:48,708 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 22 log start offset 0 and error None.
21:18:48,710 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:49,250 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUEKIVFS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:49,252 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUEKIVFS,13010.0,5200,30.0,0.0,0.0,0.0,False,60.0,14:13:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:49,252 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:49,252 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:49,252 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:49,252 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:49,252 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02t\xfc\xb4~\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xae$\x00\x00\x01\x94\x12\xc8\xae$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEKIVFS,13010.0,5200,30.0,0.0,0...')])])}
21:18:49,253 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02t\xfc\xb4~\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xae$\x00\x00\x01\x94\x12\xc8\xae$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEKIVFS,13010.0,5200,30.0,0.0,0...')])])
21:18:49,253 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02t\xfc\xb4~\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xae$\x00\x00\x01\x94\x12\xc8\xae$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEKIVFS,13010.0,5200,30.0,0.0,0...')])])
21:18:49,253 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 25: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02t\xfc\xb4~\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xae$\x00\x00\x01\x94\x12\xc8\xae$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEKIVFS,13010.0,5200,30.0,0.0,0...')])])
21:18:49,253 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:49,255 <kafka.protocol.parser>[DEBUG]: Received correlation id: 25
21:18:49,256 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:49,256 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 25 (3.0252933502197266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=23, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:49,256 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=23, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:49,256 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 23 log start offset 0 and error None.
21:18:49,257 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:49,545 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GCF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:49,547 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GCF,25000.0,100,1200.0,0.1,0.0,0.0,False,1000.0,13:22:38' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:49,547 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:49,547 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:49,547 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:49,547 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:49,547 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:49,547 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb8\x05\xa4\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xafK\x00\x00\x01\x94\x12\xc8\xafK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGCF,25000.0,100,1200.0,0.1,0.0,0....')])])}
21:18:49,548 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb8\x05\xa4\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xafK\x00\x00\x01\x94\x12\xc8\xafK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGCF,25000.0,100,1200.0,0.1,0.0,0....')])])
21:18:49,548 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb8\x05\xa4\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xafK\x00\x00\x01\x94\x12\xc8\xafK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGCF,25000.0,100,1200.0,0.1,0.0,0....')])])
21:18:49,548 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 26: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb8\x05\xa4\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xafK\x00\x00\x01\x94\x12\xc8\xafK\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGCF,25000.0,100,1200.0,0.1,0.0,0....')])])
21:18:49,550 <kafka.protocol.parser>[DEBUG]: Received correlation id: 26
21:18:49,550 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:49,551 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 26 (2.969980239868164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=24, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:49,551 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=24, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:49,551 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 24 log start offset 0 and error None.
21:18:49,552 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:50,246 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LPT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:50,248 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LPT,6300.0,1000,-100.0,0.0,0.0,0.0,False,-100.0,13:13:49' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:50,248 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:50,248 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:50,248 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:50,249 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:50,249 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:50,249 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02;\xbd\x87\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb2\x08\x00\x00\x01\x94\x12\xc8\xb2\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pLPT,6300.0,1000,-100.0,0.0,0.0,0....')])])}
21:18:50,249 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02;\xbd\x87\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb2\x08\x00\x00\x01\x94\x12\xc8\xb2\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pLPT,6300.0,1000,-100.0,0.0,0.0,0....')])])
21:18:50,249 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02;\xbd\x87\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb2\x08\x00\x00\x01\x94\x12\xc8\xb2\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pLPT,6300.0,1000,-100.0,0.0,0.0,0....')])])
21:18:50,249 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 27: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02;\xbd\x87\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb2\x08\x00\x00\x01\x94\x12\xc8\xb2\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pLPT,6300.0,1000,-100.0,0.0,0.0,0....')])])
21:18:50,252 <kafka.protocol.parser>[DEBUG]: Received correlation id: 27
21:18:50,252 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:50,252 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 27 (2.0012855529785156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=25, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:50,253 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=25, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:50,253 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 25 log start offset 0 and error None.
21:18:50,254 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:50,708 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AAA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:50,710 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AAA,8900.0,225300,-120.0,0.0,0.0,0.0,True,-40.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:50,710 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:50,710 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:50,710 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:50,710 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:50,711 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\xf8\xdd/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb3\xd6\x00\x00\x01\x94\x12\xc8\xb3\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAAA,8900.0,225300,-120.0,0.0,0.0,...')])])}
21:18:50,711 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\xf8\xdd/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb3\xd6\x00\x00\x01\x94\x12\xc8\xb3\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAAA,8900.0,225300,-120.0,0.0,0.0,...')])])
21:18:50,711 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:50,711 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\xf8\xdd/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb3\xd6\x00\x00\x01\x94\x12\xc8\xb3\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAAA,8900.0,225300,-120.0,0.0,0.0,...')])])
21:18:50,711 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 28: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\xf8\xdd/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xb3\xd6\x00\x00\x01\x94\x12\xc8\xb3\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAAA,8900.0,225300,-120.0,0.0,0.0,...')])])
21:18:50,714 <kafka.protocol.parser>[DEBUG]: Received correlation id: 28
21:18:50,714 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:50,715 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 28 (3.0069351196289062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=26, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:50,715 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=26, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:50,715 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 26 log start offset 0 and error None.
21:18:50,716 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:52,619 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AAM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:52,621 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AAM,7320.0,3500,70.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:52,621 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:52,621 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:52,621 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:52,622 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:52,622 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:52,622 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa0'<\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xbbM\x00\x00\x01\x94\x12\xc8\xbbM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAAM,7320.0,3500,70.0,0.0,0.0,0.0,...")])])}
21:18:52,622 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa0'<\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xbbM\x00\x00\x01\x94\x12\xc8\xbbM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAAM,7320.0,3500,70.0,0.0,0.0,0.0,...")])])
21:18:52,622 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa0'<\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xbbM\x00\x00\x01\x94\x12\xc8\xbbM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAAM,7320.0,3500,70.0,0.0,0.0,0.0,...")])])
21:18:52,622 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 29: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa0'<\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xbbM\x00\x00\x01\x94\x12\xc8\xbbM\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAAM,7320.0,3500,70.0,0.0,0.0,0.0,...")])])
21:18:52,625 <kafka.protocol.parser>[DEBUG]: Received correlation id: 29
21:18:52,625 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:52,625 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 29 (3.2324790954589844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=27, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:52,625 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=27, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:52,625 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 27 log start offset 0 and error None.
21:18:52,627 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:54,342 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AAT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:54,344 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AAT,3490.0,2300,10.0,0.0,0.0,0.0,False,-10.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:54,344 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:54,345 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:54,345 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:54,345 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:54,345 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbf\x99\x1bq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc2\t\x00\x00\x01\x94\x12\xc8\xc2\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAT,3490.0,2300,10.0,0.0,0.0,0.0,...')])])}
21:18:54,345 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbf\x99\x1bq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc2\t\x00\x00\x01\x94\x12\xc8\xc2\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAT,3490.0,2300,10.0,0.0,0.0,0.0,...')])])
21:18:54,345 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbf\x99\x1bq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc2\t\x00\x00\x01\x94\x12\xc8\xc2\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAT,3490.0,2300,10.0,0.0,0.0,0.0,...')])])
21:18:54,346 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:54,346 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 30: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbf\x99\x1bq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc2\t\x00\x00\x01\x94\x12\xc8\xc2\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAT,3490.0,2300,10.0,0.0,0.0,0.0,...')])])
21:18:54,350 <kafka.protocol.parser>[DEBUG]: Received correlation id: 30
21:18:54,350 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:54,350 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 30 (4.040718078613281 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=28, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:54,351 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=28, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:54,351 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 28 log start offset 0 and error None.
21:18:54,352 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:55,413 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AAV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:55,501 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AAV,7500.0,86300,100.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:55,501 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:55,501 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:55,501 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:55,503 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:55,503 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:55,503 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02A\xfe\xc3\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc6\x8d\x00\x00\x01\x94\x12\xc8\xc6\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAAV,7500.0,86300,100.0,0.0,0.0,0....')])])}
21:18:55,503 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02A\xfe\xc3\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc6\x8d\x00\x00\x01\x94\x12\xc8\xc6\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAAV,7500.0,86300,100.0,0.0,0.0,0....')])])
21:18:55,503 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02A\xfe\xc3\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc6\x8d\x00\x00\x01\x94\x12\xc8\xc6\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAAV,7500.0,86300,100.0,0.0,0.0,0....')])])
21:18:55,503 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 31: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02A\xfe\xc3\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc6\x8d\x00\x00\x01\x94\x12\xc8\xc6\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAAV,7500.0,86300,100.0,0.0,0.0,0....')])])
21:18:55,505 <kafka.protocol.parser>[DEBUG]: Received correlation id: 31
21:18:55,505 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:55,505 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 31 (1.9955635070800781 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=29, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:55,505 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=29, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:55,505 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 29 log start offset 0 and error None.
21:18:55,506 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:55,795 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ABB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:55,797 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ABB,7400.0,5000,0.0,0.0,0.0,0.0,False,0.0,14:56:55' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:55,797 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:55,797 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:55,797 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:55,798 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:55,798 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02q;\x1b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc7\xb5\x00\x00\x01\x94\x12\xc8\xc7\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dABB,7400.0,5000,0.0,0.0,0.0,0.0,F...')])])}
21:18:55,798 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02q;\x1b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc7\xb5\x00\x00\x01\x94\x12\xc8\xc7\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dABB,7400.0,5000,0.0,0.0,0.0,0.0,F...')])])
21:18:55,798 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:55,798 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02q;\x1b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc7\xb5\x00\x00\x01\x94\x12\xc8\xc7\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dABB,7400.0,5000,0.0,0.0,0.0,0.0,F...')])])
21:18:55,799 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 32: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02q;\x1b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xc7\xb5\x00\x00\x01\x94\x12\xc8\xc7\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dABB,7400.0,5000,0.0,0.0,0.0,0.0,F...')])])
21:18:55,802 <kafka.protocol.parser>[DEBUG]: Received correlation id: 32
21:18:55,802 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:55,802 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 32 (2.9823780059814453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=30, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:55,802 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=30, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:55,803 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 30 log start offset 0 and error None.
21:18:55,804 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:57,136 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ABI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:57,555 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ABI,26200.0,4500,100.0,0.0,0.0,0.0,False,100.0,14:59:16' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:57,555 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:57,555 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:57,555 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:57,555 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:57,556 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\xd4\x82\x16\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xce\x93\x00\x00\x01\x94\x12\xc8\xce\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nABI,26200.0,4500,100.0,0.0,0.0,0....')])])}
21:18:57,556 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\xd4\x82\x16\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xce\x93\x00\x00\x01\x94\x12\xc8\xce\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nABI,26200.0,4500,100.0,0.0,0.0,0....')])])
21:18:57,556 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\xd4\x82\x16\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xce\x93\x00\x00\x01\x94\x12\xc8\xce\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nABI,26200.0,4500,100.0,0.0,0.0,0....')])])
21:18:57,556 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:57,556 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 33: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\xd4\x82\x16\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xce\x93\x00\x00\x01\x94\x12\xc8\xce\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nABI,26200.0,4500,100.0,0.0,0.0,0....')])])
21:18:57,559 <kafka.protocol.parser>[DEBUG]: Received correlation id: 33
21:18:57,559 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:57,560 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 33 (3.0014514923095703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=31, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:57,560 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=31, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:57,560 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 31 log start offset 0 and error None.
21:18:57,561 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:57,954 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ABR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:57,956 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ABR,13750.0,100,750.0,0.1,0.0,0.0,False,0.0,09:28:35' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:57,956 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:57,956 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:57,956 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:57,957 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:57,957 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:57,957 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xdb\xe82\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd0$\x00\x00\x01\x94\x12\xc8\xd0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hABR,13750.0,100,750.0,0.1,0.0,0.0...')])])}
21:18:57,957 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xdb\xe82\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd0$\x00\x00\x01\x94\x12\xc8\xd0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hABR,13750.0,100,750.0,0.1,0.0,0.0...')])])
21:18:57,957 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xdb\xe82\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd0$\x00\x00\x01\x94\x12\xc8\xd0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hABR,13750.0,100,750.0,0.1,0.0,0.0...')])])
21:18:57,957 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 34: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xdb\xe82\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd0$\x00\x00\x01\x94\x12\xc8\xd0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hABR,13750.0,100,750.0,0.1,0.0,0.0...')])])
21:18:57,960 <kafka.protocol.parser>[DEBUG]: Received correlation id: 34
21:18:57,960 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:57,960 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 34 (2.9926300048828125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=32, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:57,961 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=32, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:57,961 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 32 log start offset 0 and error None.
21:18:57,962 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:58,865 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ABS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:58,867 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ABS,4980.0,20100,-80.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:58,867 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:58,867 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:58,867 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:58,868 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:58,868 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}\x0b\x1b=\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd3\xb3\x00\x00\x01\x94\x12\xc8\xd3\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jABS,4980.0,20100,-80.0,0.0,0.0,0....')])])}
21:18:58,868 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}\x0b\x1b=\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd3\xb3\x00\x00\x01\x94\x12\xc8\xd3\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jABS,4980.0,20100,-80.0,0.0,0.0,0....')])])
21:18:58,868 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}\x0b\x1b=\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd3\xb3\x00\x00\x01\x94\x12\xc8\xd3\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jABS,4980.0,20100,-80.0,0.0,0.0,0....')])])
21:18:58,868 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:58,868 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 35: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}\x0b\x1b=\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd3\xb3\x00\x00\x01\x94\x12\xc8\xd3\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jABS,4980.0,20100,-80.0,0.0,0.0,0....')])])
21:18:58,871 <kafka.protocol.parser>[DEBUG]: Received correlation id: 35
21:18:58,871 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:58,871 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 35 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=33, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:58,872 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=33, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:58,872 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 33 log start offset 0 and error None.
21:18:58,873 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:18:59,559 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ABT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:18:59,562 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ABT,39000.0,2200,-150.0,0.0,0.0,0.0,False,-2850.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:18:59,562 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:18:59,562 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:18:59,562 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:18:59,563 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:18:59,563 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02sjT\x12\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd6j\x00\x00\x01\x94\x12\xc8\xd6j\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tABT,39000.0,2200,-150.0,0.0,0.0,...')])])}
21:18:59,563 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02sjT\x12\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd6j\x00\x00\x01\x94\x12\xc8\xd6j\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tABT,39000.0,2200,-150.0,0.0,0.0,...')])])
21:18:59,563 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02sjT\x12\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd6j\x00\x00\x01\x94\x12\xc8\xd6j\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tABT,39000.0,2200,-150.0,0.0,0.0,...')])])
21:18:59,563 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:18:59,563 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 36: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02sjT\x12\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd6j\x00\x00\x01\x94\x12\xc8\xd6j\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tABT,39000.0,2200,-150.0,0.0,0.0,...')])])
21:18:59,583 <kafka.protocol.parser>[DEBUG]: Received correlation id: 36
21:18:59,584 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:18:59,584 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 36 (21.454811096191406 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=34, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:59,584 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=34, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:18:59,584 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 34 log start offset 0 and error None.
21:18:59,586 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:00,305 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:00,306 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ACB,25550.0,718500,0.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:00,307 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:00,307 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:00,307 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:00,307 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:00,307 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd4"\x7f\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd9S\x00\x00\x01\x94\x12\xc8\xd9S\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACB,25550.0,718500,0.0,0.0,0.0,0....')])])}
21:19:00,307 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd4"\x7f\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd9S\x00\x00\x01\x94\x12\xc8\xd9S\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACB,25550.0,718500,0.0,0.0,0.0,0....')])])
21:19:00,307 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:00,308 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd4"\x7f\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd9S\x00\x00\x01\x94\x12\xc8\xd9S\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACB,25550.0,718500,0.0,0.0,0.0,0....')])])
21:19:00,308 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 37: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd4"\x7f\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xd9S\x00\x00\x01\x94\x12\xc8\xd9S\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACB,25550.0,718500,0.0,0.0,0.0,0....')])])
21:19:00,311 <kafka.protocol.parser>[DEBUG]: Received correlation id: 37
21:19:00,311 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:00,311 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 37 (2.997875213623047 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=35, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:00,311 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=35, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:00,312 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 35 log start offset 0 and error None.
21:19:00,313 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:01,661 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:01,663 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ACC,14450.0,5000,100.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:01,664 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:01,664 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:01,664 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:01,664 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:01,664 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x92I\xa6V\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xde\xa0\x00\x00\x01\x94\x12\xc8\xde\xa0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACC,14450.0,5000,100.0,0.0,0.0,0....')])])}
21:19:01,664 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x92I\xa6V\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xde\xa0\x00\x00\x01\x94\x12\xc8\xde\xa0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACC,14450.0,5000,100.0,0.0,0.0,0....')])])
21:19:01,664 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x92I\xa6V\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xde\xa0\x00\x00\x01\x94\x12\xc8\xde\xa0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACC,14450.0,5000,100.0,0.0,0.0,0....')])])
21:19:01,665 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:01,665 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 38: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x92I\xa6V\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xde\xa0\x00\x00\x01\x94\x12\xc8\xde\xa0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACC,14450.0,5000,100.0,0.0,0.0,0....')])])
21:19:01,668 <kafka.protocol.parser>[DEBUG]: Received correlation id: 38
21:19:01,668 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:01,668 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 38 (3.0088424682617188 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=36, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:01,668 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=36, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:01,668 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 36 log start offset 0 and error None.
21:19:01,669 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:02,46 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:02,48 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ACE,36200.0,2700,300.0,0.0,0.0,0.0,False,0.0,13:12:21' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:02,48 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:02,48 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:02,48 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:02,48 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:02,48 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xadvcn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe0 \x00\x00\x01\x94\x12\xc8\xe0 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jACE,36200.0,2700,300.0,0.0,0.0,0....')])])}
21:19:02,48 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xadvcn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe0 \x00\x00\x01\x94\x12\xc8\xe0 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jACE,36200.0,2700,300.0,0.0,0.0,0....')])])
21:19:02,49 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xadvcn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe0 \x00\x00\x01\x94\x12\xc8\xe0 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jACE,36200.0,2700,300.0,0.0,0.0,0....')])])
21:19:02,49 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:02,49 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 39: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xadvcn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe0 \x00\x00\x01\x94\x12\xc8\xe0 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jACE,36200.0,2700,300.0,0.0,0.0,0....')])])
21:19:02,52 <kafka.protocol.parser>[DEBUG]: Received correlation id: 39
21:19:02,52 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:02,52 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 39 (2.954721450805664 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=37, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:02,52 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=37, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:02,52 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 37 log start offset 0 and error None.
21:19:02,53 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:03,510 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:03,512 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ACL,11900.0,200,0.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:03,513 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:03,513 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:03,513 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:03,513 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:03,513 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:03,513 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd0\xf0oN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe5\xd9\x00\x00\x01\x94\x12\xc8\xe5\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACL,11900.0,200,0.0,0.0,0.0,0.0,F...')])])}
21:19:03,513 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd0\xf0oN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe5\xd9\x00\x00\x01\x94\x12\xc8\xe5\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACL,11900.0,200,0.0,0.0,0.0,0.0,F...')])])
21:19:03,514 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd0\xf0oN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe5\xd9\x00\x00\x01\x94\x12\xc8\xe5\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACL,11900.0,200,0.0,0.0,0.0,0.0,F...')])])
21:19:03,514 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 40: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd0\xf0oN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xe5\xd9\x00\x00\x01\x94\x12\xc8\xe5\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACL,11900.0,200,0.0,0.0,0.0,0.0,F...')])])
21:19:03,516 <kafka.protocol.parser>[DEBUG]: Received correlation id: 40
21:19:03,517 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:03,517 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 40 (2.9969215393066406 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=38, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:03,517 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=38, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:03,517 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 38 log start offset 0 and error None.
21:19:03,518 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:05,301 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:05,390 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ACM,700.0,5700,100.0,0.2,0.0,0.0,False,0.0,14:59:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:05,391 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:05,391 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:05,391 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:05,391 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:05,391 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc0u\xa6B\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xed/\x00\x00\x01\x94\x12\xc8\xed/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACM,700.0,5700,100.0,0.2,0.0,0.0,...')])])}
21:19:05,391 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc0u\xa6B\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xed/\x00\x00\x01\x94\x12\xc8\xed/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACM,700.0,5700,100.0,0.2,0.0,0.0,...')])])
21:19:05,391 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc0u\xa6B\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xed/\x00\x00\x01\x94\x12\xc8\xed/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACM,700.0,5700,100.0,0.2,0.0,0.0,...')])])
21:19:05,392 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 41: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc0u\xa6B\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xed/\x00\x00\x01\x94\x12\xc8\xed/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fACM,700.0,5700,100.0,0.2,0.0,0.0,...')])])
21:19:05,392 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:05,394 <kafka.protocol.parser>[DEBUG]: Received correlation id: 41
21:19:05,394 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:05,395 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 41 (3.001689910888672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=39, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:05,395 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=39, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:05,395 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 39 log start offset 0 and error None.
21:19:05,396 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:05,771 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:05,773 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:07,693 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:07,695 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ACV,124500.0,20000,600.0,0.0,0.0,0.0,True,0.0,14:59:59' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:07,695 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:07,695 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:07,696 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:07,696 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:07,696 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:07,696 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa2<\xb8^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xf6/\x00\x00\x01\x94\x12\xc8\xf6/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACV,124500.0,20000,600.0,0.0,0.0,...')])])}
21:19:07,696 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa2<\xb8^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xf6/\x00\x00\x01\x94\x12\xc8\xf6/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACV,124500.0,20000,600.0,0.0,0.0,...')])])
21:19:07,697 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa2<\xb8^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xf6/\x00\x00\x01\x94\x12\xc8\xf6/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACV,124500.0,20000,600.0,0.0,0.0,...')])])
21:19:07,697 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 42: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa2<\xb8^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xf6/\x00\x00\x01\x94\x12\xc8\xf6/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lACV,124500.0,20000,600.0,0.0,0.0,...')])])
21:19:07,699 <kafka.protocol.parser>[DEBUG]: Received correlation id: 42
21:19:07,699 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:07,699 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 42 (2.7191638946533203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=40, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:07,700 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=40, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:07,700 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 40 log start offset 0 and error None.
21:19:07,701 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:08,76 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ADC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:08,78 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:09,47 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ADP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:09,49 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ADP,29000.0,100,500.0,0.0,0.0,0.0,False,500.0,13:00:07' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:09,49 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:09,50 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:09,50 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:09,50 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:09,50 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05\x17\xed\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfby\x00\x00\x01\x94\x12\xc8\xfby\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lADP,29000.0,100,500.0,0.0,0.0,0.0...')])])}
21:19:09,50 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05\x17\xed\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfby\x00\x00\x01\x94\x12\xc8\xfby\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lADP,29000.0,100,500.0,0.0,0.0,0.0...')])])
21:19:09,50 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05\x17\xed\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfby\x00\x00\x01\x94\x12\xc8\xfby\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lADP,29000.0,100,500.0,0.0,0.0,0.0...')])])
21:19:09,50 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:09,51 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 43: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05\x17\xed\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfby\x00\x00\x01\x94\x12\xc8\xfby\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lADP,29000.0,100,500.0,0.0,0.0,0.0...')])])
21:19:09,53 <kafka.protocol.parser>[DEBUG]: Received correlation id: 43
21:19:09,53 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:09,53 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 43 (2.0008087158203125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=41, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:09,53 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=41, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:09,54 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 41 log start offset 0 and error None.
21:19:09,55 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:09,343 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AFX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:09,346 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AFX,7700.0,6400,0.0,0.0,0.0,0.0,False,0.0,14:54:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:09,346 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:09,346 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:09,346 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:09,346 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:09,347 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7s7\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfc\xa2\x00\x00\x01\x94\x12\xc8\xfc\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAFX,7700.0,6400,0.0,0.0,0.0,0.0,F...')])])}
21:19:09,347 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:09,347 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7s7\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfc\xa2\x00\x00\x01\x94\x12\xc8\xfc\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAFX,7700.0,6400,0.0,0.0,0.0,0.0,F...')])])
21:19:09,347 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7s7\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfc\xa2\x00\x00\x01\x94\x12\xc8\xfc\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAFX,7700.0,6400,0.0,0.0,0.0,0.0,F...')])])
21:19:09,347 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 44: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7s7\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc8\xfc\xa2\x00\x00\x01\x94\x12\xc8\xfc\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAFX,7700.0,6400,0.0,0.0,0.0,0.0,F...')])])
21:19:09,359 <kafka.protocol.parser>[DEBUG]: Received correlation id: 44
21:19:09,359 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:09,359 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 44 (12.000799179077148 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=42, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:09,359 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=42, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:09,360 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 42 log start offset 0 and error None.
21:19:09,361 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:12,456 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AGF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:12,458 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AGF,3000.0,1000,200.0,0.1,0.0,0.0,False,0.0,13:06:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:12,458 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:12,458 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:12,458 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:12,458 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\r8{\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x08\xca\x00\x00\x01\x94\x12\xc9\x08\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGF,3000.0,1000,200.0,0.1,0.0,0.0...')])])}
21:19:12,459 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\r8{\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x08\xca\x00\x00\x01\x94\x12\xc9\x08\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGF,3000.0,1000,200.0,0.1,0.0,0.0...')])])
21:19:12,459 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:12,459 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\r8{\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x08\xca\x00\x00\x01\x94\x12\xc9\x08\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGF,3000.0,1000,200.0,0.1,0.0,0.0...')])])
21:19:12,459 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 45: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\r8{\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x08\xca\x00\x00\x01\x94\x12\xc9\x08\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGF,3000.0,1000,200.0,0.1,0.0,0.0...')])])
21:19:12,459 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:12,462 <kafka.protocol.parser>[DEBUG]: Received correlation id: 45
21:19:12,462 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:12,462 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 45 (3.401517868041992 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=43, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:12,462 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=43, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:12,462 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 43 log start offset 0 and error None.
21:19:12,464 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:12,853 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CKA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:12,855 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CKA,43600.0,300,0.0,0.0,0.0,0.0,False,100.0,14:58:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:12,855 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:12,855 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:12,855 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:12,855 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:12,856 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb7\x9bK\xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\nW\x00\x00\x01\x94\x12\xc9\nW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCKA,43600.0,300,0.0,0.0,0.0,0.0,F...')])])}
21:19:12,856 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb7\x9bK\xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\nW\x00\x00\x01\x94\x12\xc9\nW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCKA,43600.0,300,0.0,0.0,0.0,0.0,F...')])])
21:19:12,856 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb7\x9bK\xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\nW\x00\x00\x01\x94\x12\xc9\nW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCKA,43600.0,300,0.0,0.0,0.0,0.0,F...')])])
21:19:12,856 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:12,856 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 46: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb7\x9bK\xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\nW\x00\x00\x01\x94\x12\xc9\nW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCKA,43600.0,300,0.0,0.0,0.0,0.0,F...')])])
21:19:12,859 <kafka.protocol.parser>[DEBUG]: Received correlation id: 46
21:19:12,859 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:12,859 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 46 (3.001689910888672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=44, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:12,860 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=44, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:12,860 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 44 log start offset 0 and error None.
21:19:12,861 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:13,167 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AGP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:13,169 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AGP,38800.0,100,0.0,0.0,0.0,0.0,False,0.0,10:03:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:13,169 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:13,169 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:13,169 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:13,170 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:13,170 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xafO\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x0b\x91\x00\x00\x01\x94\x12\xc9\x0b\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGP,38800.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:19:13,170 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xafO\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x0b\x91\x00\x00\x01\x94\x12\xc9\x0b\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGP,38800.0,100,0.0,0.0,0.0,0.0,F...')])])
21:19:13,170 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xafO\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x0b\x91\x00\x00\x01\x94\x12\xc9\x0b\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGP,38800.0,100,0.0,0.0,0.0,0.0,F...')])])
21:19:13,170 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 47: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xafO\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x0b\x91\x00\x00\x01\x94\x12\xc9\x0b\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGP,38800.0,100,0.0,0.0,0.0,0.0,F...')])])
21:19:13,170 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:13,174 <kafka.protocol.parser>[DEBUG]: Received correlation id: 47
21:19:13,174 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:13,174 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 47 (3.247976303100586 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=45, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:13,174 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=45, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:13,174 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 45 log start offset 0 and error None.
21:19:13,176 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:14,658 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AGM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:14,661 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AGM,3340.0,1700,-10.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:14,661 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:14,661 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:14,661 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:14,662 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:14,662 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf1\xd6\xdb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x11e\x00\x00\x01\x94\x12\xc9\x11e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGM,3340.0,1700,-10.0,0.0,0.0,0.0...')])])}
21:19:14,662 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf1\xd6\xdb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x11e\x00\x00\x01\x94\x12\xc9\x11e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGM,3340.0,1700,-10.0,0.0,0.0,0.0...')])])
21:19:14,662 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf1\xd6\xdb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x11e\x00\x00\x01\x94\x12\xc9\x11e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGM,3340.0,1700,-10.0,0.0,0.0,0.0...')])])
21:19:14,662 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:14,662 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 48: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf1\xd6\xdb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x11e\x00\x00\x01\x94\x12\xc9\x11e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hAGM,3340.0,1700,-10.0,0.0,0.0,0.0...')])])
21:19:14,665 <kafka.protocol.parser>[DEBUG]: Received correlation id: 48
21:19:14,665 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:14,665 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 48 (2.9718875885009766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=46, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:14,665 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=46, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:14,665 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 46 log start offset 0 and error None.
21:19:14,667 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:15,365 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CAG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:15,368 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CAG,7900.0,200,0.0,0.0,0.0,0.0,False,200.0,14:45:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:15,368 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:15,368 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:15,369 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:15,369 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:15,369 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:15,369 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcaK5g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x14(\x00\x00\x01\x94\x12\xc9\x14(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCAG,7900.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:19:15,369 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcaK5g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x14(\x00\x00\x01\x94\x12\xc9\x14(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCAG,7900.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:19:15,369 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcaK5g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x14(\x00\x00\x01\x94\x12\xc9\x14(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCAG,7900.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:19:15,370 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 49: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xcaK5g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x14(\x00\x00\x01\x94\x12\xc9\x14(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCAG,7900.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:19:15,372 <kafka.protocol.parser>[DEBUG]: Received correlation id: 49
21:19:15,373 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:15,373 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 49 (3.0007362365722656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=47, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:15,373 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=47, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:15,373 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 47 log start offset 0 and error None.
21:19:15,375 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:15,719 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LTG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:15,721 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LTG,7500.0,10000,0.0,0.0,0.0,0.0,False,0.0,14:59:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:15,721 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:15,721 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:15,721 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:15,722 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:15,722 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x18Q\xad\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x15\x89\x00\x00\x01\x94\x12\xc9\x15\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTG,7500.0,10000,0.0,0.0,0.0,0.0,...')])])}
21:19:15,722 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x18Q\xad\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x15\x89\x00\x00\x01\x94\x12\xc9\x15\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTG,7500.0,10000,0.0,0.0,0.0,0.0,...')])])
21:19:15,722 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x18Q\xad\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x15\x89\x00\x00\x01\x94\x12\xc9\x15\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTG,7500.0,10000,0.0,0.0,0.0,0.0,...')])])
21:19:15,722 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:15,722 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 50: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x18Q\xad\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x15\x89\x00\x00\x01\x94\x12\xc9\x15\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTG,7500.0,10000,0.0,0.0,0.0,0.0,...')])])
21:19:15,725 <kafka.protocol.parser>[DEBUG]: Received correlation id: 50
21:19:15,725 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:15,726 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 50 (3.000497817993164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=48, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:15,726 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=48, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:15,726 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 48 log start offset 0 and error None.
21:19:15,728 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:16,173 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AGR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:16,175 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AGR,17100.0,29200,0.0,0.0,0.0,0.0,True,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:16,175 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:16,175 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:16,175 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:16,176 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:16,176 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:16,177 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd8\xb1\xa0M\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x17O\x00\x00\x01\x94\x12\xc9\x17O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAGR,17100.0,29200,0.0,0.0,0.0,0.0...')])])}
21:19:16,177 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd8\xb1\xa0M\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x17O\x00\x00\x01\x94\x12\xc9\x17O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAGR,17100.0,29200,0.0,0.0,0.0,0.0...')])])
21:19:16,177 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd8\xb1\xa0M\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x17O\x00\x00\x01\x94\x12\xc9\x17O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAGR,17100.0,29200,0.0,0.0,0.0,0.0...')])])
21:19:16,178 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 51: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd8\xb1\xa0M\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x17O\x00\x00\x01\x94\x12\xc9\x17O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAGR,17100.0,29200,0.0,0.0,0.0,0.0...')])])
21:19:16,180 <kafka.protocol.parser>[DEBUG]: Received correlation id: 51
21:19:16,180 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:16,180 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 51 (2.0296573638916016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=49, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:16,181 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=49, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:16,181 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 49 log start offset 0 and error None.
21:19:16,182 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:16,445 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AGG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:16,447 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AGG,15800.0,13800,-250.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:16,447 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:16,447 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:16,448 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:16,448 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:16,448 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xd7\x05N\xc6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x18_\x00\x00\x01\x94\x12\xc9\x18_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAGG,15800.0,13800,-250.0,0.0,0.0,...')])])}
21:19:16,448 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xd7\x05N\xc6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x18_\x00\x00\x01\x94\x12\xc9\x18_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAGG,15800.0,13800,-250.0,0.0,0.0,...')])])
21:19:16,448 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xd7\x05N\xc6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x18_\x00\x00\x01\x94\x12\xc9\x18_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAGG,15800.0,13800,-250.0,0.0,0.0,...')])])
21:19:16,448 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:16,448 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 52: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xd7\x05N\xc6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x18_\x00\x00\x01\x94\x12\xc9\x18_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAGG,15800.0,13800,-250.0,0.0,0.0,...')])])
21:19:16,451 <kafka.protocol.parser>[DEBUG]: Received correlation id: 52
21:19:16,452 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:16,452 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 52 (2.9685497283935547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=50, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:16,452 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=50, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:16,452 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 50 log start offset 0 and error None.
21:19:16,453 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:16,735 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AGX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:18,32 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AGX,74100.0,200,0.0,0.0,0.0,0.0,False,0.0,09:07:48' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:18,32 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:18,32 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:18,32 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:18,33 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:18,33 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:18,33 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xed\xb8\x96.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1e\x90\x00\x00\x01\x94\x12\xc9\x1e\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGX,74100.0,200,0.0,0.0,0.0,0.0,F...')])])}
21:19:18,33 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xed\xb8\x96.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1e\x90\x00\x00\x01\x94\x12\xc9\x1e\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGX,74100.0,200,0.0,0.0,0.0,0.0,F...')])])
21:19:18,33 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xed\xb8\x96.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1e\x90\x00\x00\x01\x94\x12\xc9\x1e\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGX,74100.0,200,0.0,0.0,0.0,0.0,F...')])])
21:19:18,33 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 53: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xed\xb8\x96.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1e\x90\x00\x00\x01\x94\x12\xc9\x1e\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAGX,74100.0,200,0.0,0.0,0.0,0.0,F...')])])
21:19:18,36 <kafka.protocol.parser>[DEBUG]: Received correlation id: 53
21:19:18,36 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:18,36 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 53 (3.0002593994140625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=51, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:18,36 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=51, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:18,37 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 51 log start offset 0 and error None.
21:19:18,38 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:18,345 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AG1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:18,347 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AG1,11500.0,11500,-1200.0,-0.1,0.0,0.0,False,0.0,14:27:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:18,347 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:18,347 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:18,347 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:18,348 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:18,348 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x10\xaa\xa5\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1f\xcb\x00\x00\x01\x94\x12\xc9\x1f\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rAG1,11500.0,11500,-1200.0,-0.1,0....')])])}
21:19:18,348 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x10\xaa\xa5\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1f\xcb\x00\x00\x01\x94\x12\xc9\x1f\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rAG1,11500.0,11500,-1200.0,-0.1,0....')])])
21:19:18,348 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:18,348 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x10\xaa\xa5\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1f\xcb\x00\x00\x01\x94\x12\xc9\x1f\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rAG1,11500.0,11500,-1200.0,-0.1,0....')])])
21:19:18,348 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 54: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x10\xaa\xa5\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x1f\xcb\x00\x00\x01\x94\x12\xc9\x1f\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rAG1,11500.0,11500,-1200.0,-0.1,0....')])])
21:19:18,351 <kafka.protocol.parser>[DEBUG]: Received correlation id: 54
21:19:18,351 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:18,351 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 54 (2.317667007446289 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=52, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:18,351 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=52, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:18,353 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 52 log start offset 0 and error None.
21:19:18,353 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:18,949 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AGE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:18,951 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:19,270 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ALT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:19,272 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ALT,11900.0,100,-300.0,0.0,0.0,0.0,False,0.0,14:03:21' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:19,272 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:19,273 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:19,273 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:19,273 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:19,273 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfd\xf3)\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9#h\x00\x00\x01\x94\x12\xc9#h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALT,11900.0,100,-300.0,0.0,0.0,0....')])])}
21:19:19,273 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfd\xf3)\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9#h\x00\x00\x01\x94\x12\xc9#h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALT,11900.0,100,-300.0,0.0,0.0,0....')])])
21:19:19,273 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfd\xf3)\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9#h\x00\x00\x01\x94\x12\xc9#h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALT,11900.0,100,-300.0,0.0,0.0,0....')])])
21:19:19,273 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:19,274 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 55: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfd\xf3)\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9#h\x00\x00\x01\x94\x12\xc9#h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALT,11900.0,100,-300.0,0.0,0.0,0....')])])
21:19:19,277 <kafka.protocol.parser>[DEBUG]: Received correlation id: 55
21:19:19,277 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:19,277 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 55 (3.0074119567871094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=53, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:19,277 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=53, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:19,277 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 53 log start offset 0 and error None.
21:19:19,278 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:19,604 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ALV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:19,607 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ALV,6500.0,200,200.0,0.0,0.0,0.0,False,100.0,14:41:59' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:19,607 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:19,607 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:19,607 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:19,607 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:19,607 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9a\xce\xcdh\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9$\xb7\x00\x00\x01\x94\x12\xc9$\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALV,6500.0,200,200.0,0.0,0.0,0.0,...')])])}
21:19:19,607 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9a\xce\xcdh\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9$\xb7\x00\x00\x01\x94\x12\xc9$\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALV,6500.0,200,200.0,0.0,0.0,0.0,...')])])
21:19:19,608 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9a\xce\xcdh\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9$\xb7\x00\x00\x01\x94\x12\xc9$\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALV,6500.0,200,200.0,0.0,0.0,0.0,...')])])
21:19:19,608 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 56: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9a\xce\xcdh\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9$\xb7\x00\x00\x01\x94\x12\xc9$\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jALV,6500.0,200,200.0,0.0,0.0,0.0,...')])])
21:19:19,608 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:19,611 <kafka.protocol.parser>[DEBUG]: Received correlation id: 56
21:19:19,611 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:19,611 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 56 (2.9616355895996094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=54, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:19,611 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=54, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:19,611 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 54 log start offset 0 and error None.
21:19:19,613 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:20,661 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:20,663 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:21,388 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AMD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:21,390 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:21,660 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AME/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:22,32 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:23,430 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AMP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:23,432 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AMP,14300.0,900,0.0,0.0,0.0,0.0,False,0.0,14:57:39' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:23,432 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:23,432 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:23,432 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:23,433 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:23,433 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x1ds\x0e\xd5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc93\xa8\x00\x00\x01\x94\x12\xc93\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAMP,14300.0,900,0.0,0.0,0.0,0.0,F...')])])}
21:19:23,433 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x1ds\x0e\xd5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc93\xa8\x00\x00\x01\x94\x12\xc93\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAMP,14300.0,900,0.0,0.0,0.0,0.0,F...')])])
21:19:23,433 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x1ds\x0e\xd5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc93\xa8\x00\x00\x01\x94\x12\xc93\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAMP,14300.0,900,0.0,0.0,0.0,0.0,F...')])])
21:19:23,433 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:23,433 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 57: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x1ds\x0e\xd5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc93\xa8\x00\x00\x01\x94\x12\xc93\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dAMP,14300.0,900,0.0,0.0,0.0,0.0,F...')])])
21:19:23,436 <kafka.protocol.parser>[DEBUG]: Received correlation id: 57
21:19:23,436 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:23,436 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 57 (2.084493637084961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=55, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:23,436 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=55, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:23,436 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 55 log start offset 0 and error None.
21:19:23,438 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:24,931 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AMV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:24,933 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AMV,1500.0,17200,0.0,0.0,0.0,0.0,False,0.0,14:45:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:24,933 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:24,933 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:24,933 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:24,934 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:24,934 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02z\xe1.\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc99\x85\x00\x00\x01\x94\x12\xc99\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAMV,1500.0,17200,0.0,0.0,0.0,0.0,...')])])}
21:19:24,934 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02z\xe1.\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc99\x85\x00\x00\x01\x94\x12\xc99\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAMV,1500.0,17200,0.0,0.0,0.0,0.0,...')])])
21:19:24,934 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02z\xe1.\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc99\x85\x00\x00\x01\x94\x12\xc99\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAMV,1500.0,17200,0.0,0.0,0.0,0.0,...')])])
21:19:24,934 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 58: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02z\xe1.\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc99\x85\x00\x00\x01\x94\x12\xc99\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fAMV,1500.0,17200,0.0,0.0,0.0,0.0,...')])])
21:19:24,935 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:24,937 <kafka.protocol.parser>[DEBUG]: Received correlation id: 58
21:19:24,937 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:24,937 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 58 (3.3011436462402344 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=56, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:24,937 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=56, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:24,938 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 56 log start offset 0 and error None.
21:19:24,939 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:25,242 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ACG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:25,244 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ACG,42200.0,600,-50.0,0.0,0.0,0.0,False,0.0,14:08:25' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:25,245 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:25,245 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:25,245 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:25,245 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:25,245 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x91bA\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9:\xbd\x00\x00\x01\x94\x12\xc9:\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACG,42200.0,600,-50.0,0.0,0.0,0.0...')])])}
21:19:25,245 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:25,245 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x91bA\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9:\xbd\x00\x00\x01\x94\x12\xc9:\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACG,42200.0,600,-50.0,0.0,0.0,0.0...')])])
21:19:25,246 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x91bA\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9:\xbd\x00\x00\x01\x94\x12\xc9:\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACG,42200.0,600,-50.0,0.0,0.0,0.0...')])])
21:19:25,246 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 59: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x91bA\x80\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9:\xbd\x00\x00\x01\x94\x12\xc9:\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hACG,42200.0,600,-50.0,0.0,0.0,0.0...')])])
21:19:25,248 <kafka.protocol.parser>[DEBUG]: Received correlation id: 59
21:19:25,249 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:25,249 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 59 (3.000497817993164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=57, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:25,249 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=57, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:25,249 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 57 log start offset 0 and error None.
21:19:25,250 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:26,581 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ANT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:26,582 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ANT,19600.0,200,-200.0,0.0,0.0,0.0,False,500.0,14:59:57' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:26,582 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:26,582 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:26,583 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:26,583 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:26,583 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\x13\xd3\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9?\xf6\x00\x00\x01\x94\x12\xc9?\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nANT,19600.0,200,-200.0,0.0,0.0,0....')])])}
21:19:26,583 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\x13\xd3\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9?\xf6\x00\x00\x01\x94\x12\xc9?\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nANT,19600.0,200,-200.0,0.0,0.0,0....')])])
21:19:26,583 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\x13\xd3\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9?\xf6\x00\x00\x01\x94\x12\xc9?\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nANT,19600.0,200,-200.0,0.0,0.0,0....')])])
21:19:26,583 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:26,584 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 60: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\x13\xd3\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9?\xf6\x00\x00\x01\x94\x12\xc9?\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nANT,19600.0,200,-200.0,0.0,0.0,0....')])])
21:19:26,586 <kafka.protocol.parser>[DEBUG]: Received correlation id: 60
21:19:26,586 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:26,586 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 60 (2.001523971557617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=58, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:26,586 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=58, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:26,587 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 58 log start offset 0 and error None.
21:19:26,588 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:29,295 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ANV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:29,382 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ANV,19800.0,69400,-450.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,382 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,382 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:29,382 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:29,383 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:29,383 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xab\x9fhH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9J\xe6\x00\x00\x01\x94\x12\xc9J\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rANV,19800.0,69400,-450.0,0.0,0.0,...')])])}
21:19:29,383 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xab\x9fhH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9J\xe6\x00\x00\x01\x94\x12\xc9J\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rANV,19800.0,69400,-450.0,0.0,0.0,...')])])
21:19:29,384 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xab\x9fhH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9J\xe6\x00\x00\x01\x94\x12\xc9J\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rANV,19800.0,69400,-450.0,0.0,0.0,...')])])
21:19:29,384 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 61: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xab\x9fhH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9J\xe6\x00\x00\x01\x94\x12\xc9J\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rANV,19800.0,69400,-450.0,0.0,0.0,...')])])
21:19:29,384 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,386 <kafka.protocol.parser>[DEBUG]: Received correlation id: 61
21:19:29,386 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:29,387 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 61 (2.7375221252441406 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=59, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:29,387 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=59, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:29,387 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 59 log start offset 0 and error None.
21:19:29,388 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:29,672 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/APC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:29,674 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'APC,6500.0,200,0.0,0.0,0.0,0.0,False,0.0,13:46:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,674 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,674 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:29,674 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:29,674 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:29,674 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb2^"\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9L\n\x00\x00\x01\x94\x12\xc9L\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bAPC,6500.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:19:29,675 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb2^"\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9L\n\x00\x00\x01\x94\x12\xc9L\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bAPC,6500.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:19:29,675 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb2^"\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9L\n\x00\x00\x01\x94\x12\xc9L\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bAPC,6500.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:19:29,675 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 62: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb2^"\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9L\n\x00\x00\x01\x94\x12\xc9L\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bAPC,6500.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:19:29,675 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,678 <kafka.protocol.parser>[DEBUG]: Received correlation id: 62
21:19:29,678 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:29,678 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 62 (3.008127212524414 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=60, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:29,678 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=60, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:29,678 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 60 log start offset 0 and error None.
21:19:29,679 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:29,987 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/APF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:29,989 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'APF,50700.0,100,100.0,0.0,0.0,0.0,False,-100.0,14:54:48' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,989 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,989 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:29,989 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:29,990 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:29,990 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd4\xcc\xc5}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9ME\x00\x00\x01\x94\x12\xc9ME\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPF,50700.0,100,100.0,0.0,0.0,0.0...')])])}
21:19:29,990 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd4\xcc\xc5}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9ME\x00\x00\x01\x94\x12\xc9ME\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPF,50700.0,100,100.0,0.0,0.0,0.0...')])])
21:19:29,990 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd4\xcc\xc5}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9ME\x00\x00\x01\x94\x12\xc9ME\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPF,50700.0,100,100.0,0.0,0.0,0.0...')])])
21:19:29,990 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 63: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd4\xcc\xc5}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9ME\x00\x00\x01\x94\x12\xc9ME\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPF,50700.0,100,100.0,0.0,0.0,0.0...')])])
21:19:29,990 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:29,993 <kafka.protocol.parser>[DEBUG]: Received correlation id: 63
21:19:29,993 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:29,994 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 63 (4.021883010864258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=61, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:29,994 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=61, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:29,994 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 61 log start offset 0 and error None.
21:19:29,995 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:30,524 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/APG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:30,527 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'APG,7190.0,22100,430.0,0.1,0.0,0.0,False,140.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:30,527 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:30,527 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:30,527 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:30,527 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:30,527 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe3Q\xefG\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9O_\x00\x00\x01\x94\x12\xc9O_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPG,7190.0,22100,430.0,0.1,0.0,0....')])])}
21:19:30,528 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe3Q\xefG\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9O_\x00\x00\x01\x94\x12\xc9O_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPG,7190.0,22100,430.0,0.1,0.0,0....')])])
21:19:30,528 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe3Q\xefG\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9O_\x00\x00\x01\x94\x12\xc9O_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPG,7190.0,22100,430.0,0.1,0.0,0....')])])
21:19:30,528 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:30,528 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 64: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe3Q\xefG\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9O_\x00\x00\x01\x94\x12\xc9O_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nAPG,7190.0,22100,430.0,0.1,0.0,0....')])])
21:19:30,531 <kafka.protocol.parser>[DEBUG]: Received correlation id: 64
21:19:30,531 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:30,531 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 64 (2.9931068420410156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=62, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:30,531 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=62, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:30,531 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 62 log start offset 0 and error None.
21:19:30,533 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:31,126 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/APH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:31,128 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'APH,7070.0,80800,110.0,0.0,0.0,0.0,True,-10.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:31,128 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:31,128 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:31,128 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:31,128 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:31,128 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02m%\xc3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Q\xb8\x00\x00\x01\x94\x12\xc9Q\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAPH,7070.0,80800,110.0,0.0,0.0,0....')])])}
21:19:31,129 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02m%\xc3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Q\xb8\x00\x00\x01\x94\x12\xc9Q\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAPH,7070.0,80800,110.0,0.0,0.0,0....')])])
21:19:31,129 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:31,129 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02m%\xc3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Q\xb8\x00\x00\x01\x94\x12\xc9Q\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAPH,7070.0,80800,110.0,0.0,0.0,0....')])])
21:19:31,129 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 65: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02m%\xc3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Q\xb8\x00\x00\x01\x94\x12\xc9Q\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAPH,7070.0,80800,110.0,0.0,0.0,0....')])])
21:19:31,132 <kafka.protocol.parser>[DEBUG]: Received correlation id: 65
21:19:31,132 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:31,132 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 65 (3.000497817993164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=63, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:31,132 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=63, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:31,132 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 63 log start offset 0 and error None.
21:19:31,134 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:31,419 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/API/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:31,421 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'API,7900.0,26000,-300.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:31,421 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:31,421 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:31,422 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:31,422 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:31,422 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02(\x14\xf8e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9R\xdd\x00\x00\x01\x94\x12\xc9R\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPI,7900.0,26000,-300.0,0.0,0.0,0...')])])}
21:19:31,422 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02(\x14\xf8e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9R\xdd\x00\x00\x01\x94\x12\xc9R\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPI,7900.0,26000,-300.0,0.0,0.0,0...')])])
21:19:31,422 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02(\x14\xf8e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9R\xdd\x00\x00\x01\x94\x12\xc9R\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPI,7900.0,26000,-300.0,0.0,0.0,0...')])])
21:19:31,422 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:31,422 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 66: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02(\x14\xf8e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9R\xdd\x00\x00\x01\x94\x12\xc9R\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPI,7900.0,26000,-300.0,0.0,0.0,0...')])])
21:19:31,425 <kafka.protocol.parser>[DEBUG]: Received correlation id: 66
21:19:31,426 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:31,426 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 66 (2.9926300048828125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=64, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:31,426 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=64, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:31,426 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 64 log start offset 0 and error None.
21:19:31,428 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:31,721 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/APL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:31,723 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:32,859 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/APP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:32,861 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'APP,8000.0,100,600.0,0.1,0.0,0.0,False,500.0,14:59:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:32,861 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:32,861 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:32,861 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:32,862 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:32,862 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83i\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9X}\x00\x00\x01\x94\x12\xc9X}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPP,8000.0,100,600.0,0.1,0.0,0.0,...')])])}
21:19:32,862 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83i\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9X}\x00\x00\x01\x94\x12\xc9X}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPP,8000.0,100,600.0,0.1,0.0,0.0,...')])])
21:19:32,862 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:32,862 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83i\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9X}\x00\x00\x01\x94\x12\xc9X}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPP,8000.0,100,600.0,0.1,0.0,0.0,...')])])
21:19:32,863 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 67: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83i\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9X}\x00\x00\x01\x94\x12\xc9X}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAPP,8000.0,100,600.0,0.1,0.0,0.0,...')])])
21:19:32,865 <kafka.protocol.parser>[DEBUG]: Received correlation id: 67
21:19:32,865 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:32,866 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 67 (2.987384796142578 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=65, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:32,866 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=65, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:32,866 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 65 log start offset 0 and error None.
21:19:32,867 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:33,145 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/APS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:33,147 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'APS,6500.0,92500,-100.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:33,147 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:33,147 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:33,147 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:33,148 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:33,148 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02&xA\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Y\x9b\x00\x00\x01\x94\x12\xc9Y\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAPS,6500.0,92500,-100.0,0.0,0.0,0...')])])}
21:19:33,148 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02&xA\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Y\x9b\x00\x00\x01\x94\x12\xc9Y\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAPS,6500.0,92500,-100.0,0.0,0.0,0...')])])
21:19:33,148 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02&xA\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Y\x9b\x00\x00\x01\x94\x12\xc9Y\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAPS,6500.0,92500,-100.0,0.0,0.0,0...')])])
21:19:33,148 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:33,148 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 68: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02&xA\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Y\x9b\x00\x00\x01\x94\x12\xc9Y\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pAPS,6500.0,92500,-100.0,0.0,0.0,0...')])])
21:19:33,151 <kafka.protocol.parser>[DEBUG]: Received correlation id: 68
21:19:33,151 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:33,151 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 68 (3.008127212524414 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=66, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:33,151 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=66, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:33,151 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 66 log start offset 0 and error None.
21:19:33,153 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:33,467 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HII/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:33,469 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HII,4500.0,600,0.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:33,469 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:33,469 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:33,469 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:33,469 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:33,470 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xfc\x08\xf3w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Z\xdd\x00\x00\x01\x94\x12\xc9Z\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHII,4500.0,600,0.0,0.0,0.0,0.0,Fa...')])])}
21:19:33,470 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xfc\x08\xf3w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Z\xdd\x00\x00\x01\x94\x12\xc9Z\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHII,4500.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:19:33,470 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xfc\x08\xf3w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Z\xdd\x00\x00\x01\x94\x12\xc9Z\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHII,4500.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:19:33,470 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:33,470 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 69: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xfc\x08\xf3w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9Z\xdd\x00\x00\x01\x94\x12\xc9Z\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHII,4500.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:19:33,473 <kafka.protocol.parser>[DEBUG]: Received correlation id: 69
21:19:33,473 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:33,473 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 69 (3.3423900604248047 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=67, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:33,473 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=67, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:33,473 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 67 log start offset 0 and error None.
21:19:33,474 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:33,784 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ARM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:33,785 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:34,701 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ASA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:34,703 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:35,276 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/A32/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:35,278 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:35,707 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ASG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:35,709 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ASG,18350.0,500,-100.0,0.0,0.0,0.0,False,0.0,13:00:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:35,709 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:35,709 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:35,709 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:35,710 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:35,710 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:35,710 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9\xbcy\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9c\x9d\x00\x00\x01\x94\x12\xc9c\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jASG,18350.0,500,-100.0,0.0,0.0,0....')])])}
21:19:35,710 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9\xbcy\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9c\x9d\x00\x00\x01\x94\x12\xc9c\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jASG,18350.0,500,-100.0,0.0,0.0,0....')])])
21:19:35,710 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9\xbcy\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9c\x9d\x00\x00\x01\x94\x12\xc9c\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jASG,18350.0,500,-100.0,0.0,0.0,0....')])])
21:19:35,710 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 70: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9\xbcy\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9c\x9d\x00\x00\x01\x94\x12\xc9c\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jASG,18350.0,500,-100.0,0.0,0.0,0....')])])
21:19:35,713 <kafka.protocol.parser>[DEBUG]: Received correlation id: 70
21:19:35,713 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:35,713 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 70 (1.9993782043457031 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=68, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:35,713 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=68, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:35,714 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 68 log start offset 0 and error None.
21:19:35,715 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:36,26 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ASM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:36,28 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ASM,8750.0,23700,-100.0,0.0,0.0,0.0,True,-10.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:36,28 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:36,28 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:36,28 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:36,29 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:36,29 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:36,29 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02p\x8d!+\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9d\xdc\x00\x00\x01\x94\x12\xc9d\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nASM,8750.0,23700,-100.0,0.0,0.0,0...')])])}
21:19:36,29 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02p\x8d!+\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9d\xdc\x00\x00\x01\x94\x12\xc9d\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nASM,8750.0,23700,-100.0,0.0,0.0,0...')])])
21:19:36,29 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02p\x8d!+\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9d\xdc\x00\x00\x01\x94\x12\xc9d\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nASM,8750.0,23700,-100.0,0.0,0.0,0...')])])
21:19:36,29 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 71: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02p\x8d!+\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9d\xdc\x00\x00\x01\x94\x12\xc9d\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nASM,8750.0,23700,-100.0,0.0,0.0,0...')])])
21:19:36,32 <kafka.protocol.parser>[DEBUG]: Received correlation id: 71
21:19:36,32 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:36,32 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 71 (2.0024776458740234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=69, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:36,32 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=69, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:36,33 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 69 log start offset 0 and error None.
21:19:36,34 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:36,669 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ASP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:36,671 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ASP,4000.0,100,-70.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:36,671 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:36,671 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:36,671 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:36,672 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:36,672 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb1\xe3\xf1\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9g_\x00\x00\x01\x94\x12\xc9g_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fASP,4000.0,100,-70.0,0.0,0.0,0.0,...')])])}
21:19:36,672 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb1\xe3\xf1\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9g_\x00\x00\x01\x94\x12\xc9g_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fASP,4000.0,100,-70.0,0.0,0.0,0.0,...')])])
21:19:36,672 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:36,672 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb1\xe3\xf1\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9g_\x00\x00\x01\x94\x12\xc9g_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fASP,4000.0,100,-70.0,0.0,0.0,0.0,...')])])
21:19:36,672 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 72: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb1\xe3\xf1\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9g_\x00\x00\x01\x94\x12\xc9g_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fASP,4000.0,100,-70.0,0.0,0.0,0.0,...')])])
21:19:36,675 <kafka.protocol.parser>[DEBUG]: Received correlation id: 72
21:19:36,675 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:36,675 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 72 (3.004312515258789 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=70, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:36,676 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=70, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:36,676 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 70 log start offset 0 and error None.
21:19:36,677 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:37,546 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ATA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:37,548 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ATA,500.0,10000,0.0,0.0,0.0,0.0,False,-100.0,14:46:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:37,548 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:37,548 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:37,548 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:37,549 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:37,549 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>JM\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9j\xcc\x00\x00\x01\x94\x12\xc9j\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jATA,500.0,10000,0.0,0.0,0.0,0.0,F...')])])}
21:19:37,549 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>JM\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9j\xcc\x00\x00\x01\x94\x12\xc9j\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jATA,500.0,10000,0.0,0.0,0.0,0.0,F...')])])
21:19:37,549 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>JM\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9j\xcc\x00\x00\x01\x94\x12\xc9j\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jATA,500.0,10000,0.0,0.0,0.0,0.0,F...')])])
21:19:37,549 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 73: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>JM\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9j\xcc\x00\x00\x01\x94\x12\xc9j\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jATA,500.0,10000,0.0,0.0,0.0,0.0,F...')])])
21:19:37,549 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:37,552 <kafka.protocol.parser>[DEBUG]: Received correlation id: 73
21:19:37,552 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:37,552 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 73 (2.9692649841308594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=71, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:37,552 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=71, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:37,552 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 71 log start offset 0 and error None.
21:19:37,553 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:38,58 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ATG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:38,60 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ATG,2100.0,1500,100.0,0.1,0.0,0.0,False,0.0,14:25:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,60 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,60 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:38,60 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:38,60 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:38,61 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,61 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\xa5uK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9l\xcc\x00\x00\x01\x94\x12\xc9l\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATG,2100.0,1500,100.0,0.1,0.0,0.0...')])])}
21:19:38,61 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\xa5uK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9l\xcc\x00\x00\x01\x94\x12\xc9l\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATG,2100.0,1500,100.0,0.1,0.0,0.0...')])])
21:19:38,61 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\xa5uK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9l\xcc\x00\x00\x01\x94\x12\xc9l\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATG,2100.0,1500,100.0,0.1,0.0,0.0...')])])
21:19:38,61 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 74: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\xa5uK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9l\xcc\x00\x00\x01\x94\x12\xc9l\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATG,2100.0,1500,100.0,0.1,0.0,0.0...')])])
21:19:38,64 <kafka.protocol.parser>[DEBUG]: Received correlation id: 74
21:19:38,64 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:38,64 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 74 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=72, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:38,64 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=72, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:38,64 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 72 log start offset 0 and error None.
21:19:38,65 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:38,358 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ATB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:38,360 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ATB,600.0,30000,100.0,0.2,0.0,0.0,False,0.0,09:52:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,361 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,361 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:38,361 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:38,361 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:38,361 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa8hc#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9m\xf9\x00\x00\x01\x94\x12\xc9m\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATB,600.0,30000,100.0,0.2,0.0,0.0...')])])}
21:19:38,362 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa8hc#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9m\xf9\x00\x00\x01\x94\x12\xc9m\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATB,600.0,30000,100.0,0.2,0.0,0.0...')])])
21:19:38,362 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,362 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa8hc#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9m\xf9\x00\x00\x01\x94\x12\xc9m\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATB,600.0,30000,100.0,0.2,0.0,0.0...')])])
21:19:38,362 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 75: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa8hc#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9m\xf9\x00\x00\x01\x94\x12\xc9m\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hATB,600.0,30000,100.0,0.2,0.0,0.0...')])])
21:19:38,365 <kafka.protocol.parser>[DEBUG]: Received correlation id: 75
21:19:38,365 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:38,365 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 75 (3.000497817993164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=73, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:38,365 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=73, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:38,365 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 73 log start offset 0 and error None.
21:19:38,367 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:38,679 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ATS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:38,682 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ATS,13800.0,100,800.0,0.1,0.0,0.0,False,1800.0,13:22:55' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,682 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,682 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:38,682 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:38,683 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:38,683 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa0\x91m^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9o:\x00\x00\x01\x94\x12\xc9o:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nATS,13800.0,100,800.0,0.1,0.0,0.0...')])])}
21:19:38,683 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa0\x91m^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9o:\x00\x00\x01\x94\x12\xc9o:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nATS,13800.0,100,800.0,0.1,0.0,0.0...')])])
21:19:38,683 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa0\x91m^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9o:\x00\x00\x01\x94\x12\xc9o:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nATS,13800.0,100,800.0,0.1,0.0,0.0...')])])
21:19:38,684 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 76: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa0\x91m^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9o:\x00\x00\x01\x94\x12\xc9o:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nATS,13800.0,100,800.0,0.1,0.0,0.0...')])])
21:19:38,684 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:38,687 <kafka.protocol.parser>[DEBUG]: Received correlation id: 76
21:19:38,687 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:38,687 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 76 (3.01361083984375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=74, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:38,687 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=74, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:38,687 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 74 log start offset 0 and error None.
21:19:38,689 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:39,11 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AVF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:39,13 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:39,308 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AVC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:39,310 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AVC,54400.0,1000,300.0,0.0,0.0,0.0,False,0.0,13:40:08' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:39,310 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:39,310 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:39,312 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:39,312 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb9\x90\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9q\xae\x00\x00\x01\x94\x12\xc9q\xae\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAVC,54400.0,1000,300.0,0.0,0.0,0....')])])}
21:19:39,312 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:39,312 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb9\x90\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9q\xae\x00\x00\x01\x94\x12\xc9q\xae\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAVC,54400.0,1000,300.0,0.0,0.0,0....')])])
21:19:39,312 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb9\x90\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9q\xae\x00\x00\x01\x94\x12\xc9q\xae\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAVC,54400.0,1000,300.0,0.0,0.0,0....')])])
21:19:39,312 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:39,312 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 77: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb9\x90\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9q\xae\x00\x00\x01\x94\x12\xc9q\xae\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAVC,54400.0,1000,300.0,0.0,0.0,0....')])])
21:19:39,315 <kafka.protocol.parser>[DEBUG]: Received correlation id: 77
21:19:39,315 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:39,315 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 77 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=75, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:39,315 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=75, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:39,315 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 75 log start offset 0 and error None.
21:19:39,317 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:42,270 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/B82/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:42,272 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:43,223 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BAF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:43,225 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BAF,28450.0,238600,1650.0,0.1,0.0,0.0,True,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:43,225 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:43,225 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:43,226 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:43,226 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:43,226 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdb\x07g\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x80\xf9\x00\x00\x01\x94\x12\xc9\x80\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rBAF,28450.0,238600,1650.0,0.1,0.0...')])])}
21:19:43,226 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:43,226 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdb\x07g\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x80\xf9\x00\x00\x01\x94\x12\xc9\x80\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rBAF,28450.0,238600,1650.0,0.1,0.0...')])])
21:19:43,227 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdb\x07g\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x80\xf9\x00\x00\x01\x94\x12\xc9\x80\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rBAF,28450.0,238600,1650.0,0.1,0.0...')])])
21:19:43,227 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 78: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdb\x07g\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x80\xf9\x00\x00\x01\x94\x12\xc9\x80\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rBAF,28450.0,238600,1650.0,0.1,0.0...')])])
21:19:43,230 <kafka.protocol.parser>[DEBUG]: Received correlation id: 78
21:19:43,231 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:43,231 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 78 (3.674745559692383 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=76, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:43,231 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=76, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:43,231 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 76 log start offset 0 and error None.
21:19:43,233 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:43,528 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BAL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:43,531 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BAL,8600.0,100,-100.0,0.0,0.0,0.0,False,-100.0,14:18:55' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:43,532 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:43,532 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:43,532 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:43,532 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:43,533 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:43,536 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x14\xcb\x006\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x82,\x00\x00\x01\x94\x12\xc9\x82,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBAL,8600.0,100,-100.0,0.0,0.0,0.0...')])])}
21:19:43,537 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x14\xcb\x006\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x82,\x00\x00\x01\x94\x12\xc9\x82,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBAL,8600.0,100,-100.0,0.0,0.0,0.0...')])])
21:19:43,537 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x14\xcb\x006\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x82,\x00\x00\x01\x94\x12\xc9\x82,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBAL,8600.0,100,-100.0,0.0,0.0,0.0...')])])
21:19:43,537 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 79: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x14\xcb\x006\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x82,\x00\x00\x01\x94\x12\xc9\x82,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBAL,8600.0,100,-100.0,0.0,0.0,0.0...')])])
21:19:43,549 <kafka.protocol.parser>[DEBUG]: Received correlation id: 79
21:19:43,549 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:43,549 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 79 (12.001276016235352 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=77, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:43,549 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=77, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:43,549 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 77 log start offset 0 and error None.
21:19:43,551 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:43,890 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:43,893 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:44,218 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BNA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:44,627 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BNA,10900.0,39000,300.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:44,627 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:44,627 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:44,627 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:44,627 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:44,628 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:44,628 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02 \x06P\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x86s\x00\x00\x01\x94\x12\xc9\x86s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBNA,10900.0,39000,300.0,0.0,0.0,0...')])])}
21:19:44,628 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02 \x06P\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x86s\x00\x00\x01\x94\x12\xc9\x86s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBNA,10900.0,39000,300.0,0.0,0.0,0...')])])
21:19:44,628 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02 \x06P\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x86s\x00\x00\x01\x94\x12\xc9\x86s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBNA,10900.0,39000,300.0,0.0,0.0,0...')])])
21:19:44,628 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 80: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02 \x06P\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x86s\x00\x00\x01\x94\x12\xc9\x86s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBNA,10900.0,39000,300.0,0.0,0.0,0...')])])
21:19:44,631 <kafka.protocol.parser>[DEBUG]: Received correlation id: 80
21:19:44,631 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:44,631 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 80 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=78, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:44,631 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=78, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:44,631 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 78 log start offset 0 and error None.
21:19:44,633 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:45,4 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BRR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:45,6 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BRR,19000.0,500,0.0,0.0,0.0,0.0,False,-900.0,09:22:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:45,6 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:45,6 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:45,6 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:45,7 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:45,7 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb&\x8e\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x87\xee\x00\x00\x01\x94\x12\xc9\x87\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRR,19000.0,500,0.0,0.0,0.0,0.0,F...')])])}
21:19:45,7 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb&\x8e\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x87\xee\x00\x00\x01\x94\x12\xc9\x87\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRR,19000.0,500,0.0,0.0,0.0,0.0,F...')])])
21:19:45,7 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb&\x8e\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x87\xee\x00\x00\x01\x94\x12\xc9\x87\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRR,19000.0,500,0.0,0.0,0.0,0.0,F...')])])
21:19:45,7 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:45,7 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 81: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb&\x8e\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x87\xee\x00\x00\x01\x94\x12\xc9\x87\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRR,19000.0,500,0.0,0.0,0.0,0.0,F...')])])
21:19:45,10 <kafka.protocol.parser>[DEBUG]: Received correlation id: 81
21:19:45,10 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:45,10 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 81 (2.037525177001953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=79, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:45,11 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=79, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:45,11 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 79 log start offset 0 and error None.
21:19:45,12 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:49,329 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:49,332 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:49,654 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BLW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:49,656 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:50,599 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:50,602 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BBC,53700.0,100,2500.0,0.0,0.0,0.0,False,0.0,13:22:28' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:50,602 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:50,603 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:50,603 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:50,603 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:50,603 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:50,604 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x902\xb9G\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9d\xca\x00\x00\x01\x94\x12\xc9\x9d\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBBC,53700.0,100,2500.0,0.0,0.0,0....')])])}
21:19:50,604 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x902\xb9G\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9d\xca\x00\x00\x01\x94\x12\xc9\x9d\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBBC,53700.0,100,2500.0,0.0,0.0,0....')])])
21:19:50,604 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x902\xb9G\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9d\xca\x00\x00\x01\x94\x12\xc9\x9d\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBBC,53700.0,100,2500.0,0.0,0.0,0....')])])
21:19:50,604 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 82: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x902\xb9G\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9d\xca\x00\x00\x01\x94\x12\xc9\x9d\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBBC,53700.0,100,2500.0,0.0,0.0,0....')])])
21:19:50,609 <kafka.protocol.parser>[DEBUG]: Received correlation id: 82
21:19:50,609 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:50,609 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 82 (3.9587020874023438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=80, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:50,610 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=80, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:50,610 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 80 log start offset 0 and error None.
21:19:50,612 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:50,910 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VLB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:50,912 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'VLB,42600.0,300,-1300.0,0.0,0.0,0.0,False,100.0,14:59:33' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:50,912 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:50,912 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:50,912 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:50,912 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:50,913 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02s\xbf\xec\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVLB,42600.0,300,-1300.0,0.0,0.0,0...')])])}
21:19:50,913 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02s\xbf\xec\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVLB,42600.0,300,-1300.0,0.0,0.0,0...')])])
21:19:50,913 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:50,913 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02s\xbf\xec\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVLB,42600.0,300,-1300.0,0.0,0.0,0...')])])
21:19:50,913 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 83: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02s\xbf\xec\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\x00\x00\x01\x94\x12\xc9\x9f\x00\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pVLB,42600.0,300,-1300.0,0.0,0.0,0...')])])
21:19:50,916 <kafka.protocol.parser>[DEBUG]: Received correlation id: 83
21:19:50,916 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:50,916 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 83 (2.999544143676758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=81, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:50,916 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=81, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:50,916 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 81 log start offset 0 and error None.
21:19:50,917 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:51,209 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BBH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:51,211 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:51,790 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BBS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:51,792 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BBS,10200.0,200,100.0,0.0,0.0,0.0,False,0.0,14:10:17' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:51,793 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:51,793 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:51,793 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:51,794 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8bb\xcc\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xa2q\x00\x00\x01\x94\x12\xc9\xa2q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBBS,10200.0,200,100.0,0.0,0.0,0.0...')])])}
21:19:51,794 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8bb\xcc\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xa2q\x00\x00\x01\x94\x12\xc9\xa2q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBBS,10200.0,200,100.0,0.0,0.0,0.0...')])])
21:19:51,794 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:51,794 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8bb\xcc\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xa2q\x00\x00\x01\x94\x12\xc9\xa2q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBBS,10200.0,200,100.0,0.0,0.0,0.0...')])])
21:19:51,794 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 84: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x8bb\xcc\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xa2q\x00\x00\x01\x94\x12\xc9\xa2q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBBS,10200.0,200,100.0,0.0,0.0,0.0...')])])
21:19:51,795 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:51,796 <kafka.protocol.parser>[DEBUG]: Received correlation id: 84
21:19:51,797 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:51,797 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 84 (3.6597251892089844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=82, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:51,797 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=82, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:51,797 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 82 log start offset 0 and error None.
21:19:51,798 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:52,192 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BBT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:52,194 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:53,591 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:53,593 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:53,902 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:54,288 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BCC,7300.0,2100,-200.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,289 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,289 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:54,289 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:54,290 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:54,290 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,290 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0bT\x13\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xac1\x00\x00\x01\x94\x12\xc9\xac1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCC,7300.0,2100,-200.0,0.0,0.0,0....')])])}
21:19:54,290 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0bT\x13\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xac1\x00\x00\x01\x94\x12\xc9\xac1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCC,7300.0,2100,-200.0,0.0,0.0,0....')])])
21:19:54,290 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0bT\x13\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xac1\x00\x00\x01\x94\x12\xc9\xac1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCC,7300.0,2100,-200.0,0.0,0.0,0....')])])
21:19:54,290 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 85: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0bT\x13\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xac1\x00\x00\x01\x94\x12\xc9\xac1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCC,7300.0,2100,-200.0,0.0,0.0,0....')])])
21:19:54,294 <kafka.protocol.parser>[DEBUG]: Received correlation id: 85
21:19:54,294 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:54,294 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 85 (3.996133804321289 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=83, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:54,295 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=83, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:54,295 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 83 log start offset 0 and error None.
21:19:54,297 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:54,624 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:54,627 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BCE,8180.0,31100,180.0,0.0,0.0,0.0,True,-10.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,627 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,627 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:54,627 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:54,627 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:54,627 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02@\xca\xedK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xad\x83\x00\x00\x01\x94\x12\xc9\xad\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBCE,8180.0,31100,180.0,0.0,0.0,0....')])])}
21:19:54,628 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02@\xca\xedK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xad\x83\x00\x00\x01\x94\x12\xc9\xad\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBCE,8180.0,31100,180.0,0.0,0.0,0....')])])
21:19:54,628 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,628 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02@\xca\xedK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xad\x83\x00\x00\x01\x94\x12\xc9\xad\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBCE,8180.0,31100,180.0,0.0,0.0,0....')])])
21:19:54,628 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 86: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02@\xca\xedK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xad\x83\x00\x00\x01\x94\x12\xc9\xad\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBCE,8180.0,31100,180.0,0.0,0.0,0....')])])
21:19:54,631 <kafka.protocol.parser>[DEBUG]: Received correlation id: 86
21:19:54,631 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:54,631 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 86 (2.6984214782714844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=84, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:54,631 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=84, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:54,631 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 84 log start offset 0 and error None.
21:19:54,633 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:54,953 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:54,954 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BCG,6420.0,438300,-80.0,0.0,0.0,0.0,True,-30.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,954 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,955 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:54,955 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:54,955 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\xf9\xf2\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xae\xcb\x00\x00\x01\x94\x12\xc9\xae\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCG,6420.0,438300,-80.0,0.0,0.0,0...')])])}
21:19:54,955 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\xf9\xf2\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xae\xcb\x00\x00\x01\x94\x12\xc9\xae\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCG,6420.0,438300,-80.0,0.0,0.0,0...')])])
21:19:54,955 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:54,955 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\xf9\xf2\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xae\xcb\x00\x00\x01\x94\x12\xc9\xae\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCG,6420.0,438300,-80.0,0.0,0.0,0...')])])
21:19:54,956 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 87: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xd6\xf9\xf2\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xae\xcb\x00\x00\x01\x94\x12\xc9\xae\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBCG,6420.0,438300,-80.0,0.0,0.0,0...')])])
21:19:54,956 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:54,958 <kafka.protocol.parser>[DEBUG]: Received correlation id: 87
21:19:54,958 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:54,959 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 87 (2.994060516357422 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=85, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:54,959 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=85, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:54,959 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 85 log start offset 0 and error None.
21:19:54,960 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:56,532 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:56,535 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:57,816 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BDB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:57,818 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:58,475 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MVC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:58,477 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MVC,9000.0,1000,-100.0,0.0,0.0,0.0,False,0.0,14:02:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:58,477 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:58,477 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:58,477 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:58,478 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:58,478 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\xa7\xee\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xbc\x8d\x00\x00\x01\x94\x12\xc9\xbc\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMVC,9000.0,1000,-100.0,0.0,0.0,0....')])])}
21:19:58,478 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\xa7\xee\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xbc\x8d\x00\x00\x01\x94\x12\xc9\xbc\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMVC,9000.0,1000,-100.0,0.0,0.0,0....')])])
21:19:58,478 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\xa7\xee\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xbc\x8d\x00\x00\x01\x94\x12\xc9\xbc\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMVC,9000.0,1000,-100.0,0.0,0.0,0....')])])
21:19:58,478 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 88: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\xa7\xee\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xbc\x8d\x00\x00\x01\x94\x12\xc9\xbc\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMVC,9000.0,1000,-100.0,0.0,0.0,0....')])])
21:19:58,478 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:58,481 <kafka.protocol.parser>[DEBUG]: Received correlation id: 88
21:19:58,481 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:58,481 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 88 (2.9647350311279297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=86, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:58,481 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=86, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:58,481 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 86 log start offset 0 and error None.
21:19:58,482 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:59,210 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BFC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:59,610 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BFC,40200.0,61200,-450.0,0.0,0.0,0.0,True,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:59,610 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:59,610 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:59,611 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:59,611 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:59,611 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02r\xb6c\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc0\xfa\x00\x00\x01\x94\x12\xc9\xc0\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBFC,40200.0,61200,-450.0,0.0,0.0,...')])])}
21:19:59,611 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02r\xb6c\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc0\xfa\x00\x00\x01\x94\x12\xc9\xc0\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBFC,40200.0,61200,-450.0,0.0,0.0,...')])])
21:19:59,611 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02r\xb6c\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc0\xfa\x00\x00\x01\x94\x12\xc9\xc0\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBFC,40200.0,61200,-450.0,0.0,0.0,...')])])
21:19:59,611 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 89: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02r\xb6c\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc0\xfa\x00\x00\x01\x94\x12\xc9\xc0\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBFC,40200.0,61200,-450.0,0.0,0.0,...')])])
21:19:59,612 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:59,614 <kafka.protocol.parser>[DEBUG]: Received correlation id: 89
21:19:59,614 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:59,614 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 89 (2.0263195037841797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=87, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:59,615 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=87, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:59,615 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 87 log start offset 0 and error None.
21:19:59,616 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:19:59,971 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BDG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:19:59,973 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BDG,34000.0,100,-200.0,0.0,0.0,0.0,False,0.0,14:42:59' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:19:59,973 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:19:59,973 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:19:59,973 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:19:59,973 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:19:59,974 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\xa2Y\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc2e\x00\x00\x01\x94\x12\xc9\xc2e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBDG,34000.0,100,-200.0,0.0,0.0,0....')])])}
21:19:59,974 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\xa2Y\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc2e\x00\x00\x01\x94\x12\xc9\xc2e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBDG,34000.0,100,-200.0,0.0,0.0,0....')])])
21:19:59,974 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:19:59,974 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\xa2Y\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc2e\x00\x00\x01\x94\x12\xc9\xc2e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBDG,34000.0,100,-200.0,0.0,0.0,0....')])])
21:19:59,974 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 90: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\xa2Y\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc2e\x00\x00\x01\x94\x12\xc9\xc2e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBDG,34000.0,100,-200.0,0.0,0.0,0....')])])
21:19:59,977 <kafka.protocol.parser>[DEBUG]: Received correlation id: 90
21:19:59,977 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:19:59,977 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 90 (3.0062198638916016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=88, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:59,977 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=88, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:19:59,978 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 88 log start offset 0 and error None.
21:19:59,979 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:00,290 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BSA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:00,718 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BSA,22300.0,2000,-400.0,0.0,0.0,0.0,False,0.0,10:19:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:00,719 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:00,719 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:00,719 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:00,719 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:00,719 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xcaw\xe3\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc5O\x00\x00\x01\x94\x12\xc9\xc5O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBSA,22300.0,2000,-400.0,0.0,0.0,0...')])])}
21:20:00,719 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xcaw\xe3\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc5O\x00\x00\x01\x94\x12\xc9\xc5O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBSA,22300.0,2000,-400.0,0.0,0.0,0...')])])
21:20:00,720 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:00,720 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xcaw\xe3\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc5O\x00\x00\x01\x94\x12\xc9\xc5O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBSA,22300.0,2000,-400.0,0.0,0.0,0...')])])
21:20:00,720 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 91: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xcaw\xe3\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc5O\x00\x00\x01\x94\x12\xc9\xc5O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBSA,22300.0,2000,-400.0,0.0,0.0,0...')])])
21:20:00,723 <kafka.protocol.parser>[DEBUG]: Received correlation id: 91
21:20:00,723 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:00,723 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 91 (3.016948699951172 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=89, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:00,723 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=89, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:00,723 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 89 log start offset 0 and error None.
21:20:00,724 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:01,26 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PRT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:01,28 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PRT,9700.0,100,200.0,0.0,0.0,0.0,False,100.0,14:57:56' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:01,29 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:01,29 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:01,29 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:01,29 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:01,29 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1b\x83\x1bn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc6\x85\x00\x00\x01\x94\x12\xc9\xc6\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPRT,9700.0,100,200.0,0.0,0.0,0.0,...')])])}
21:20:01,29 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1b\x83\x1bn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc6\x85\x00\x00\x01\x94\x12\xc9\xc6\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPRT,9700.0,100,200.0,0.0,0.0,0.0,...')])])
21:20:01,30 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1b\x83\x1bn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc6\x85\x00\x00\x01\x94\x12\xc9\xc6\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPRT,9700.0,100,200.0,0.0,0.0,0.0,...')])])
21:20:01,30 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:01,30 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 92: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1b\x83\x1bn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc6\x85\x00\x00\x01\x94\x12\xc9\xc6\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPRT,9700.0,100,200.0,0.0,0.0,0.0,...')])])
21:20:01,32 <kafka.protocol.parser>[DEBUG]: Received correlation id: 92
21:20:01,33 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:01,33 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 92 (3.007650375366211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=90, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:01,33 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=90, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:01,33 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 90 log start offset 0 and error None.
21:20:01,34 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:01,339 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BDW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:01,341 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BDW,24600.0,100,100.0,0.0,0.0,0.0,False,0.0,13:55:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:01,341 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:01,341 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:01,342 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:01,342 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x81m7\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc7\xbd\x00\x00\x01\x94\x12\xc9\xc7\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBDW,24600.0,100,100.0,0.0,0.0,0.0...')])])}
21:20:01,342 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x81m7\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc7\xbd\x00\x00\x01\x94\x12\xc9\xc7\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBDW,24600.0,100,100.0,0.0,0.0,0.0...')])])
21:20:01,342 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x81m7\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc7\xbd\x00\x00\x01\x94\x12\xc9\xc7\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBDW,24600.0,100,100.0,0.0,0.0,0.0...')])])
21:20:01,342 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:01,342 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 93: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x81m7\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xc7\xbd\x00\x00\x01\x94\x12\xc9\xc7\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBDW,24600.0,100,100.0,0.0,0.0,0.0...')])])
21:20:01,342 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:01,345 <kafka.protocol.parser>[DEBUG]: Received correlation id: 93
21:20:01,345 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:01,345 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 93 (2.007722854614258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=91, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:01,345 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=91, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:01,345 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 91 log start offset 0 and error None.
21:20:01,347 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:01,673 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BED/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:01,675 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:02,514 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BEL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:02,516 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:02,839 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NBT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:02,842 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:04,233 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BGW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:04,234 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:04,532 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BHA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:04,534 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:04,839 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:04,841 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BHC,1700.0,1100,0.0,0.0,0.0,0.0,False,-100.0,13:32:49' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:04,841 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:04,841 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:04,841 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:04,842 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:04,842 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95f\xf53\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xd5i\x00\x00\x01\x94\x12\xc9\xd5i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBHC,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])}
21:20:04,842 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95f\xf53\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xd5i\x00\x00\x01\x94\x12\xc9\xd5i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBHC,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:20:04,842 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:04,842 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95f\xf53\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xd5i\x00\x00\x01\x94\x12\xc9\xd5i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBHC,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:20:04,843 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 94: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95f\xf53\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xd5i\x00\x00\x01\x94\x12\xc9\xd5i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBHC,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:20:04,845 <kafka.protocol.parser>[DEBUG]: Received correlation id: 94
21:20:04,845 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:04,845 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 94 (1.9943714141845703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=92, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:04,845 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=92, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:04,846 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 92 log start offset 0 and error None.
21:20:04,847 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:05,573 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BHK/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:05,655 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:06,576 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BHN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:06,578 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BHN,38400.0,100,-300.0,0.0,0.0,0.0,False,-150.0,14:10:33' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:06,578 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:06,578 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:06,578 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:06,579 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:06,579 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x95~\x0e\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xdc2\x00\x00\x01\x94\x12\xc9\xdc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBHN,38400.0,100,-300.0,0.0,0.0,0....')])])}
21:20:06,579 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:06,579 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x95~\x0e\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xdc2\x00\x00\x01\x94\x12\xc9\xdc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBHN,38400.0,100,-300.0,0.0,0.0,0....')])])
21:20:06,579 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x95~\x0e\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xdc2\x00\x00\x01\x94\x12\xc9\xdc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBHN,38400.0,100,-300.0,0.0,0.0,0....')])])
21:20:06,580 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 95: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x95~\x0e\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xdc2\x00\x00\x01\x94\x12\xc9\xdc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBHN,38400.0,100,-300.0,0.0,0.0,0....')])])
21:20:06,582 <kafka.protocol.parser>[DEBUG]: Received correlation id: 95
21:20:06,582 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:06,582 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 95 (2.000093460083008 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=93, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:06,582 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=93, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:06,583 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 93 log start offset 0 and error None.
21:20:06,584 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:09,512 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BHP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:09,514 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BHP,6500.0,100,700.0,0.1,0.0,0.0,False,0.0,14:58:51' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:09,514 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:09,515 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:09,515 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:09,515 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:09,516 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x15\xcfZ\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xe7\xab\x00\x00\x01\x94\x12\xc9\xe7\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBHP,6500.0,100,700.0,0.1,0.0,0.0,...')])])}
21:20:09,516 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x15\xcfZ\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xe7\xab\x00\x00\x01\x94\x12\xc9\xe7\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBHP,6500.0,100,700.0,0.1,0.0,0.0,...')])])
21:20:09,515 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:09,516 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x15\xcfZ\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xe7\xab\x00\x00\x01\x94\x12\xc9\xe7\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBHP,6500.0,100,700.0,0.1,0.0,0.0,...')])])
21:20:09,516 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 96: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x15\xcfZ\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xe7\xab\x00\x00\x01\x94\x12\xc9\xe7\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBHP,6500.0,100,700.0,0.1,0.0,0.0,...')])])
21:20:09,519 <kafka.protocol.parser>[DEBUG]: Received correlation id: 96
21:20:09,519 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:09,519 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 96 (2.3844242095947266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=94, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:09,519 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=94, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:09,519 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 94 log start offset 0 and error None.
21:20:09,520 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:09,909 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BHT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:09,911 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:10,331 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BIC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:10,333 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BIC,34000.0,200,0.0,0.0,0.0,0.0,False,0.0,14:05:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:10,333 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:10,333 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:10,333 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:10,334 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:10,334 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xbaOj8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xea\xdd\x00\x00\x01\x94\x12\xc9\xea\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBIC,34000.0,200,0.0,0.0,0.0,0.0,F...')])])}
21:20:10,334 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xbaOj8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xea\xdd\x00\x00\x01\x94\x12\xc9\xea\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBIC,34000.0,200,0.0,0.0,0.0,0.0,F...')])])
21:20:10,335 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xbaOj8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xea\xdd\x00\x00\x01\x94\x12\xc9\xea\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBIC,34000.0,200,0.0,0.0,0.0,0.0,F...')])])
21:20:10,335 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 97: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xbaOj8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xea\xdd\x00\x00\x01\x94\x12\xc9\xea\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBIC,34000.0,200,0.0,0.0,0.0,0.0,F...')])])
21:20:10,335 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:10,338 <kafka.protocol.parser>[DEBUG]: Received correlation id: 97
21:20:10,338 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:10,338 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 97 (2.670764923095703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=95, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:10,338 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=95, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:10,338 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 95 log start offset 0 and error None.
21:20:10,339 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:11,275 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BID/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:11,277 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BID,39150.0,498300,150.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,277 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,277 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:11,277 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:11,278 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:11,278 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022=\xfe\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xee\x8d\x00\x00\x01\x94\x12\xc9\xee\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBID,39150.0,498300,150.0,0.0,0.0,...')])])}
21:20:11,278 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,278 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022=\xfe\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xee\x8d\x00\x00\x01\x94\x12\xc9\xee\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBID,39150.0,498300,150.0,0.0,0.0,...')])])
21:20:11,278 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022=\xfe\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xee\x8d\x00\x00\x01\x94\x12\xc9\xee\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBID,39150.0,498300,150.0,0.0,0.0,...')])])
21:20:11,278 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 98: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022=\xfe\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xee\x8d\x00\x00\x01\x94\x12\xc9\xee\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBID,39150.0,498300,150.0,0.0,0.0,...')])])
21:20:11,281 <kafka.protocol.parser>[DEBUG]: Received correlation id: 98
21:20:11,281 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:11,281 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 98 (2.00653076171875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=96, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:11,281 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=96, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:11,281 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 96 log start offset 0 and error None.
21:20:11,282 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:11,599 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:11,600 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BCM,69800.0,128300,100.0,0.0,0.0,0.0,True,600.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,600 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,601 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:11,601 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:11,601 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:11,601 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02b\xa0\x15Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xef\xd1\x00\x00\x01\x94\x12\xc9\xef\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCM,69800.0,128300,100.0,0.0,0.0,...')])])}
21:20:11,601 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02b\xa0\x15Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xef\xd1\x00\x00\x01\x94\x12\xc9\xef\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCM,69800.0,128300,100.0,0.0,0.0,...')])])
21:20:11,601 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,601 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02b\xa0\x15Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xef\xd1\x00\x00\x01\x94\x12\xc9\xef\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCM,69800.0,128300,100.0,0.0,0.0,...')])])
21:20:11,602 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 99: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02b\xa0\x15Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xef\xd1\x00\x00\x01\x94\x12\xc9\xef\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBCM,69800.0,128300,100.0,0.0,0.0,...')])])
21:20:11,604 <kafka.protocol.parser>[DEBUG]: Received correlation id: 99
21:20:11,605 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:11,605 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 99 (2.9709339141845703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=97, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:11,605 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=97, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:11,605 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 97 log start offset 0 and error None.
21:20:11,606 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:11,909 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BLT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:11,911 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BLT,38400.0,200,0.0,0.0,0.0,0.0,False,-100.0,14:12:36' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,911 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,911 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:11,912 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:11,912 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:11,912 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:11,912 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02R\x81J\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf1\x07\x00\x00\x01\x94\x12\xc9\xf1\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBLT,38400.0,200,0.0,0.0,0.0,0.0,F...')])])}
21:20:11,912 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02R\x81J\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf1\x07\x00\x00\x01\x94\x12\xc9\xf1\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBLT,38400.0,200,0.0,0.0,0.0,0.0,F...')])])
21:20:11,912 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02R\x81J\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf1\x07\x00\x00\x01\x94\x12\xc9\xf1\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBLT,38400.0,200,0.0,0.0,0.0,0.0,F...')])])
21:20:11,913 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 100: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02R\x81J\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf1\x07\x00\x00\x01\x94\x12\xc9\xf1\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBLT,38400.0,200,0.0,0.0,0.0,0.0,F...')])])
21:20:11,915 <kafka.protocol.parser>[DEBUG]: Received correlation id: 100
21:20:11,915 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:11,915 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 100 (1.99127197265625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=98, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:11,915 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=98, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:11,915 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 98 log start offset 0 and error None.
21:20:11,917 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:12,496 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DBD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:12,498 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DBD,57500.0,133400,-1000.0,0.0,0.0,0.0,True,-500.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:12,498 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:12,498 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:12,499 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:12,499 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xba\xd8T\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf3R\x00\x00\x01\x94\x12\xc9\xf3R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDBD,57500.0,133400,-1000.0,0.0,0...')])])}
21:20:12,499 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xba\xd8T\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf3R\x00\x00\x01\x94\x12\xc9\xf3R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDBD,57500.0,133400,-1000.0,0.0,0...')])])
21:20:12,499 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:12,499 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xba\xd8T\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf3R\x00\x00\x01\x94\x12\xc9\xf3R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDBD,57500.0,133400,-1000.0,0.0,0...')])])
21:20:12,499 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 101: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xba\xd8T\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xf3R\x00\x00\x01\x94\x12\xc9\xf3R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDBD,57500.0,133400,-1000.0,0.0,0...')])])
21:20:12,499 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:12,501 <kafka.protocol.parser>[DEBUG]: Received correlation id: 101
21:20:12,502 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:12,502 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 101 (3.0024051666259766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=99, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:12,502 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=99, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:12,502 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 99 log start offset 0 and error None.
21:20:12,503 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:12,821 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BHG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:12,823 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:14,387 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BII/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:14,389 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BII,700.0,1000,100.0,0.2,0.0,0.0,False,0.0,14:58:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:14,389 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:14,389 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:14,389 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:14,389 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:14,390 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x89\x97z-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfa\xb5\x00\x00\x01\x94\x12\xc9\xfa\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBII,700.0,1000,100.0,0.2,0.0,0.0,...')])])}
21:20:14,390 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x89\x97z-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfa\xb5\x00\x00\x01\x94\x12\xc9\xfa\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBII,700.0,1000,100.0,0.2,0.0,0.0,...')])])
21:20:14,389 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:14,390 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x89\x97z-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfa\xb5\x00\x00\x01\x94\x12\xc9\xfa\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBII,700.0,1000,100.0,0.2,0.0,0.0,...')])])
21:20:14,390 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 102: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x89\x97z-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfa\xb5\x00\x00\x01\x94\x12\xc9\xfa\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBII,700.0,1000,100.0,0.2,0.0,0.0,...')])])
21:20:14,393 <kafka.protocol.parser>[DEBUG]: Received correlation id: 102
21:20:14,393 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:14,393 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 102 (2.995729446411133 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=100, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:14,393 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=100, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:14,393 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 100 log start offset 0 and error None.
21:20:14,395 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:14,816 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BIO/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:14,817 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:15,111 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BWE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:15,113 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BWE,47150.0,2800,-350.0,0.0,0.0,0.0,False,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,113 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,113 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:15,113 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:15,113 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:15,114 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc7\x84k\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfd\x89\x00\x00\x01\x94\x12\xc9\xfd\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBWE,47150.0,2800,-350.0,0.0,0.0,0...')])])}
21:20:15,114 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc7\x84k\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfd\x89\x00\x00\x01\x94\x12\xc9\xfd\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBWE,47150.0,2800,-350.0,0.0,0.0,0...')])])
21:20:15,114 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc7\x84k\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfd\x89\x00\x00\x01\x94\x12\xc9\xfd\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBWE,47150.0,2800,-350.0,0.0,0.0,0...')])])
21:20:15,114 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,114 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 103: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc7\x84k\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xfd\x89\x00\x00\x01\x94\x12\xc9\xfd\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBWE,47150.0,2800,-350.0,0.0,0.0,0...')])])
21:20:15,117 <kafka.protocol.parser>[DEBUG]: Received correlation id: 103
21:20:15,117 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:15,117 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 103 (2.9611587524414062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=101, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:15,117 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=101, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:15,117 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 101 log start offset 0 and error None.
21:20:15,118 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:15,529 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BKC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:15,531 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BKC,15700.0,200,300.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,532 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,532 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:15,532 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:15,532 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:15,532 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,532 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02&\x7fz\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xff,\x00\x00\x01\x94\x12\xc9\xff,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBKC,15700.0,200,300.0,0.0,0.0,0.0...')])])}
21:20:15,533 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02&\x7fz\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xff,\x00\x00\x01\x94\x12\xc9\xff,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBKC,15700.0,200,300.0,0.0,0.0,0.0...')])])
21:20:15,533 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02&\x7fz\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xff,\x00\x00\x01\x94\x12\xc9\xff,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBKC,15700.0,200,300.0,0.0,0.0,0.0...')])])
21:20:15,533 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 104: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02&\x7fz\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xc9\xff,\x00\x00\x01\x94\x12\xc9\xff,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBKC,15700.0,200,300.0,0.0,0.0,0.0...')])])
21:20:15,538 <kafka.protocol.parser>[DEBUG]: Received correlation id: 104
21:20:15,538 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:15,538 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 104 (5.0106048583984375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=102, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:15,539 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=102, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:15,539 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 102 log start offset 0 and error None.
21:20:15,541 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:15,974 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BKG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:15,976 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BKG,3350.0,2100,-40.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,976 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,976 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:15,976 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:15,977 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:15,977 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x00\xdc\xb9\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x00\xe8\x00\x00\x01\x94\x12\xca\x00\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBKG,3350.0,2100,-40.0,0.0,0.0,0.0...')])])}
21:20:15,977 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x00\xdc\xb9\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x00\xe8\x00\x00\x01\x94\x12\xca\x00\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBKG,3350.0,2100,-40.0,0.0,0.0,0.0...')])])
21:20:15,977 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:15,977 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x00\xdc\xb9\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x00\xe8\x00\x00\x01\x94\x12\xca\x00\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBKG,3350.0,2100,-40.0,0.0,0.0,0.0...')])])
21:20:15,977 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 105: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x00\xdc\xb9\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x00\xe8\x00\x00\x01\x94\x12\xca\x00\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBKG,3350.0,2100,-40.0,0.0,0.0,0.0...')])])
21:20:15,980 <kafka.protocol.parser>[DEBUG]: Received correlation id: 105
21:20:15,980 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:15,980 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 105 (1.9724369049072266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=103, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:15,980 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=103, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:15,980 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 103 log start offset 0 and error None.
21:20:15,982 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:16,772 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BLF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:16,775 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BLF,3300.0,3400,0.0,0.0,0.0,0.0,False,0.0,14:55:42' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:16,775 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:16,775 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:16,775 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:16,776 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:16,776 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5"\xbe,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x04\x07\x00\x00\x01\x94\x12\xca\x04\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBLF,3300.0,3400,0.0,0.0,0.0,0.0,F...')])])}
21:20:16,776 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5"\xbe,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x04\x07\x00\x00\x01\x94\x12\xca\x04\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBLF,3300.0,3400,0.0,0.0,0.0,0.0,F...')])])
21:20:16,776 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5"\xbe,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x04\x07\x00\x00\x01\x94\x12\xca\x04\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBLF,3300.0,3400,0.0,0.0,0.0,0.0,F...')])])
21:20:16,776 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:16,776 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 106: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5"\xbe,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x04\x07\x00\x00\x01\x94\x12\xca\x04\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBLF,3300.0,3400,0.0,0.0,0.0,0.0,F...')])])
21:20:16,779 <kafka.protocol.parser>[DEBUG]: Received correlation id: 106
21:20:16,779 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:16,779 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 106 (1.9965171813964844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=104, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:16,780 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=104, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:16,780 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 104 log start offset 0 and error None.
21:20:16,781 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:19,372 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BLI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:19,374 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BLI,10100.0,100,100.0,0.0,0.0,0.0,False,0.0,14:58:25' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:19,374 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:19,374 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:19,374 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:19,375 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02u\x0b\xdc\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x0e.\x00\x00\x01\x94\x12\xca\x0e.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBLI,10100.0,100,100.0,0.0,0.0,0.0...')])])}
21:20:19,375 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02u\x0b\xdc\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x0e.\x00\x00\x01\x94\x12\xca\x0e.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBLI,10100.0,100,100.0,0.0,0.0,0.0...')])])
21:20:19,375 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:19,375 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02u\x0b\xdc\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x0e.\x00\x00\x01\x94\x12\xca\x0e.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBLI,10100.0,100,100.0,0.0,0.0,0.0...')])])
21:20:19,375 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 107: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02u\x0b\xdc\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x0e.\x00\x00\x01\x94\x12\xca\x0e.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBLI,10100.0,100,100.0,0.0,0.0,0.0...')])])
21:20:19,376 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:19,378 <kafka.protocol.parser>[DEBUG]: Received correlation id: 107
21:20:19,378 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:19,378 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 107 (2.998828887939453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=105, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:19,378 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=105, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:19,379 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 105 log start offset 0 and error None.
21:20:19,380 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:20,797 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MH3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:20,800 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MH3,32900.0,100,-300.0,0.0,0.0,0.0,False,-100.0,14:20:37' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:20,800 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:20,800 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:20,801 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:20,803 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:20,804 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x022r\xb2D\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x13\xc0\x00\x00\x01\x94\x12\xca\x13\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMH3,32900.0,100,-300.0,0.0,0.0,0....')])])}
21:20:20,804 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:20,804 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x022r\xb2D\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x13\xc0\x00\x00\x01\x94\x12\xca\x13\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMH3,32900.0,100,-300.0,0.0,0.0,0....')])])
21:20:20,804 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x022r\xb2D\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x13\xc0\x00\x00\x01\x94\x12\xca\x13\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMH3,32900.0,100,-300.0,0.0,0.0,0....')])])
21:20:20,804 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 108: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x022r\xb2D\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x13\xc0\x00\x00\x01\x94\x12\xca\x13\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMH3,32900.0,100,-300.0,0.0,0.0,0....')])])
21:20:20,824 <kafka.protocol.parser>[DEBUG]: Received correlation id: 108
21:20:20,824 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:20,825 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 108 (19.4549560546875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=106, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:20,825 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=106, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:20,825 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 106 log start offset 0 and error None.
21:20:20,826 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:23,685 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:23,766 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DTB,13000.0,700,-400.0,0.0,0.0,0.0,False,0.0,13:03:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:23,767 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:23,767 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:23,767 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:23,767 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:23,767 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02=Q\xfaC\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x1fW\x00\x00\x01\x94\x12\xca\x1fW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTB,13000.0,700,-400.0,0.0,0.0,0....')])])}
21:20:23,767 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02=Q\xfaC\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x1fW\x00\x00\x01\x94\x12\xca\x1fW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTB,13000.0,700,-400.0,0.0,0.0,0....')])])
21:20:23,768 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02=Q\xfaC\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x1fW\x00\x00\x01\x94\x12\xca\x1fW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTB,13000.0,700,-400.0,0.0,0.0,0....')])])
21:20:23,768 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:23,768 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 109: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02=Q\xfaC\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x1fW\x00\x00\x01\x94\x12\xca\x1fW\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTB,13000.0,700,-400.0,0.0,0.0,0....')])])
21:20:23,770 <kafka.protocol.parser>[DEBUG]: Received correlation id: 109
21:20:23,771 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:23,771 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 109 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=107, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:23,771 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=107, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:23,771 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 107 log start offset 0 and error None.
21:20:23,772 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:24,779 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:24,781 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BMC,22700.0,42100,-1300.0,-0.1,0.0,0.0,True,-200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:24,781 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:24,781 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:24,781 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:24,781 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02m\x85l\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca#M\x00\x00\x01\x94\x12\xca#M\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vBMC,22700.0,42100,-1300.0,-0.1,0...')])])}
21:20:24,781 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02m\x85l\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca#M\x00\x00\x01\x94\x12\xca#M\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vBMC,22700.0,42100,-1300.0,-0.1,0...')])])
21:20:24,782 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:24,782 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02m\x85l\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca#M\x00\x00\x01\x94\x12\xca#M\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vBMC,22700.0,42100,-1300.0,-0.1,0...')])])
21:20:24,782 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 110: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02m\x85l\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca#M\x00\x00\x01\x94\x12\xca#M\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vBMC,22700.0,42100,-1300.0,-0.1,0...')])])
21:20:24,782 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:24,784 <kafka.protocol.parser>[DEBUG]: Received correlation id: 110
21:20:24,784 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:24,784 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 110 (2.0084381103515625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=108, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:24,785 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=108, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:24,785 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 108 log start offset 0 and error None.
21:20:24,786 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:25,492 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:25,494 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:25,992 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:25,995 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:26,267 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:26,269 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BMI,21450.0,600,-300.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:26,269 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:26,269 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:26,269 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:26,269 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:26,269 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\\\n<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca)\x1d\x00\x00\x01\x94\x12\xca)\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBMI,21450.0,600,-300.0,0.0,0.0,0....')])])}
21:20:26,270 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\\\n<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca)\x1d\x00\x00\x01\x94\x12\xca)\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBMI,21450.0,600,-300.0,0.0,0.0,0....')])])
21:20:26,270 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\\\n<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca)\x1d\x00\x00\x01\x94\x12\xca)\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBMI,21450.0,600,-300.0,0.0,0.0,0....')])])
21:20:26,270 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:26,270 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 111: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\\\n<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca)\x1d\x00\x00\x01\x94\x12\xca)\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBMI,21450.0,600,-300.0,0.0,0.0,0....')])])
21:20:26,273 <kafka.protocol.parser>[DEBUG]: Received correlation id: 111
21:20:26,273 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:26,273 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 111 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=109, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:26,273 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=109, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:26,273 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 109 log start offset 0 and error None.
21:20:26,275 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:29,520 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:29,522 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:29,951 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMJ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:29,953 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BMJ,11800.0,100,1300.0,0.1,0.0,0.0,False,0.0,09:07:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:29,953 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:29,953 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:29,953 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:29,953 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:29,954 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:29,954 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xee\xf4a\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca7\x81\x00\x00\x01\x94\x12\xca7\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMJ,11800.0,100,1300.0,0.1,0.0,0....')])])}
21:20:29,954 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xee\xf4a\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca7\x81\x00\x00\x01\x94\x12\xca7\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMJ,11800.0,100,1300.0,0.1,0.0,0....')])])
21:20:29,954 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xee\xf4a\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca7\x81\x00\x00\x01\x94\x12\xca7\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMJ,11800.0,100,1300.0,0.1,0.0,0....')])])
21:20:29,954 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 112: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xee\xf4a\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca7\x81\x00\x00\x01\x94\x12\xca7\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMJ,11800.0,100,1300.0,0.1,0.0,0....')])])
21:20:29,956 <kafka.protocol.parser>[DEBUG]: Received correlation id: 112
21:20:29,956 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:29,956 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 112 (2.0008087158203125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=110, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:29,956 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=110, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:29,956 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 110 log start offset 0 and error None.
21:20:29,958 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:30,797 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:30,799 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:33,280 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:33,282 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BMP,134800.0,55100,1200.0,0.0,0.0,0.0,True,2800.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:33,282 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:33,282 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:33,282 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:33,282 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:33,283 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc0\xd2\x81L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaD\x82\x00\x00\x01\x94\x12\xcaD\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tBMP,134800.0,55100,1200.0,0.0,0....')])])}
21:20:33,283 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc0\xd2\x81L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaD\x82\x00\x00\x01\x94\x12\xcaD\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tBMP,134800.0,55100,1200.0,0.0,0....')])])
21:20:33,283 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc0\xd2\x81L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaD\x82\x00\x00\x01\x94\x12\xcaD\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tBMP,134800.0,55100,1200.0,0.0,0....')])])
21:20:33,283 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:33,283 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 113: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc0\xd2\x81L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaD\x82\x00\x00\x01\x94\x12\xcaD\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tBMP,134800.0,55100,1200.0,0.0,0....')])])
21:20:33,286 <kafka.protocol.parser>[DEBUG]: Received correlation id: 113
21:20:33,286 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:33,286 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 113 (3.0057430267333984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=111, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:33,286 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=111, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:33,286 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 111 log start offset 0 and error None.
21:20:33,287 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:33,987 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BMS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:33,989 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BMS,11000.0,500,-200.0,0.0,0.0,0.0,False,0.0,14:59:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:33,989 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:33,989 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:33,989 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:33,990 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:33,990 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe2\xdf|\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaGE\x00\x00\x01\x94\x12\xcaGE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMS,11000.0,500,-200.0,0.0,0.0,0....')])])}
21:20:33,990 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe2\xdf|\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaGE\x00\x00\x01\x94\x12\xcaGE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMS,11000.0,500,-200.0,0.0,0.0,0....')])])
21:20:33,990 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe2\xdf|\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaGE\x00\x00\x01\x94\x12\xcaGE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMS,11000.0,500,-200.0,0.0,0.0,0....')])])
21:20:33,990 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 114: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe2\xdf|\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaGE\x00\x00\x01\x94\x12\xcaGE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBMS,11000.0,500,-200.0,0.0,0.0,0....')])])
21:20:33,990 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:33,993 <kafka.protocol.parser>[DEBUG]: Received correlation id: 114
21:20:33,993 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:33,993 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 114 (2.9642581939697266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=112, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:33,993 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=112, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:33,994 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 112 log start offset 0 and error None.
21:20:33,995 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:35,988 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MBN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:35,990 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:37,904 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BNW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:37,906 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:38,581 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BOT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:38,583 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BOT,2700.0,100,0.0,0.0,0.0,0.0,False,100.0,14:55:35' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:38,583 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:38,583 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:38,584 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:38,584 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:38,584 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029W\xd2\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaY7\x00\x00\x01\x94\x12\xcaY7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBOT,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:20:38,584 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029W\xd2\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaY7\x00\x00\x01\x94\x12\xcaY7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBOT,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:38,584 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029W\xd2\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaY7\x00\x00\x01\x94\x12\xcaY7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBOT,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:38,584 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:38,584 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 115: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029W\xd2\x8c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaY7\x00\x00\x01\x94\x12\xcaY7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fBOT,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:38,587 <kafka.protocol.parser>[DEBUG]: Received correlation id: 115
21:20:38,587 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:38,587 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 115 (2.0034313201904297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=113, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:38,588 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=113, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:38,588 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 113 log start offset 0 and error None.
21:20:38,589 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:39,575 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BPC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:39,577 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BPC,9900.0,100,0.0,0.0,0.0,0.0,False,0.0,13:54:39' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:39,577 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:39,577 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:39,577 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:39,578 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:39,578 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02i\xe9\xd2\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca]\x19\x00\x00\x01\x94\x12\xca]\x19\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBPC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:20:39,578 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02i\xe9\xd2\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca]\x19\x00\x00\x01\x94\x12\xca]\x19\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBPC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:39,578 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:39,578 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02i\xe9\xd2\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca]\x19\x00\x00\x01\x94\x12\xca]\x19\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBPC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:39,579 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 116: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02i\xe9\xd2\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca]\x19\x00\x00\x01\x94\x12\xca]\x19\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBPC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:39,581 <kafka.protocol.parser>[DEBUG]: Received correlation id: 116
21:20:39,581 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:39,581 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 116 (2.0096302032470703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=114, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:39,581 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=114, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:39,582 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 114 log start offset 0 and error None.
21:20:39,583 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:40,896 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BRC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:40,898 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BRC,14350.0,1800,50.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:40,899 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:40,899 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:40,899 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:40,899 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:40,899 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:40,899 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02LM\xcb\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcabC\x00\x00\x01\x94\x12\xcabC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRC,14350.0,1800,50.0,0.0,0.0,0.0...')])])}
21:20:40,900 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02LM\xcb\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcabC\x00\x00\x01\x94\x12\xcabC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRC,14350.0,1800,50.0,0.0,0.0,0.0...')])])
21:20:40,900 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02LM\xcb\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcabC\x00\x00\x01\x94\x12\xcabC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRC,14350.0,1800,50.0,0.0,0.0,0.0...')])])
21:20:40,900 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 117: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02LM\xcb\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcabC\x00\x00\x01\x94\x12\xcabC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBRC,14350.0,1800,50.0,0.0,0.0,0.0...')])])
21:20:40,902 <kafka.protocol.parser>[DEBUG]: Received correlation id: 117
21:20:40,902 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:40,902 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 117 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=115, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:40,903 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=115, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:40,903 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 115 log start offset 0 and error None.
21:20:40,904 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:41,230 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BRS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:41,232 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BRS,22000.0,300,-200.0,0.0,0.0,0.0,False,-100.0,13:00:08' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:41,232 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:41,232 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:41,232 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:41,233 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:41,233 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:41,233 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd5\xfb~\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcac\x90\x00\x00\x01\x94\x12\xcac\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBRS,22000.0,300,-200.0,0.0,0.0,0....')])])}
21:20:41,233 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd5\xfb~\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcac\x90\x00\x00\x01\x94\x12\xcac\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBRS,22000.0,300,-200.0,0.0,0.0,0....')])])
21:20:41,233 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd5\xfb~\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcac\x90\x00\x00\x01\x94\x12\xcac\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBRS,22000.0,300,-200.0,0.0,0.0,0....')])])
21:20:41,233 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 118: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd5\xfb~\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcac\x90\x00\x00\x01\x94\x12\xcac\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBRS,22000.0,300,-200.0,0.0,0.0,0....')])])
21:20:41,236 <kafka.protocol.parser>[DEBUG]: Received correlation id: 118
21:20:41,236 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:41,236 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 118 (2.008676528930664 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=116, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:41,236 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=116, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:41,236 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 116 log start offset 0 and error None.
21:20:41,238 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:41,571 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VTG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:41,573 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:44,66 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BSC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:44,68 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:44,365 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BSP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:44,367 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:44,810 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BSI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:44,812 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BSI,48600.0,54500,400.0,0.0,0.0,0.0,True,250.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:44,812 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:44,812 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:44,812 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:44,813 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:44,813 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02X\xa65\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaq\x8c\x00\x00\x01\x94\x12\xcaq\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBSI,48600.0,54500,400.0,0.0,0.0,0...')])])}
21:20:44,813 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02X\xa65\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaq\x8c\x00\x00\x01\x94\x12\xcaq\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBSI,48600.0,54500,400.0,0.0,0.0,0...')])])
21:20:44,813 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02X\xa65\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaq\x8c\x00\x00\x01\x94\x12\xcaq\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBSI,48600.0,54500,400.0,0.0,0.0,0...')])])
21:20:44,813 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:44,813 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 119: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02X\xa65\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcaq\x8c\x00\x00\x01\x94\x12\xcaq\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nBSI,48600.0,54500,400.0,0.0,0.0,0...')])])
21:20:44,816 <kafka.protocol.parser>[DEBUG]: Received correlation id: 119
21:20:44,816 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:44,816 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 119 (1.9817352294921875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=117, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:44,816 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=117, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:44,816 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 117 log start offset 0 and error None.
21:20:44,817 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:45,571 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BSR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:46,42 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BSR,22300.0,100,-400.0,0.0,0.0,0.0,False,0.0,14:59:57' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:46,42 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:46,42 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:46,43 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:46,43 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc\x15%$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcavZ\x00\x00\x01\x94\x12\xcavZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBSR,22300.0,100,-400.0,0.0,0.0,0....')])])}
21:20:46,43 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:46,43 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc\x15%$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcavZ\x00\x00\x01\x94\x12\xcavZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBSR,22300.0,100,-400.0,0.0,0.0,0....')])])
21:20:46,43 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc\x15%$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcavZ\x00\x00\x01\x94\x12\xcavZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBSR,22300.0,100,-400.0,0.0,0.0,0....')])])
21:20:46,43 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:46,43 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 120: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc\x15%$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcavZ\x00\x00\x01\x94\x12\xcavZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBSR,22300.0,100,-400.0,0.0,0.0,0....')])])
21:20:46,46 <kafka.protocol.parser>[DEBUG]: Received correlation id: 120
21:20:46,46 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:46,46 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 120 (2.7370452880859375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=118, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:46,46 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=118, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:46,47 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 118 log start offset 0 and error None.
21:20:46,48 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:48,906 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BST/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:48,997 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BST,14800.0,100,200.0,0.0,0.0,0.0,False,0.0,14:06:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:48,997 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:48,998 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:48,998 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:48,998 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:48,998 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02(\xbfH\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x81\xe6\x00\x00\x01\x94\x12\xca\x81\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBST,14800.0,100,200.0,0.0,0.0,0.0...')])])}
21:20:48,998 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02(\xbfH\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x81\xe6\x00\x00\x01\x94\x12\xca\x81\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBST,14800.0,100,200.0,0.0,0.0,0.0...')])])
21:20:48,998 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:48,999 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02(\xbfH\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x81\xe6\x00\x00\x01\x94\x12\xca\x81\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBST,14800.0,100,200.0,0.0,0.0,0.0...')])])
21:20:48,999 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 121: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02(\xbfH\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x81\xe6\x00\x00\x01\x94\x12\xca\x81\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBST,14800.0,100,200.0,0.0,0.0,0.0...')])])
21:20:49,2 <kafka.protocol.parser>[DEBUG]: Received correlation id: 121
21:20:49,2 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:49,3 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 121 (3.030061721801758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=119, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:49,3 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=119, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:49,3 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 119 log start offset 0 and error None.
21:20:49,4 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:49,337 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BT6/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:49,339 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:50,632 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:50,634 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:50,969 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:50,971 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BTH,39900.0,300,4400.0,0.1,0.0,0.0,False,0.0,09:57:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:50,971 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:50,971 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:50,971 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:50,972 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:50,972 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0e\t"\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x89\x9b\x00\x00\x01\x94\x12\xca\x89\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBTH,39900.0,300,4400.0,0.1,0.0,0....')])])}
21:20:50,972 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0e\t"\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x89\x9b\x00\x00\x01\x94\x12\xca\x89\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBTH,39900.0,300,4400.0,0.1,0.0,0....')])])
21:20:50,972 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0e\t"\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x89\x9b\x00\x00\x01\x94\x12\xca\x89\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBTH,39900.0,300,4400.0,0.1,0.0,0....')])])
21:20:50,972 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 122: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0e\t"\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x89\x9b\x00\x00\x01\x94\x12\xca\x89\x9b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBTH,39900.0,300,4400.0,0.1,0.0,0....')])])
21:20:50,972 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:50,976 <kafka.protocol.parser>[DEBUG]: Received correlation id: 122
21:20:50,976 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:50,976 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 122 (3.570556640625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=120, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:50,976 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=120, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:50,976 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 120 log start offset 0 and error None.
21:20:50,977 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:51,308 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:51,310 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BTN,2700.0,100,0.0,0.0,0.0,0.0,False,-100.0,14:43:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:51,310 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:51,310 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:51,310 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:51,310 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:51,311 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xeb\xff}5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8a\xee\x00\x00\x01\x94\x12\xca\x8a\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTN,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:20:51,311 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xeb\xff}5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8a\xee\x00\x00\x01\x94\x12\xca\x8a\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTN,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:51,311 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:51,311 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xeb\xff}5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8a\xee\x00\x00\x01\x94\x12\xca\x8a\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTN,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:51,311 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 123: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xeb\xff}5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8a\xee\x00\x00\x01\x94\x12\xca\x8a\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTN,2700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:20:51,314 <kafka.protocol.parser>[DEBUG]: Received correlation id: 123
21:20:51,314 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:51,314 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 123 (3.007650375366211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=121, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:51,314 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=121, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:51,314 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 121 log start offset 0 and error None.
21:20:51,316 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:51,796 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:51,798 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BTP,12000.0,300,100.0,0.0,0.0,0.0,False,0.0,13:44:49' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:51,798 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:51,799 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:51,799 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:51,799 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:51,799 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfeE\xf4\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8c\xd6\x00\x00\x01\x94\x12\xca\x8c\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTP,12000.0,300,100.0,0.0,0.0,0.0...')])])}
21:20:51,799 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfeE\xf4\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8c\xd6\x00\x00\x01\x94\x12\xca\x8c\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTP,12000.0,300,100.0,0.0,0.0,0.0...')])])
21:20:51,799 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfeE\xf4\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8c\xd6\x00\x00\x01\x94\x12\xca\x8c\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTP,12000.0,300,100.0,0.0,0.0,0.0...')])])
21:20:51,799 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:51,800 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 124: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfeE\xf4\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x8c\xd6\x00\x00\x01\x94\x12\xca\x8c\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hBTP,12000.0,300,100.0,0.0,0.0,0.0...')])])
21:20:51,803 <kafka.protocol.parser>[DEBUG]: Received correlation id: 124
21:20:51,803 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:51,803 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 124 (2.6674270629882812 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=122, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:51,803 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=122, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:51,803 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 122 log start offset 0 and error None.
21:20:51,804 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:53,221 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:53,223 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BTS,4900.0,2000,-100.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:53,223 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:53,223 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:53,223 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:53,223 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd4\xf8\xa0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x92g\x00\x00\x01\x94\x12\xca\x92g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBTS,4900.0,2000,-100.0,0.0,0.0,0....')])])}
21:20:53,223 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:53,223 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd4\xf8\xa0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x92g\x00\x00\x01\x94\x12\xca\x92g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBTS,4900.0,2000,-100.0,0.0,0.0,0....')])])
21:20:53,224 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd4\xf8\xa0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x92g\x00\x00\x01\x94\x12\xca\x92g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBTS,4900.0,2000,-100.0,0.0,0.0,0....')])])
21:20:53,224 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 125: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xd4\xf8\xa0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\x92g\x00\x00\x01\x94\x12\xca\x92g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pBTS,4900.0,2000,-100.0,0.0,0.0,0....')])])
21:20:53,224 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:53,227 <kafka.protocol.parser>[DEBUG]: Received correlation id: 125
21:20:53,227 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:53,227 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 125 (3.025531768798828 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=123, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:53,227 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=123, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:53,227 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 123 log start offset 0 and error None.
21:20:53,229 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:53,975 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:53,977 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:54,302 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:54,304 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:54,991 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:54,993 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:55,807 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTU/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:56,209 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:58,356 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BTW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:58,358 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:58,649 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BLN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:58,651 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:58,948 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BVG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:58,950 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BVG,2200.0,200,0.0,0.0,0.0,0.0,False,0.0,14:14:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:58,950 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:58,950 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:58,950 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:58,951 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:58,951 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x92\xdd\xb4\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xa8\xc6\x00\x00\x01\x94\x12\xca\xa8\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBVG,2200.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:20:58,951 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x92\xdd\xb4\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xa8\xc6\x00\x00\x01\x94\x12\xca\xa8\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBVG,2200.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:20:58,951 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x92\xdd\xb4\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xa8\xc6\x00\x00\x01\x94\x12\xca\xa8\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBVG,2200.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:20:58,951 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 126: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x92\xdd\xb4\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xa8\xc6\x00\x00\x01\x94\x12\xca\xa8\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bBVG,2200.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:20:58,952 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:58,954 <kafka.protocol.parser>[DEBUG]: Received correlation id: 126
21:20:58,954 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:58,954 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 126 (1.9953250885009766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=124, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:58,954 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=124, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:58,955 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 124 log start offset 0 and error None.
21:20:58,956 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:20:59,267 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BVH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:20:59,268 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BVH,52300.0,28200,-300.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:20:59,269 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:20:59,269 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:20:59,269 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:20:59,269 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x1a\xeft\xb6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xaa\x05\x00\x00\x01\x94\x12\xca\xaa\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVH,52300.0,28200,-300.0,0.0,0.0,...')])])}
21:20:59,269 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x1a\xeft\xb6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xaa\x05\x00\x00\x01\x94\x12\xca\xaa\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVH,52300.0,28200,-300.0,0.0,0.0,...')])])
21:20:59,269 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:20:59,269 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x1a\xeft\xb6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xaa\x05\x00\x00\x01\x94\x12\xca\xaa\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVH,52300.0,28200,-300.0,0.0,0.0,...')])])
21:20:59,270 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 127: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x1a\xeft\xb6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xaa\x05\x00\x00\x01\x94\x12\xca\xaa\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVH,52300.0,28200,-300.0,0.0,0.0,...')])])
21:20:59,270 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:20:59,272 <kafka.protocol.parser>[DEBUG]: Received correlation id: 127
21:20:59,272 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:20:59,272 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 127 (2.007722854614258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=125, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:59,273 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=125, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:20:59,273 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 125 log start offset 0 and error None.
21:20:59,274 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:00,122 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BVN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:00,216 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:00,644 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TNH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:00,646 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'TNH,18250.0,57200,700.0,0.0,0.0,0.0,True,-100.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:00,646 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:00,647 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:00,647 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:00,647 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:00,647 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:00,647 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xde\xfaX\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xafg\x00\x00\x01\x94\x12\xca\xafg\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pTNH,18250.0,57200,700.0,0.0,0.0,0...')])])}
21:21:00,648 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xde\xfaX\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xafg\x00\x00\x01\x94\x12\xca\xafg\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pTNH,18250.0,57200,700.0,0.0,0.0,0...')])])
21:21:00,648 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xde\xfaX\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xafg\x00\x00\x01\x94\x12\xca\xafg\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pTNH,18250.0,57200,700.0,0.0,0.0,0...')])])
21:21:00,648 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 128: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xde\xfaX\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xafg\x00\x00\x01\x94\x12\xca\xafg\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pTNH,18250.0,57200,700.0,0.0,0.0,0...')])])
21:21:00,650 <kafka.protocol.parser>[DEBUG]: Received correlation id: 128
21:21:00,650 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:00,650 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 128 (2.7818679809570312 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=126, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:00,651 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=126, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:00,651 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 126 log start offset 0 and error None.
21:21:00,653 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:00,958 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BVS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:00,961 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BVS,37600.0,200,-200.0,0.0,0.0,0.0,False,0.0,14:57:29' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:00,961 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:00,961 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:00,961 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:00,961 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:00,961 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x84|l)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb0\xa1\x00\x00\x01\x94\x12\xca\xb0\xa1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBVS,37600.0,200,-200.0,0.0,0.0,0....')])])}
21:21:00,962 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x84|l)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb0\xa1\x00\x00\x01\x94\x12\xca\xb0\xa1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBVS,37600.0,200,-200.0,0.0,0.0,0....')])])
21:21:00,962 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:00,962 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x84|l)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb0\xa1\x00\x00\x01\x94\x12\xca\xb0\xa1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBVS,37600.0,200,-200.0,0.0,0.0,0....')])])
21:21:00,962 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 129: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x84|l)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb0\xa1\x00\x00\x01\x94\x12\xca\xb0\xa1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBVS,37600.0,200,-200.0,0.0,0.0,0....')])])
21:21:00,965 <kafka.protocol.parser>[DEBUG]: Received correlation id: 129
21:21:00,965 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:00,965 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 129 (3.0031204223632812 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=127, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:00,965 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=127, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:00,966 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 127 log start offset 0 and error None.
21:21:00,967 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:01,344 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BWA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:01,346 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:01,660 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BWS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:02,60 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BWS,33700.0,100,-200.0,0.0,0.0,0.0,False,0.0,14:34:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:02,60 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:02,60 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:02,60 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:02,61 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:02,61 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83\xbc\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb4\xec\x00\x00\x01\x94\x12\xca\xb4\xec\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBWS,33700.0,100,-200.0,0.0,0.0,0....')])])}
21:21:02,61 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83\xbc\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb4\xec\x00\x00\x01\x94\x12\xca\xb4\xec\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBWS,33700.0,100,-200.0,0.0,0.0,0....')])])
21:21:02,61 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83\xbc\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb4\xec\x00\x00\x01\x94\x12\xca\xb4\xec\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBWS,33700.0,100,-200.0,0.0,0.0,0....')])])
21:21:02,61 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 130: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02k\x83\xbc\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xb4\xec\x00\x00\x01\x94\x12\xca\xb4\xec\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jBWS,33700.0,100,-200.0,0.0,0.0,0....')])])
21:21:02,61 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:02,64 <kafka.protocol.parser>[DEBUG]: Received correlation id: 130
21:21:02,64 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:02,64 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 130 (2.9997825622558594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=128, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:02,64 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=128, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:02,64 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 128 log start offset 0 and error None.
21:21:02,66 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:03,382 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BXH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:03,384 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:03,867 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:03,869 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HNB,12500.0,100,-500.0,0.0,0.0,0.0,False,0.0,14:47:58' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:03,869 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:03,869 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:03,870 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:03,870 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:03,870 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:03,870 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc|A/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbb\xfd\x00\x00\x01\x94\x12\xca\xbb\xfd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNB,12500.0,100,-500.0,0.0,0.0,0....')])])}
21:21:03,870 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc|A/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbb\xfd\x00\x00\x01\x94\x12\xca\xbb\xfd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNB,12500.0,100,-500.0,0.0,0.0,0....')])])
21:21:03,871 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc|A/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbb\xfd\x00\x00\x01\x94\x12\xca\xbb\xfd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNB,12500.0,100,-500.0,0.0,0.0,0....')])])
21:21:03,871 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 131: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbc|A/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbb\xfd\x00\x00\x01\x94\x12\xca\xbb\xfd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNB,12500.0,100,-500.0,0.0,0.0,0....')])])
21:21:03,873 <kafka.protocol.parser>[DEBUG]: Received correlation id: 131
21:21:03,873 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:03,873 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 131 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=129, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:03,874 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=129, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:03,874 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 129 log start offset 0 and error None.
21:21:03,876 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:04,274 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C69/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:04,276 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'C69,6400.0,45500,-100.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:04,276 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:04,276 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:04,277 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:04,277 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:04,277 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:04,277 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02RG\xda\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbd\x94\x00\x00\x01\x94\x12\xca\xbd\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jC69,6400.0,45500,-100.0,0.0,0.0,0...')])])}
21:21:04,277 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02RG\xda\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbd\x94\x00\x00\x01\x94\x12\xca\xbd\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jC69,6400.0,45500,-100.0,0.0,0.0,0...')])])
21:21:04,278 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02RG\xda\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbd\x94\x00\x00\x01\x94\x12\xca\xbd\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jC69,6400.0,45500,-100.0,0.0,0.0,0...')])])
21:21:04,278 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 132: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02RG\xda\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xbd\x94\x00\x00\x01\x94\x12\xca\xbd\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jC69,6400.0,45500,-100.0,0.0,0.0,0...')])])
21:21:04,283 <kafka.protocol.parser>[DEBUG]: Received correlation id: 132
21:21:04,283 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:04,283 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 132 (5.00178337097168 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=130, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:04,284 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=130, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:04,284 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 130 log start offset 0 and error None.
21:21:04,285 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:08,282 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C21/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:08,284 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:08,693 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C22/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:08,696 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:09,28 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C32/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:09,30 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'C32,17200.0,1000,-50.0,0.0,0.0,0.0,False,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,31 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,31 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:09,32 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:09,32 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:09,32 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02{\xc3\x08\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd0'\x00\x00\x01\x94\x12\xca\xd0'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC32,17200.0,1000,-50.0,0.0,0.0,0....")])])}
21:21:09,32 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02{\xc3\x08\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd0'\x00\x00\x01\x94\x12\xca\xd0'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC32,17200.0,1000,-50.0,0.0,0.0,0....")])])
21:21:09,32 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,32 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02{\xc3\x08\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd0'\x00\x00\x01\x94\x12\xca\xd0'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC32,17200.0,1000,-50.0,0.0,0.0,0....")])])
21:21:09,33 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 133: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02{\xc3\x08\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd0'\x00\x00\x01\x94\x12\xca\xd0'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC32,17200.0,1000,-50.0,0.0,0.0,0....")])])
21:21:09,35 <kafka.protocol.parser>[DEBUG]: Received correlation id: 133
21:21:09,35 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:09,35 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 133 (2.438068389892578 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=131, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:09,36 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=131, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:09,36 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 131 log start offset 0 and error None.
21:21:09,37 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:09,349 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C47/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:09,351 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'C47,6100.0,200,0.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,351 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,351 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:09,351 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:09,351 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:09,352 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x0f\x13\xf1\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd1g\x00\x00\x01\x94\x12\xca\xd1g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bC47,6100.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:21:09,352 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x0f\x13\xf1\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd1g\x00\x00\x01\x94\x12\xca\xd1g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bC47,6100.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:21:09,351 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,352 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x0f\x13\xf1\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd1g\x00\x00\x01\x94\x12\xca\xd1g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bC47,6100.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:21:09,352 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 134: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x0f\x13\xf1\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd1g\x00\x00\x01\x94\x12\xca\xd1g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bC47,6100.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:21:09,355 <kafka.protocol.parser>[DEBUG]: Received correlation id: 134
21:21:09,355 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:09,355 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 134 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=132, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:09,355 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=132, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:09,355 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 132 log start offset 0 and error None.
21:21:09,357 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:09,686 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C71/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:09,688 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:09,970 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TS3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:09,972 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'TS3,5200.0,100,0.0,0.0,0.0,0.0,False,0.0,10:24:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,973 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,973 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:09,973 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:09,973 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:09,974 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:09,974 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1b\xaf\xeeA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd3\xd5\x00\x00\x01\x94\x12\xca\xd3\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bTS3,5200.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:21:09,975 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1b\xaf\xeeA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd3\xd5\x00\x00\x01\x94\x12\xca\xd3\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bTS3,5200.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:21:09,975 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1b\xaf\xeeA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd3\xd5\x00\x00\x01\x94\x12\xca\xd3\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bTS3,5200.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:21:09,975 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 135: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1b\xaf\xeeA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd3\xd5\x00\x00\x01\x94\x12\xca\xd3\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bTS3,5200.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:21:09,978 <kafka.protocol.parser>[DEBUG]: Received correlation id: 135
21:21:09,978 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:09,978 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 135 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=133, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:09,978 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=133, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:09,978 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 133 log start offset 0 and error None.
21:21:09,980 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:10,394 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C92/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:10,498 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'C92,4700.0,100,600.0,0.1,0.0,0.0,False,0.0,13:44:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:10,499 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:10,499 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:10,499 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:10,499 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:10,500 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:10,500 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa2<\xbdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd5\xe3\x00\x00\x01\x94\x12\xca\xd5\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fC92,4700.0,100,600.0,0.1,0.0,0.0,...')])])}
21:21:10,500 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa2<\xbdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd5\xe3\x00\x00\x01\x94\x12\xca\xd5\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fC92,4700.0,100,600.0,0.1,0.0,0.0,...')])])
21:21:10,500 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa2<\xbdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd5\xe3\x00\x00\x01\x94\x12\xca\xd5\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fC92,4700.0,100,600.0,0.1,0.0,0.0,...')])])
21:21:10,500 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 136: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa2<\xbdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd5\xe3\x00\x00\x01\x94\x12\xca\xd5\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fC92,4700.0,100,600.0,0.1,0.0,0.0,...')])])
21:21:10,503 <kafka.protocol.parser>[DEBUG]: Received correlation id: 136
21:21:10,503 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:10,504 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 136 (3.420591354370117 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=134, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:10,504 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=134, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:10,504 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 134 log start offset 0 and error None.
21:21:10,505 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:10,832 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CAD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:10,834 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CAD,600.0,300,0.0,0.0,0.0,0.0,False,100.0,11:09:32' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:10,834 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:10,834 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:10,834 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:10,834 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:10,835 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02b:a\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd72\x00\x00\x01\x94\x12\xca\xd72\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCAD,600.0,300,0.0,0.0,0.0,0.0,Fal...')])])}
21:21:10,835 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:10,835 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02b:a\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd72\x00\x00\x01\x94\x12\xca\xd72\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCAD,600.0,300,0.0,0.0,0.0,0.0,Fal...')])])
21:21:10,835 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02b:a\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd72\x00\x00\x01\x94\x12\xca\xd72\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCAD,600.0,300,0.0,0.0,0.0,0.0,Fal...')])])
21:21:10,835 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 137: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02b:a\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xd72\x00\x00\x01\x94\x12\xca\xd72\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCAD,600.0,300,0.0,0.0,0.0,0.0,Fal...')])])
21:21:10,838 <kafka.protocol.parser>[DEBUG]: Received correlation id: 137
21:21:10,838 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:10,838 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 137 (2.9990673065185547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=135, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:10,838 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=135, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:10,838 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 135 log start offset 0 and error None.
21:21:10,840 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:11,214 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CPA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:11,307 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:11,616 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CFV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:11,618 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:12,7 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CAN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:12,9 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:13,448 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CCT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:13,451 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:14,327 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CAP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:14,329 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CAP,44300.0,700,-400.0,0.0,0.0,0.0,False,-500.0,14:45:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:14,329 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:14,329 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:14,329 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:14,330 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:14,330 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02>j\xa8:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe4\xd9\x00\x00\x01\x94\x12\xca\xe4\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCAP,44300.0,700,-400.0,0.0,0.0,0....')])])}
21:21:14,330 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02>j\xa8:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe4\xd9\x00\x00\x01\x94\x12\xca\xe4\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCAP,44300.0,700,-400.0,0.0,0.0,0....')])])
21:21:14,330 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02>j\xa8:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe4\xd9\x00\x00\x01\x94\x12\xca\xe4\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCAP,44300.0,700,-400.0,0.0,0.0,0....')])])
21:21:14,330 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:14,330 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 138: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02>j\xa8:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe4\xd9\x00\x00\x01\x94\x12\xca\xe4\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCAP,44300.0,700,-400.0,0.0,0.0,0....')])])
21:21:14,333 <kafka.protocol.parser>[DEBUG]: Received correlation id: 138
21:21:14,333 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:14,333 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 138 (2.404928207397461 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=136, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:14,333 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=136, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:14,333 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 136 log start offset 0 and error None.
21:21:14,334 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:14,608 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CCA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:14,611 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CCA,17000.0,100,1100.0,0.1,0.0,0.0,False,0.0,11:05:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:14,611 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:14,611 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:14,611 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:14,612 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:14,612 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xef\x94m\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe5\xf3\x00\x00\x01\x94\x12\xca\xe5\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCCA,17000.0,100,1100.0,0.1,0.0,0....')])])}
21:21:14,612 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xef\x94m\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe5\xf3\x00\x00\x01\x94\x12\xca\xe5\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCCA,17000.0,100,1100.0,0.1,0.0,0....')])])
21:21:14,612 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:14,612 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xef\x94m\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe5\xf3\x00\x00\x01\x94\x12\xca\xe5\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCCA,17000.0,100,1100.0,0.1,0.0,0....')])])
21:21:14,613 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 139: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xef\x94m\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xe5\xf3\x00\x00\x01\x94\x12\xca\xe5\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCCA,17000.0,100,1100.0,0.1,0.0,0....')])])
21:21:14,616 <kafka.protocol.parser>[DEBUG]: Received correlation id: 139
21:21:14,616 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:14,616 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 139 (2.904176712036133 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=137, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:14,616 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=137, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:14,616 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 137 log start offset 0 and error None.
21:21:14,618 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:14,913 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HFB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:14,917 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:15,250 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CAV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:15,252 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:15,901 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:16,270 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMW,12100.0,100,-1400.0,-0.1,0.0,0.0,False,0.0,09:00:11' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:16,271 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:16,271 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:16,271 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:16,271 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:16,271 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xbdl\xb8\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xeco\x00\x00\x01\x94\x12\xca\xeco\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCMW,12100.0,100,-1400.0,-0.1,0.0,...')])])}
21:21:16,271 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xbdl\xb8\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xeco\x00\x00\x01\x94\x12\xca\xeco\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCMW,12100.0,100,-1400.0,-0.1,0.0,...')])])
21:21:16,272 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:16,272 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xbdl\xb8\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xeco\x00\x00\x01\x94\x12\xca\xeco\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCMW,12100.0,100,-1400.0,-0.1,0.0,...')])])
21:21:16,272 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 140: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xbdl\xb8\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xeco\x00\x00\x01\x94\x12\xca\xeco\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCMW,12100.0,100,-1400.0,-0.1,0.0,...')])])
21:21:16,275 <kafka.protocol.parser>[DEBUG]: Received correlation id: 140
21:21:16,275 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:16,275 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 140 (2.8836727142333984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=138, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:16,275 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=138, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:16,275 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 138 log start offset 0 and error None.
21:21:16,277 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:16,616 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KCB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:16,619 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KCB,12400.0,2100,-2100.0,-0.1,0.0,0.0,False,0.0,14:58:41' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:16,619 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:16,619 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:16,619 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:16,619 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:16,619 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:16,619 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xca\xb8\xcc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xed\xcb\x00\x00\x01\x94\x12\xca\xed\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKCB,12400.0,2100,-2100.0,-0.1,0.0...')])])}
21:21:16,620 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xca\xb8\xcc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xed\xcb\x00\x00\x01\x94\x12\xca\xed\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKCB,12400.0,2100,-2100.0,-0.1,0.0...')])])
21:21:16,620 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xca\xb8\xcc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xed\xcb\x00\x00\x01\x94\x12\xca\xed\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKCB,12400.0,2100,-2100.0,-0.1,0.0...')])])
21:21:16,620 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 141: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xca\xb8\xcc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xed\xcb\x00\x00\x01\x94\x12\xca\xed\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKCB,12400.0,2100,-2100.0,-0.1,0.0...')])])
21:21:16,622 <kafka.protocol.parser>[DEBUG]: Received correlation id: 141
21:21:16,622 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:16,622 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 141 (2.2306442260742188 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=139, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:16,622 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=139, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:16,623 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 139 log start offset 0 and error None.
21:21:16,624 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:17,329 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CBS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:17,331 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CBS,31500.0,500,200.0,0.0,0.0,0.0,False,0.0,14:36:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:17,331 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:17,331 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:17,332 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:17,332 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:17,332 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x97\xdb\xf8n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf0\x93\x00\x00\x01\x94\x12\xca\xf0\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCBS,31500.0,500,200.0,0.0,0.0,0.0...')])])}
21:21:17,332 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x97\xdb\xf8n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf0\x93\x00\x00\x01\x94\x12\xca\xf0\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCBS,31500.0,500,200.0,0.0,0.0,0.0...')])])
21:21:17,332 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x97\xdb\xf8n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf0\x93\x00\x00\x01\x94\x12\xca\xf0\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCBS,31500.0,500,200.0,0.0,0.0,0.0...')])])
21:21:17,332 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:17,333 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 142: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x97\xdb\xf8n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf0\x93\x00\x00\x01\x94\x12\xca\xf0\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCBS,31500.0,500,200.0,0.0,0.0,0.0...')])])
21:21:17,335 <kafka.protocol.parser>[DEBUG]: Received correlation id: 142
21:21:17,336 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:17,336 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 142 (2.7616024017333984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=140, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:17,336 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=140, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:17,336 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 140 log start offset 0 and error None.
21:21:17,337 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:17,674 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CCI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:17,676 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CCI,22900.0,4100,1250.0,0.1,0.0,0.0,False,2100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:17,677 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:17,677 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:17,677 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:17,677 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:17,677 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\xd6\x96\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf1\xed\x00\x00\x01\x94\x12\xca\xf1\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCCI,22900.0,4100,1250.0,0.1,0.0,0...')])])}
21:21:17,677 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\xd6\x96\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf1\xed\x00\x00\x01\x94\x12\xca\xf1\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCCI,22900.0,4100,1250.0,0.1,0.0,0...')])])
21:21:17,677 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\xd6\x96\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf1\xed\x00\x00\x01\x94\x12\xca\xf1\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCCI,22900.0,4100,1250.0,0.1,0.0,0...')])])
21:21:17,678 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 143: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\xd6\x96\xc4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf1\xed\x00\x00\x01\x94\x12\xca\xf1\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCCI,22900.0,4100,1250.0,0.1,0.0,0...')])])
21:21:17,678 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:17,680 <kafka.protocol.parser>[DEBUG]: Received correlation id: 143
21:21:17,680 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:17,680 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 143 (2.019643783569336 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=141, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:17,681 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=141, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:17,681 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 141 log start offset 0 and error None.
21:21:17,682 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:18,377 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CCL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:18,379 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CCL,8970.0,8600,-100.0,0.0,0.0,0.0,False,60.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:18,379 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:18,379 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:18,380 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:18,380 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:18,380 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02}\xd0\x9d\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf4\xab\x00\x00\x01\x94\x12\xca\xf4\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCCL,8970.0,8600,-100.0,0.0,0.0,0....')])])}
21:21:18,380 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:18,380 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02}\xd0\x9d\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf4\xab\x00\x00\x01\x94\x12\xca\xf4\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCCL,8970.0,8600,-100.0,0.0,0.0,0....')])])
21:21:18,380 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02}\xd0\x9d\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf4\xab\x00\x00\x01\x94\x12\xca\xf4\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCCL,8970.0,8600,-100.0,0.0,0.0,0....')])])
21:21:18,381 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 144: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02}\xd0\x9d\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xf4\xab\x00\x00\x01\x94\x12\xca\xf4\xab\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCCL,8970.0,8600,-100.0,0.0,0.0,0....')])])
21:21:18,383 <kafka.protocol.parser>[DEBUG]: Received correlation id: 144
21:21:18,383 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:18,383 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 144 (2.0008087158203125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=142, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:18,384 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=142, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:18,384 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 142 log start offset 0 and error None.
21:21:18,385 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:18,705 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VSM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:18,708 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:19,23 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:19,25 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:20,478 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CCR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:20,564 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:20,871 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:20,874 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CDC,16850.0,2100,0.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:20,874 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:20,874 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:20,874 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:20,875 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:20,875 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:20,875 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02+\xdb\x84|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xfej\x00\x00\x01\x94\x12\xca\xfej\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDC,16850.0,2100,0.0,0.0,0.0,0.0,...')])])}
21:21:20,875 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02+\xdb\x84|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xfej\x00\x00\x01\x94\x12\xca\xfej\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDC,16850.0,2100,0.0,0.0,0.0,0.0,...')])])
21:21:20,876 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02+\xdb\x84|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xfej\x00\x00\x01\x94\x12\xca\xfej\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDC,16850.0,2100,0.0,0.0,0.0,0.0,...')])])
21:21:20,876 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 145: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02+\xdb\x84|\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xca\xfej\x00\x00\x01\x94\x12\xca\xfej\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDC,16850.0,2100,0.0,0.0,0.0,0.0,...')])])
21:21:20,879 <kafka.protocol.parser>[DEBUG]: Received correlation id: 145
21:21:20,879 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:20,879 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 145 (2.9647350311279297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=143, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:20,879 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=143, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:20,880 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 143 log start offset 0 and error None.
21:21:20,881 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:21,615 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CDH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:21,617 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CDH,9500.0,200,-100.0,0.0,0.0,0.0,False,0.0,13:37:13' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:21,617 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:21,617 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:21,618 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:21,618 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:21,618 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:21,618 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02$\xc3G#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x01Q\x00\x00\x01\x94\x12\xcb\x01Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDH,9500.0,200,-100.0,0.0,0.0,0.0...')])])}
21:21:21,618 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02$\xc3G#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x01Q\x00\x00\x01\x94\x12\xcb\x01Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDH,9500.0,200,-100.0,0.0,0.0,0.0...')])])
21:21:21,618 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02$\xc3G#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x01Q\x00\x00\x01\x94\x12\xcb\x01Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDH,9500.0,200,-100.0,0.0,0.0,0.0...')])])
21:21:21,619 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 146: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02$\xc3G#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x01Q\x00\x00\x01\x94\x12\xcb\x01Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCDH,9500.0,200,-100.0,0.0,0.0,0.0...')])])
21:21:21,621 <kafka.protocol.parser>[DEBUG]: Received correlation id: 146
21:21:21,621 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:21,621 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 146 (2.0062923431396484 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=144, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:21,621 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=144, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:21,622 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 144 log start offset 0 and error None.
21:21:21,623 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:22,307 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CDG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:22,309 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:22,600 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CDO/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:22,602 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CDO,1900.0,600,0.0,0.0,0.0,0.0,False,0.0,14:43:08' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:22,602 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:22,603 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:22,603 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:22,603 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:22,603 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02sW\xae-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x05+\x00\x00\x01\x94\x12\xcb\x05+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCDO,1900.0,600,0.0,0.0,0.0,0.0,Fa...')])])}
21:21:22,603 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02sW\xae-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x05+\x00\x00\x01\x94\x12\xcb\x05+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCDO,1900.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:21:22,603 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02sW\xae-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x05+\x00\x00\x01\x94\x12\xcb\x05+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCDO,1900.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:21:22,603 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:22,604 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 147: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02sW\xae-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x05+\x00\x00\x01\x94\x12\xcb\x05+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCDO,1900.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:21:22,605 <kafka.protocol.parser>[DEBUG]: Received correlation id: 147
21:21:22,606 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:22,606 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 147 (2.6760101318359375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=145, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:22,606 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=145, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:22,606 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 145 log start offset 0 and error None.
21:21:22,608 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:23,24 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CEN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:23,26 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CEN,2000.0,100,0.0,0.0,0.0,0.0,False,100.0,14:49:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:23,27 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:23,27 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:23,27 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:23,27 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:23,27 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:23,27 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02M\xcbw\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x06\xd3\x00\x00\x01\x94\x12\xcb\x06\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCEN,2000.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:21:23,27 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02M\xcbw\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x06\xd3\x00\x00\x01\x94\x12\xcb\x06\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCEN,2000.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:21:23,28 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02M\xcbw\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x06\xd3\x00\x00\x01\x94\x12\xcb\x06\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCEN,2000.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:21:23,28 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 148: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02M\xcbw\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x06\xd3\x00\x00\x01\x94\x12\xcb\x06\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCEN,2000.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:21:23,30 <kafka.protocol.parser>[DEBUG]: Received correlation id: 148
21:21:23,30 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:23,30 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 148 (1.995086669921875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=146, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:23,30 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=146, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:23,31 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 146 log start offset 0 and error None.
21:21:23,32 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:24,368 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CRE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:24,447 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CRE,7750.0,40700,-30.0,0.0,0.0,0.0,True,120.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:24,448 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:24,448 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:24,448 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:24,448 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:24,448 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02]q\x14\x92\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x0c`\x00\x00\x01\x94\x12\xcb\x0c`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCRE,7750.0,40700,-30.0,0.0,0.0,0....')])])}
21:21:24,449 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02]q\x14\x92\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x0c`\x00\x00\x01\x94\x12\xcb\x0c`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCRE,7750.0,40700,-30.0,0.0,0.0,0....')])])
21:21:24,449 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02]q\x14\x92\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x0c`\x00\x00\x01\x94\x12\xcb\x0c`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCRE,7750.0,40700,-30.0,0.0,0.0,0....')])])
21:21:24,449 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 149: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02]q\x14\x92\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x0c`\x00\x00\x01\x94\x12\xcb\x0c`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCRE,7750.0,40700,-30.0,0.0,0.0,0....')])])
21:21:24,449 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:24,452 <kafka.protocol.parser>[DEBUG]: Received correlation id: 149
21:21:24,452 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:24,452 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 149 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=147, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:24,452 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=147, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:24,453 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 147 log start offset 0 and error None.
21:21:24,454 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:24,755 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/STK/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:24,757 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'STK,24600.0,2000,-300.0,0.0,0.0,0.0,False,-200.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:24,757 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:24,757 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:24,758 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:24,758 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:24,758 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\\\x1b\xb5\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\r\x95\x00\x00\x01\x94\x12\xcb\r\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rSTK,24600.0,2000,-300.0,0.0,0.0,0...')])])}
21:21:24,758 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\\\x1b\xb5\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\r\x95\x00\x00\x01\x94\x12\xcb\r\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rSTK,24600.0,2000,-300.0,0.0,0.0,0...')])])
21:21:24,758 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:24,759 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\\\x1b\xb5\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\r\x95\x00\x00\x01\x94\x12\xcb\r\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rSTK,24600.0,2000,-300.0,0.0,0.0,0...')])])
21:21:24,759 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 150: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\\\x1b\xb5\xcf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\r\x95\x00\x00\x01\x94\x12\xcb\r\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rSTK,24600.0,2000,-300.0,0.0,0.0,0...')])])
21:21:24,762 <kafka.protocol.parser>[DEBUG]: Received correlation id: 150
21:21:24,762 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:24,762 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 150 (3.010988235473633 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=148, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:24,763 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=148, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:24,763 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 148 log start offset 0 and error None.
21:21:24,764 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:25,109 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CEO/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:25,592 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CEO,13500.0,1800,-100.0,0.0,0.0,0.0,False,0.0,14:56:13' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:25,592 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:25,593 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:25,593 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:25,593 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:25,594 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:25,594 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02w\xc86\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x10\xd9\x00\x00\x01\x94\x12\xcb\x10\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCEO,13500.0,1800,-100.0,0.0,0.0,0...')])])}
21:21:25,594 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02w\xc86\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x10\xd9\x00\x00\x01\x94\x12\xcb\x10\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCEO,13500.0,1800,-100.0,0.0,0.0,0...')])])
21:21:25,594 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02w\xc86\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x10\xd9\x00\x00\x01\x94\x12\xcb\x10\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCEO,13500.0,1800,-100.0,0.0,0.0,0...')])])
21:21:25,595 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 151: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02w\xc86\x1a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x10\xd9\x00\x00\x01\x94\x12\xcb\x10\xd9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCEO,13500.0,1800,-100.0,0.0,0.0,0...')])])
21:21:25,597 <kafka.protocol.parser>[DEBUG]: Received correlation id: 151
21:21:25,598 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:25,598 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 151 (2.9976367950439453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=149, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:25,598 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=149, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:25,598 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 149 log start offset 0 and error None.
21:21:25,600 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:26,916 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TW3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:26,918 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:27,891 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CFM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:27,894 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:28,300 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CH5/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:28,302 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:28,950 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:28,952 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:30,217 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CLX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:30,218 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CLX,16700.0,100,-300.0,0.0,0.0,0.0,False,100.0,14:59:11' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,219 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,219 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:30,219 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:30,219 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:30,219 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf2HiM\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb"\xeb\x00\x00\x01\x94\x12\xcb"\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCLX,16700.0,100,-300.0,0.0,0.0,0....')])])}
21:21:30,219 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf2HiM\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb"\xeb\x00\x00\x01\x94\x12\xcb"\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCLX,16700.0,100,-300.0,0.0,0.0,0....')])])
21:21:30,219 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,220 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf2HiM\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb"\xeb\x00\x00\x01\x94\x12\xcb"\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCLX,16700.0,100,-300.0,0.0,0.0,0....')])])
21:21:30,220 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 152: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf2HiM\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb"\xeb\x00\x00\x01\x94\x12\xcb"\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCLX,16700.0,100,-300.0,0.0,0.0,0....')])])
21:21:30,222 <kafka.protocol.parser>[DEBUG]: Received correlation id: 152
21:21:30,222 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:30,222 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 152 (2.7391910552978516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=150, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:30,222 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=150, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:30,222 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 150 log start offset 0 and error None.
21:21:30,224 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:30,505 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CHP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:30,509 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CHP,33650.0,100,50.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,510 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,510 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:30,510 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:30,511 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:30,511 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x05\xab\xca\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb$\x0e\x00\x00\x01\x94\x12\xcb$\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCHP,33650.0,100,50.0,0.0,0.0,0.0,...')])])}
21:21:30,511 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x05\xab\xca\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb$\x0e\x00\x00\x01\x94\x12\xcb$\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCHP,33650.0,100,50.0,0.0,0.0,0.0,...')])])
21:21:30,512 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x05\xab\xca\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb$\x0e\x00\x00\x01\x94\x12\xcb$\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCHP,33650.0,100,50.0,0.0,0.0,0.0,...')])])
21:21:30,512 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 153: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x05\xab\xca\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb$\x0e\x00\x00\x01\x94\x12\xcb$\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCHP,33650.0,100,50.0,0.0,0.0,0.0,...')])])
21:21:30,512 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,516 <kafka.protocol.parser>[DEBUG]: Received correlation id: 153
21:21:30,516 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:30,517 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 153 (5.078792572021484 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=151, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:30,517 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=151, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:30,517 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 151 log start offset 0 and error None.
21:21:30,519 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:30,934 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CI5/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:30,936 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CI5,8500.0,100,900.0,0.1,0.0,0.0,False,-200.0,09:02:23' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,936 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,936 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:30,937 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:30,937 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:30,937 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02k\xde\x05\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb%\xb8\x00\x00\x01\x94\x12\xcb%\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCI5,8500.0,100,900.0,0.1,0.0,0.0,...')])])}
21:21:30,937 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02k\xde\x05\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb%\xb8\x00\x00\x01\x94\x12\xcb%\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCI5,8500.0,100,900.0,0.1,0.0,0.0,...')])])
21:21:30,937 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:30,937 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02k\xde\x05\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb%\xb8\x00\x00\x01\x94\x12\xcb%\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCI5,8500.0,100,900.0,0.1,0.0,0.0,...')])])
21:21:30,938 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 154: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02k\xde\x05\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb%\xb8\x00\x00\x01\x94\x12\xcb%\xb8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCI5,8500.0,100,900.0,0.1,0.0,0.0,...')])])
21:21:30,940 <kafka.protocol.parser>[DEBUG]: Received correlation id: 154
21:21:30,940 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:30,941 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 154 (3.002643585205078 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=152, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:30,941 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=152, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:30,941 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 152 log start offset 0 and error None.
21:21:30,942 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:31,372 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CID/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:31,374 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CID,23900.0,200,2200.0,0.1,0.0,0.0,False,3300.0,13:25:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:31,374 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:31,374 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:31,375 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:31,375 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:31,375 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b:\xf9\xd2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb'n\x00\x00\x01\x94\x12\xcb'n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCID,23900.0,200,2200.0,0.1,0.0,0....")])])}
21:21:31,375 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b:\xf9\xd2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb'n\x00\x00\x01\x94\x12\xcb'n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCID,23900.0,200,2200.0,0.1,0.0,0....")])])
21:21:31,375 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b:\xf9\xd2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb'n\x00\x00\x01\x94\x12\xcb'n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCID,23900.0,200,2200.0,0.1,0.0,0....")])])
21:21:31,375 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:31,376 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 155: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b:\xf9\xd2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb'n\x00\x00\x01\x94\x12\xcb'n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCID,23900.0,200,2200.0,0.1,0.0,0....")])])
21:21:31,378 <kafka.protocol.parser>[DEBUG]: Received correlation id: 155
21:21:31,379 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:31,379 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 155 (2.993345260620117 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=153, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:31,379 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=153, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:31,379 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 153 log start offset 0 and error None.
21:21:31,380 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:31,700 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CE1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:31,702 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:32,92 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CEG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:32,94 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:32,399 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C4G/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:32,401 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'C4G,8000.0,500,-100.0,0.0,0.0,0.0,False,-100.0,14:59:42' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:32,401 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:32,402 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:32,402 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:32,402 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:32,402 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\x82\xb4\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb+r\x00\x00\x01\x94\x12\xcb+r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC4G,8000.0,500,-100.0,0.0,0.0,0.0...')])])}
21:21:32,402 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\x82\xb4\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb+r\x00\x00\x01\x94\x12\xcb+r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC4G,8000.0,500,-100.0,0.0,0.0,0.0...')])])
21:21:32,402 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\x82\xb4\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb+r\x00\x00\x01\x94\x12\xcb+r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC4G,8000.0,500,-100.0,0.0,0.0,0.0...')])])
21:21:32,402 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:32,403 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 156: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xdd\x82\xb4\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb+r\x00\x00\x01\x94\x12\xcb+r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nC4G,8000.0,500,-100.0,0.0,0.0,0.0...')])])
21:21:32,405 <kafka.protocol.parser>[DEBUG]: Received correlation id: 156
21:21:32,406 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:32,406 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 156 (2.9582977294921875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=154, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:32,406 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=154, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:32,406 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 154 log start offset 0 and error None.
21:21:32,407 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:33,957 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C12/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:34,43 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:35,393 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CIG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:35,415 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CIG,8470.0,5300,40.0,0.0,0.0,0.0,False,10.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:35,419 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:35,419 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:35,419 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:35,419 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:35,420 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:35,420 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02DR\xa7\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb7;\x00\x00\x01\x94\x12\xcb7;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCIG,8470.0,5300,40.0,0.0,0.0,0.0,...')])])}
21:21:35,420 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02DR\xa7\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb7;\x00\x00\x01\x94\x12\xcb7;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCIG,8470.0,5300,40.0,0.0,0.0,0.0,...')])])
21:21:35,420 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02DR\xa7\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb7;\x00\x00\x01\x94\x12\xcb7;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCIG,8470.0,5300,40.0,0.0,0.0,0.0,...')])])
21:21:35,420 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 157: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02DR\xa7\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb7;\x00\x00\x01\x94\x12\xcb7;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCIG,8470.0,5300,40.0,0.0,0.0,0.0,...')])])
21:21:35,424 <kafka.protocol.parser>[DEBUG]: Received correlation id: 157
21:21:35,424 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:35,424 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 157 (3.714323043823242 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=155, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:35,424 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=155, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:35,424 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 155 log start offset 0 and error None.
21:21:35,430 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:35,772 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CII/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:35,778 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CII,14000.0,187800,-150.0,0.0,0.0,0.0,True,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:35,778 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:35,778 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:35,778 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:35,779 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe7+\x1fA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb8\xa2\x00\x00\x01\x94\x12\xcb8\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCII,14000.0,187800,-150.0,0.0,0.0...')])])}
21:21:35,779 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:35,779 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe7+\x1fA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb8\xa2\x00\x00\x01\x94\x12\xcb8\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCII,14000.0,187800,-150.0,0.0,0.0...')])])
21:21:35,779 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:35,779 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe7+\x1fA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb8\xa2\x00\x00\x01\x94\x12\xcb8\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCII,14000.0,187800,-150.0,0.0,0.0...')])])
21:21:35,779 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 158: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe7+\x1fA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb8\xa2\x00\x00\x01\x94\x12\xcb8\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCII,14000.0,187800,-150.0,0.0,0.0...')])])
21:21:35,783 <kafka.protocol.parser>[DEBUG]: Received correlation id: 158
21:21:35,783 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:35,783 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 158 (3.9987564086914062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=156, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:35,783 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=156, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:35,783 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 156 log start offset 0 and error None.
21:21:35,784 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:36,72 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CKG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:36,82 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CKG,22800.0,1000,0.0,0.0,0.0,0.0,False,0.0,13:25:21' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:36,83 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:36,83 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:36,84 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:36,85 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:36,85 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:36,85 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xb1(\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb9\xd3\x00\x00\x01\x94\x12\xcb9\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCKG,22800.0,1000,0.0,0.0,0.0,0.0,...')])])}
21:21:36,86 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xb1(\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb9\xd3\x00\x00\x01\x94\x12\xcb9\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCKG,22800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:21:36,86 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xb1(\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb9\xd3\x00\x00\x01\x94\x12\xcb9\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCKG,22800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:21:36,87 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 159: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xb1(\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb9\xd3\x00\x00\x01\x94\x12\xcb9\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCKG,22800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:21:36,92 <kafka.protocol.parser>[DEBUG]: Received correlation id: 159
21:21:36,92 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:36,93 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 159 (6.000041961669922 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=157, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:36,93 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=157, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:36,93 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 157 log start offset 0 and error None.
21:21:36,95 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:36,381 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CIP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:36,382 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:36,703 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CBI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:36,705 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CBI,10400.0,900,-1500.0,-0.1,0.0,0.0,False,-100.0,14:58:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:36,705 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:36,705 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:36,706 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:36,706 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:36,706 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x9e\x03\xcb\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb<A\x00\x00\x01\x94\x12\xcb<A\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCBI,10400.0,900,-1500.0,-0.1,0.0...')])])}
21:21:36,706 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x9e\x03\xcb\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb<A\x00\x00\x01\x94\x12\xcb<A\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCBI,10400.0,900,-1500.0,-0.1,0.0...')])])
21:21:36,706 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:36,706 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x9e\x03\xcb\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb<A\x00\x00\x01\x94\x12\xcb<A\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCBI,10400.0,900,-1500.0,-0.1,0.0...')])])
21:21:36,707 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 160: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x9e\x03\xcb\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb<A\x00\x00\x01\x94\x12\xcb<A\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCBI,10400.0,900,-1500.0,-0.1,0.0...')])])
21:21:36,710 <kafka.protocol.parser>[DEBUG]: Received correlation id: 160
21:21:36,710 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:36,710 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 160 (2.5234222412109375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=158, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:36,710 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=158, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:36,710 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 158 log start offset 0 and error None.
21:21:36,712 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:37,729 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CJC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:37,731 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:38,445 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CK8/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:38,539 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:38,822 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CKD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:38,825 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CKD,22700.0,700,0.0,0.0,0.0,0.0,False,0.0,11:12:22' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:38,825 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:38,825 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:38,825 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:38,826 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:38,826 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xdd\x19\xe9\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbD\x89\x00\x00\x01\x94\x12\xcbD\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCKD,22700.0,700,0.0,0.0,0.0,0.0,F...')])])}
21:21:38,826 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xdd\x19\xe9\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbD\x89\x00\x00\x01\x94\x12\xcbD\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCKD,22700.0,700,0.0,0.0,0.0,0.0,F...')])])
21:21:38,826 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xdd\x19\xe9\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbD\x89\x00\x00\x01\x94\x12\xcbD\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCKD,22700.0,700,0.0,0.0,0.0,0.0,F...')])])
21:21:38,826 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 161: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xdd\x19\xe9\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbD\x89\x00\x00\x01\x94\x12\xcbD\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCKD,22700.0,700,0.0,0.0,0.0,0.0,F...')])])
21:21:38,827 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:38,829 <kafka.protocol.parser>[DEBUG]: Received correlation id: 161
21:21:38,830 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:38,830 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 161 (4.00090217590332 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=159, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:38,830 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=159, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:38,830 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 159 log start offset 0 and error None.
21:21:38,831 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:39,164 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMK/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:39,167 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:39,589 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CKV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:39,592 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:40,58 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CLC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:40,60 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CLC,52000.0,300,-100.0,0.0,0.0,0.0,False,-200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:40,60 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:40,60 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:40,60 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:40,61 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:40,61 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb0\xde\xd4\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbI\\\x00\x00\x01\x94\x12\xcbI\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCLC,52000.0,300,-100.0,0.0,0.0,0....')])])}
21:21:40,61 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb0\xde\xd4\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbI\\\x00\x00\x01\x94\x12\xcbI\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCLC,52000.0,300,-100.0,0.0,0.0,0....')])])
21:21:40,61 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:40,61 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb0\xde\xd4\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbI\\\x00\x00\x01\x94\x12\xcbI\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCLC,52000.0,300,-100.0,0.0,0.0,0....')])])
21:21:40,62 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 162: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb0\xde\xd4\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbI\\\x00\x00\x01\x94\x12\xcbI\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCLC,52000.0,300,-100.0,0.0,0.0,0....')])])
21:21:40,64 <kafka.protocol.parser>[DEBUG]: Received correlation id: 162
21:21:40,64 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:40,64 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 162 (1.9855499267578125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=160, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:40,65 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=160, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:40,65 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 160 log start offset 0 and error None.
21:21:40,66 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:40,441 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ADG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:40,443 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ADG,11450.0,200,550.0,0.1,0.0,0.0,False,0.0,13:31:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:40,444 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:40,444 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:40,444 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:40,444 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:40,444 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd9\xcbU\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbJ\xdc\x00\x00\x01\x94\x12\xcbJ\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hADG,11450.0,200,550.0,0.1,0.0,0.0...')])])}
21:21:40,445 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd9\xcbU\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbJ\xdc\x00\x00\x01\x94\x12\xcbJ\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hADG,11450.0,200,550.0,0.1,0.0,0.0...')])])
21:21:40,445 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd9\xcbU\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbJ\xdc\x00\x00\x01\x94\x12\xcbJ\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hADG,11450.0,200,550.0,0.1,0.0,0.0...')])])
21:21:40,445 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 163: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd9\xcbU\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbJ\xdc\x00\x00\x01\x94\x12\xcbJ\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hADG,11450.0,200,550.0,0.1,0.0,0.0...')])])
21:21:40,445 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:40,448 <kafka.protocol.parser>[DEBUG]: Received correlation id: 163
21:21:40,448 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:40,448 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 163 (2.956867218017578 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=161, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:40,448 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=161, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:40,448 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 161 log start offset 0 and error None.
21:21:40,450 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:40,741 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CLG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:40,744 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:41,194 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CLL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:41,196 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CLL,35850.0,100,-150.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:41,196 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:41,196 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:41,196 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:41,196 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:41,197 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:41,197 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x16\x11Ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbM\xcc\x00\x00\x01\x94\x12\xcbM\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCLL,35850.0,100,-150.0,0.0,0.0,0....')])])}
21:21:41,197 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x16\x11Ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbM\xcc\x00\x00\x01\x94\x12\xcbM\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCLL,35850.0,100,-150.0,0.0,0.0,0....')])])
21:21:41,197 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x16\x11Ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbM\xcc\x00\x00\x01\x94\x12\xcbM\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCLL,35850.0,100,-150.0,0.0,0.0,0....')])])
21:21:41,197 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 164: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x16\x11Ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbM\xcc\x00\x00\x01\x94\x12\xcbM\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCLL,35850.0,100,-150.0,0.0,0.0,0....')])])
21:21:41,200 <kafka.protocol.parser>[DEBUG]: Received correlation id: 164
21:21:41,200 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:41,200 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 164 (3.000497817993164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=162, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:41,200 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=162, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:41,200 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 162 log start offset 0 and error None.
21:21:41,201 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:41,616 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:41,621 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMF,304200.0,500,-1100.0,0.0,0.0,0.0,False,-1800.0,13:10:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:41,621 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:41,622 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:41,622 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:41,623 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:41,624 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:41,624 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x17\xd9@\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbOv\x00\x00\x01\x94\x12\xcbOv\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMF,304200.0,500,-1100.0,0.0,0.0...')])])}
21:21:41,624 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x17\xd9@\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbOv\x00\x00\x01\x94\x12\xcbOv\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMF,304200.0,500,-1100.0,0.0,0.0...')])])
21:21:41,625 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x17\xd9@\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbOv\x00\x00\x01\x94\x12\xcbOv\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMF,304200.0,500,-1100.0,0.0,0.0...')])])
21:21:41,625 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 165: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x17\xd9@\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbOv\x00\x00\x01\x94\x12\xcbOv\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMF,304200.0,500,-1100.0,0.0,0.0...')])])
21:21:41,629 <kafka.protocol.parser>[DEBUG]: Received correlation id: 165
21:21:41,629 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:41,629 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 165 (3.997802734375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=163, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:41,630 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=163, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:41,630 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 163 log start offset 0 and error None.
21:21:41,632 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:42,509 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CLW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:42,511 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:44,890 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TVH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:44,894 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:45,203 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:45,205 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMC,5500.0,200,-300.0,-0.1,0.0,0.0,False,-100.0,10:09:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:45,205 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:45,205 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:45,205 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:45,205 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:45,206 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x025\xf8}c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb]u\x00\x00\x01\x94\x12\xcb]u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCMC,5500.0,200,-300.0,-0.1,0.0,0....')])])}
21:21:45,206 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x025\xf8}c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb]u\x00\x00\x01\x94\x12\xcb]u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCMC,5500.0,200,-300.0,-0.1,0.0,0....')])])
21:21:45,206 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x025\xf8}c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb]u\x00\x00\x01\x94\x12\xcb]u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCMC,5500.0,200,-300.0,-0.1,0.0,0....')])])
21:21:45,206 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:45,206 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 166: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x025\xf8}c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb]u\x00\x00\x01\x94\x12\xcb]u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCMC,5500.0,200,-300.0,-0.1,0.0,0....')])])
21:21:45,209 <kafka.protocol.parser>[DEBUG]: Received correlation id: 166
21:21:45,209 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:45,209 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 166 (2.58636474609375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=164, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:45,209 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=164, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:45,209 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 164 log start offset 0 and error None.
21:21:45,210 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:45,508 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:45,512 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:46,254 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TIN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:46,337 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'TIN,12800.0,1000,0.0,0.0,0.0,0.0,False,0.0,14:08:18' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:46,337 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:46,337 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:46,338 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:46,338 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:46,338 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe6\xf6\x96{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcba\xe1\x00\x00\x01\x94\x12\xcba\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fTIN,12800.0,1000,0.0,0.0,0.0,0.0,...')])])}
21:21:46,338 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe6\xf6\x96{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcba\xe1\x00\x00\x01\x94\x12\xcba\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fTIN,12800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:21:46,339 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe6\xf6\x96{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcba\xe1\x00\x00\x01\x94\x12\xcba\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fTIN,12800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:21:46,339 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:46,339 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 167: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe6\xf6\x96{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcba\xe1\x00\x00\x01\x94\x12\xcba\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fTIN,12800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:21:46,342 <kafka.protocol.parser>[DEBUG]: Received correlation id: 167
21:21:46,342 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:46,342 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 167 (2.9506683349609375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=165, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:46,342 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=165, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:46,342 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 165 log start offset 0 and error None.
21:21:46,344 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:46,735 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:46,737 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMG,53900.0,210700,-1500.0,0.0,0.0,0.0,True,-200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:46,738 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:46,738 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:46,738 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:46,738 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:46,738 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:46,738 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xdf\x97sP\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbcr\x00\x00\x01\x94\x12\xcbcr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMG,53900.0,210700,-1500.0,0.0,0...')])])}
21:21:46,739 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xdf\x97sP\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbcr\x00\x00\x01\x94\x12\xcbcr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMG,53900.0,210700,-1500.0,0.0,0...')])])
21:21:46,739 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xdf\x97sP\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbcr\x00\x00\x01\x94\x12\xcbcr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMG,53900.0,210700,-1500.0,0.0,0...')])])
21:21:46,739 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 168: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xdf\x97sP\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbcr\x00\x00\x01\x94\x12\xcbcr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCMG,53900.0,210700,-1500.0,0.0,0...')])])
21:21:46,742 <kafka.protocol.parser>[DEBUG]: Received correlation id: 168
21:21:46,742 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:46,742 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 168 (3.0035972595214844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=166, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:46,742 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=166, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:46,742 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 166 log start offset 0 and error None.
21:21:46,744 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:47,110 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:47,112 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMI,1200.0,100,100.0,0.1,0.0,0.0,False,0.0,11:08:08' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:47,112 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:47,112 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:47,112 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:47,112 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:47,112 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02q=\x86\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbd\xe8\x00\x00\x01\x94\x12\xcbd\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMI,1200.0,100,100.0,0.1,0.0,0.0,...')])])}
21:21:47,112 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02q=\x86\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbd\xe8\x00\x00\x01\x94\x12\xcbd\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMI,1200.0,100,100.0,0.1,0.0,0.0,...')])])
21:21:47,113 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:47,113 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02q=\x86\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbd\xe8\x00\x00\x01\x94\x12\xcbd\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMI,1200.0,100,100.0,0.1,0.0,0.0,...')])])
21:21:47,113 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 169: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02q=\x86\x7f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbd\xe8\x00\x00\x01\x94\x12\xcbd\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCMI,1200.0,100,100.0,0.1,0.0,0.0,...')])])
21:21:47,116 <kafka.protocol.parser>[DEBUG]: Received correlation id: 169
21:21:47,116 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:47,116 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 169 (2.8715133666992188 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=167, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:47,116 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=167, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:47,116 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 167 log start offset 0 and error None.
21:21:47,117 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:47,823 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:47,825 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMD,21900.0,100,-500.0,0.0,0.0,0.0,False,0.0,14:59:38' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:47,825 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:47,825 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:47,825 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:47,826 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:47,826 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1f\x05[\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbg\xb1\x00\x00\x01\x94\x12\xcbg\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMD,21900.0,100,-500.0,0.0,0.0,0....')])])}
21:21:47,826 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1f\x05[\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbg\xb1\x00\x00\x01\x94\x12\xcbg\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMD,21900.0,100,-500.0,0.0,0.0,0....')])])
21:21:47,826 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1f\x05[\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbg\xb1\x00\x00\x01\x94\x12\xcbg\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMD,21900.0,100,-500.0,0.0,0.0,0....')])])
21:21:47,826 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:47,826 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 170: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x1f\x05[\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbg\xb1\x00\x00\x01\x94\x12\xcbg\xb1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMD,21900.0,100,-500.0,0.0,0.0,0....')])])
21:21:47,829 <kafka.protocol.parser>[DEBUG]: Received correlation id: 170
21:21:47,829 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:47,830 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 170 (2.8510093688964844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=168, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:47,830 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=168, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:47,830 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 168 log start offset 0 and error None.
21:21:47,831 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:48,141 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:48,144 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:48,958 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:48,960 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMS,10100.0,5500,-200.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:48,960 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:48,960 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:48,960 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:48,960 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:48,960 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02.\xf7\xb78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbl \x00\x00\x01\x94\x12\xcbl \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCMS,10100.0,5500,-200.0,0.0,0.0,0...')])])}
21:21:48,960 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02.\xf7\xb78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbl \x00\x00\x01\x94\x12\xcbl \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCMS,10100.0,5500,-200.0,0.0,0.0,0...')])])
21:21:48,961 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:48,961 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02.\xf7\xb78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbl \x00\x00\x01\x94\x12\xcbl \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCMS,10100.0,5500,-200.0,0.0,0.0,0...')])])
21:21:48,962 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 171: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02.\xf7\xb78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbl \x00\x00\x01\x94\x12\xcbl \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCMS,10100.0,5500,-200.0,0.0,0.0,0...')])])
21:21:48,964 <kafka.protocol.parser>[DEBUG]: Received correlation id: 171
21:21:48,964 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:48,965 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 171 (3.010988235473633 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=169, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:48,965 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=169, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:48,965 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 169 log start offset 0 and error None.
21:21:48,966 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:49,679 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CAT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:49,681 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CAT,18500.0,400,200.0,0.0,0.0,0.0,False,0.0,14:50:36' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:49,681 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:49,681 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:49,681 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:49,681 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:49,681 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x06\xff(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbn\xf1\x00\x00\x01\x94\x12\xcbn\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCAT,18500.0,400,200.0,0.0,0.0,0.0...')])])}
21:21:49,682 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x06\xff(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbn\xf1\x00\x00\x01\x94\x12\xcbn\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCAT,18500.0,400,200.0,0.0,0.0,0.0...')])])
21:21:49,682 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x06\xff(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbn\xf1\x00\x00\x01\x94\x12\xcbn\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCAT,18500.0,400,200.0,0.0,0.0,0.0...')])])
21:21:49,682 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 172: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x06\xff(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbn\xf1\x00\x00\x01\x94\x12\xcbn\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCAT,18500.0,400,200.0,0.0,0.0,0.0...')])])
21:21:49,682 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:49,685 <kafka.protocol.parser>[DEBUG]: Received correlation id: 172
21:21:49,685 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:49,685 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 172 (2.857208251953125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=170, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:49,685 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=170, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:49,685 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 170 log start offset 0 and error None.
21:21:49,686 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:50,1 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:50,3 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMT,15600.0,200,-200.0,0.0,0.0,0.0,False,0.0,14:59:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:50,3 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:50,3 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:50,3 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:50,3 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:50,3 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbdB\x91\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbp3\x00\x00\x01\x94\x12\xcbp3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMT,15600.0,200,-200.0,0.0,0.0,0....')])])}
21:21:50,3 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbdB\x91\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbp3\x00\x00\x01\x94\x12\xcbp3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMT,15600.0,200,-200.0,0.0,0.0,0....')])])
21:21:50,3 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbdB\x91\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbp3\x00\x00\x01\x94\x12\xcbp3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMT,15600.0,200,-200.0,0.0,0.0,0....')])])
21:21:50,3 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:50,3 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 173: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xbdB\x91\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbp3\x00\x00\x01\x94\x12\xcbp3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMT,15600.0,200,-200.0,0.0,0.0,0....')])])
21:21:50,6 <kafka.protocol.parser>[DEBUG]: Received correlation id: 173
21:21:50,6 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:50,6 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 173 (1.9903182983398438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=171, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:50,7 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=171, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:50,7 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 171 log start offset 0 and error None.
21:21:50,8 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:50,692 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:50,693 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:50,973 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:50,975 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CMX,8100.0,37300,-120.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:50,975 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:50,975 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:50,975 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:50,976 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:50,976 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd0\x16\xe2\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbs\xff\x00\x00\x01\x94\x12\xcbs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMX,8100.0,37300,-120.0,0.0,0.0,0...')])])}
21:21:50,976 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd0\x16\xe2\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbs\xff\x00\x00\x01\x94\x12\xcbs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMX,8100.0,37300,-120.0,0.0,0.0,0...')])])
21:21:50,976 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:50,976 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd0\x16\xe2\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbs\xff\x00\x00\x01\x94\x12\xcbs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMX,8100.0,37300,-120.0,0.0,0.0,0...')])])
21:21:50,977 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 174: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd0\x16\xe2\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbs\xff\x00\x00\x01\x94\x12\xcbs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCMX,8100.0,37300,-120.0,0.0,0.0,0...')])])
21:21:50,979 <kafka.protocol.parser>[DEBUG]: Received correlation id: 174
21:21:50,979 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:50,979 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 174 (1.9927024841308594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=172, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:50,979 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=172, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:50,979 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 172 log start offset 0 and error None.
21:21:50,981 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:51,266 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CNC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:51,268 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CNC,34000.0,500,-500.0,0.0,0.0,0.0,False,-500.0,14:56:33' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:51,268 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:51,268 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:51,269 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:51,269 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:51,269 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xaafJU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbu$\x00\x00\x01\x94\x12\xcbu$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCNC,34000.0,500,-500.0,0.0,0.0,0....')])])}
21:21:51,269 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xaafJU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbu$\x00\x00\x01\x94\x12\xcbu$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCNC,34000.0,500,-500.0,0.0,0.0,0....')])])
21:21:51,269 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:51,269 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xaafJU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbu$\x00\x00\x01\x94\x12\xcbu$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCNC,34000.0,500,-500.0,0.0,0.0,0....')])])
21:21:51,270 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 175: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xaafJU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbu$\x00\x00\x01\x94\x12\xcbu$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCNC,34000.0,500,-500.0,0.0,0.0,0....')])])
21:21:51,272 <kafka.protocol.parser>[DEBUG]: Received correlation id: 175
21:21:51,272 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:51,272 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 175 (1.9960403442382812 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=173, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:51,272 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=173, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:51,273 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 173 log start offset 0 and error None.
21:21:51,275 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:51,578 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CNG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:51,580 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CNG,31150.0,5800,-350.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:51,581 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:51,581 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:51,581 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:51,581 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:51,582 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02,%\\0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbv]\x00\x00\x01\x94\x12\xcbv]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCNG,31150.0,5800,-350.0,0.0,0.0,0...')])])}
21:21:51,582 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02,%\\0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbv]\x00\x00\x01\x94\x12\xcbv]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCNG,31150.0,5800,-350.0,0.0,0.0,0...')])])
21:21:51,582 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02,%\\0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbv]\x00\x00\x01\x94\x12\xcbv]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCNG,31150.0,5800,-350.0,0.0,0.0,0...')])])
21:21:51,582 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 176: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02,%\\0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcbv]\x00\x00\x01\x94\x12\xcbv]\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCNG,31150.0,5800,-350.0,0.0,0.0,0...')])])
21:21:51,582 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:51,585 <kafka.protocol.parser>[DEBUG]: Received correlation id: 176
21:21:51,585 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:51,585 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 176 (3.300189971923828 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=174, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:51,585 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=174, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:51,585 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 174 log start offset 0 and error None.
21:21:51,587 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:52,909 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CNT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:52,910 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CNT,13700.0,500,0.0,0.0,0.0,0.0,False,-100.0,14:16:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:52,910 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:52,910 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:52,912 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:52,912 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:52,912 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9?U\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb{\x8e\x00\x00\x01\x94\x12\xcb{\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCNT,13700.0,500,0.0,0.0,0.0,0.0,F...')])])}
21:21:52,912 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9?U\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb{\x8e\x00\x00\x01\x94\x12\xcb{\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCNT,13700.0,500,0.0,0.0,0.0,0.0,F...')])])
21:21:52,912 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:52,912 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9?U\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb{\x8e\x00\x00\x01\x94\x12\xcb{\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCNT,13700.0,500,0.0,0.0,0.0,0.0,F...')])])
21:21:52,913 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 177: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa9?U\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb{\x8e\x00\x00\x01\x94\x12\xcb{\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCNT,13700.0,500,0.0,0.0,0.0,0.0,F...')])])
21:21:52,915 <kafka.protocol.parser>[DEBUG]: Received correlation id: 177
21:21:52,915 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:52,915 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 177 (1.9919872283935547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=175, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:52,915 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=175, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:52,915 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 175 log start offset 0 and error None.
21:21:52,917 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:54,245 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CC1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:54,247 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CC1,15900.0,1600,0.0,0.0,0.0,0.0,False,0.0,14:59:55' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:54,247 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:54,247 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:54,247 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:54,248 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:54,248 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd1N\x93,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x80\xc7\x00\x00\x01\x94\x12\xcb\x80\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCC1,15900.0,1600,0.0,0.0,0.0,0.0,...')])])}
21:21:54,248 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd1N\x93,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x80\xc7\x00\x00\x01\x94\x12\xcb\x80\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCC1,15900.0,1600,0.0,0.0,0.0,0.0,...')])])
21:21:54,248 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:54,248 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd1N\x93,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x80\xc7\x00\x00\x01\x94\x12\xcb\x80\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCC1,15900.0,1600,0.0,0.0,0.0,0.0,...')])])
21:21:54,248 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 178: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd1N\x93,\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x80\xc7\x00\x00\x01\x94\x12\xcb\x80\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCC1,15900.0,1600,0.0,0.0,0.0,0.0,...')])])
21:21:54,251 <kafka.protocol.parser>[DEBUG]: Received correlation id: 178
21:21:54,251 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:54,251 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 178 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=176, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:54,251 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=176, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:54,251 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 176 log start offset 0 and error None.
21:21:54,252 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:54,946 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CDP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:54,948 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CDP,11000.0,300,-700.0,-0.1,0.0,0.0,False,0.0,11:27:41' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:54,948 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:54,948 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:54,948 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:54,948 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:54,949 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0\xbd45\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x83\x84\x00\x00\x01\x94\x12\xcb\x83\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCDP,11000.0,300,-700.0,-0.1,0.0,0...')])])}
21:21:54,949 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0\xbd45\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x83\x84\x00\x00\x01\x94\x12\xcb\x83\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCDP,11000.0,300,-700.0,-0.1,0.0,0...')])])
21:21:54,949 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0\xbd45\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x83\x84\x00\x00\x01\x94\x12\xcb\x83\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCDP,11000.0,300,-700.0,-0.1,0.0,0...')])])
21:21:54,948 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:54,949 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 179: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0\xbd45\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x83\x84\x00\x00\x01\x94\x12\xcb\x83\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCDP,11000.0,300,-700.0,-0.1,0.0,0...')])])
21:21:54,952 <kafka.protocol.parser>[DEBUG]: Received correlation id: 179
21:21:54,952 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:54,952 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 179 (2.989053726196289 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=177, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:54,952 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=177, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:54,952 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 177 log start offset 0 and error None.
21:21:54,953 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:56,384 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/COM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:56,386 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'COM,29300.0,100,1600.0,0.1,0.0,0.0,False,800.0,13:22:33' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:56,386 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:56,386 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:56,386 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:56,386 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:56,386 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x187c\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x89"\x00\x00\x01\x94\x12\xcb\x89"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCOM,29300.0,100,1600.0,0.1,0.0,0....')])])}
21:21:56,386 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x187c\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x89"\x00\x00\x01\x94\x12\xcb\x89"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCOM,29300.0,100,1600.0,0.1,0.0,0....')])])
21:21:56,387 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x187c\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x89"\x00\x00\x01\x94\x12\xcb\x89"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCOM,29300.0,100,1600.0,0.1,0.0,0....')])])
21:21:56,387 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:56,387 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 180: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x187c\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x89"\x00\x00\x01\x94\x12\xcb\x89"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCOM,29300.0,100,1600.0,0.1,0.0,0....')])])
21:21:56,390 <kafka.protocol.parser>[DEBUG]: Received correlation id: 180
21:21:56,390 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:56,390 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 180 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=178, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:56,390 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=178, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:56,390 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 178 log start offset 0 and error None.
21:21:56,391 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:56,692 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TCK/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:56,694 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:57,505 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CMN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:57,508 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:58,178 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ICN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:58,180 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ICN,65500.0,100,1500.0,0.0,0.0,0.0,False,-100.0,14:29:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:58,181 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:58,181 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:58,181 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:58,181 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:58,181 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x90\xee\xeb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x90%\x00\x00\x01\x94\x12\xcb\x90%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICN,65500.0,100,1500.0,0.0,0.0,0....')])])}
21:21:58,181 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x90\xee\xeb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x90%\x00\x00\x01\x94\x12\xcb\x90%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICN,65500.0,100,1500.0,0.0,0.0,0....')])])
21:21:58,181 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:58,182 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x90\xee\xeb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x90%\x00\x00\x01\x94\x12\xcb\x90%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICN,65500.0,100,1500.0,0.0,0.0,0....')])])
21:21:58,182 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 181: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x90\xee\xeb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x90%\x00\x00\x01\x94\x12\xcb\x90%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICN,65500.0,100,1500.0,0.0,0.0,0....')])])
21:21:58,184 <kafka.protocol.parser>[DEBUG]: Received correlation id: 181
21:21:58,184 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:58,185 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 181 (2.003908157348633 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=179, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:58,185 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=179, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:58,185 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 179 log start offset 0 and error None.
21:21:58,186 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:58,458 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CNN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:59,113 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:59,432 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CPC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:59,434 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CPC,18000.0,200,0.0,0.0,0.0,0.0,False,0.0,13:01:41' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:21:59,434 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:21:59,434 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:21:59,435 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:21:59,435 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xc8\xb71\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x95\n\x00\x00\x01\x94\x12\xcb\x95\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCPC,18000.0,200,0.0,0.0,0.0,0.0,F...')])])}
21:21:59,435 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:21:59,435 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xc8\xb71\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x95\n\x00\x00\x01\x94\x12\xcb\x95\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCPC,18000.0,200,0.0,0.0,0.0,0.0,F...')])])
21:21:59,435 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xc8\xb71\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x95\n\x00\x00\x01\x94\x12\xcb\x95\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCPC,18000.0,200,0.0,0.0,0.0,0.0,F...')])])
21:21:59,435 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 182: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02;\xc8\xb71\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x95\n\x00\x00\x01\x94\x12\xcb\x95\n\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCPC,18000.0,200,0.0,0.0,0.0,0.0,F...')])])
21:21:59,436 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:21:59,438 <kafka.protocol.parser>[DEBUG]: Received correlation id: 182
21:21:59,438 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:21:59,438 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 182 (2.9942989349365234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=180, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:59,438 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=180, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:21:59,438 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 180 log start offset 0 and error None.
21:21:59,440 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:21:59,756 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DP1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:21:59,759 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:00,81 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:00,83 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DTP,137500.0,200,0.0,0.0,0.0,0.0,False,0.0,13:38:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:00,83 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:00,83 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:00,83 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:00,84 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:00,84 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa8\xcb\xbf\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x97\x93\x00\x00\x01\x94\x12\xcb\x97\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDTP,137500.0,200,0.0,0.0,0.0,0.0,...')])])}
21:22:00,84 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:00,84 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa8\xcb\xbf\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x97\x93\x00\x00\x01\x94\x12\xcb\x97\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDTP,137500.0,200,0.0,0.0,0.0,0.0,...')])])
21:22:00,84 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa8\xcb\xbf\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x97\x93\x00\x00\x01\x94\x12\xcb\x97\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDTP,137500.0,200,0.0,0.0,0.0,0.0,...')])])
21:22:00,84 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 183: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa8\xcb\xbf\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x97\x93\x00\x00\x01\x94\x12\xcb\x97\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDTP,137500.0,200,0.0,0.0,0.0,0.0,...')])])
21:22:00,87 <kafka.protocol.parser>[DEBUG]: Received correlation id: 183
21:22:00,87 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:00,87 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 183 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=181, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:00,88 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=181, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:00,88 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 181 log start offset 0 and error None.
21:22:00,89 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:00,900 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CPH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:00,902 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:01,843 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CPI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:01,845 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CPI,4800.0,100,0.0,0.0,0.0,0.0,False,0.0,10:19:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:01,845 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:01,846 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:01,846 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:01,846 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:01,846 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02|\xda%\x9d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x9eu\x00\x00\x01\x94\x12\xcb\x9eu\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCPI,4800.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:22:01,846 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02|\xda%\x9d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x9eu\x00\x00\x01\x94\x12\xcb\x9eu\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCPI,4800.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:22:01,847 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02|\xda%\x9d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x9eu\x00\x00\x01\x94\x12\xcb\x9eu\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCPI,4800.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:22:01,846 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:01,847 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 184: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02|\xda%\x9d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\x9eu\x00\x00\x01\x94\x12\xcb\x9eu\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCPI,4800.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:22:01,849 <kafka.protocol.parser>[DEBUG]: Received correlation id: 184
21:22:01,850 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:01,850 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 184 (3.0074119567871094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=182, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:01,850 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=182, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:01,850 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 182 log start offset 0 and error None.
21:22:01,851 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:02,274 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CIA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:02,276 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CIA,10000.0,100,-100.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:02,276 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:02,276 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:02,276 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:02,276 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:02,277 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:02,277 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02[H\xe8\xe6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa0$\x00\x00\x01\x94\x12\xcb\xa0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCIA,10000.0,100,-100.0,0.0,0.0,0....')])])}
21:22:02,277 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02[H\xe8\xe6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa0$\x00\x00\x01\x94\x12\xcb\xa0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCIA,10000.0,100,-100.0,0.0,0.0,0....')])])
21:22:02,277 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02[H\xe8\xe6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa0$\x00\x00\x01\x94\x12\xcb\xa0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCIA,10000.0,100,-100.0,0.0,0.0,0....')])])
21:22:02,277 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 185: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02[H\xe8\xe6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa0$\x00\x00\x01\x94\x12\xcb\xa0$\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCIA,10000.0,100,-100.0,0.0,0.0,0....')])])
21:22:02,280 <kafka.protocol.parser>[DEBUG]: Received correlation id: 185
21:22:02,280 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:02,280 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 185 (3.0002593994140625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=183, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:02,280 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=183, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:02,280 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 183 log start offset 0 and error None.
21:22:02,281 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:03,331 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CRC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:03,426 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CRC,6790.0,1400,-10.0,0.0,0.0,0.0,False,10.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:03,426 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:03,426 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:03,427 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:03,427 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02W\xab\xf6\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa4\xa2\x00\x00\x01\x94\x12\xcb\xa4\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCRC,6790.0,1400,-10.0,0.0,0.0,0.0...')])])}
21:22:03,427 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02W\xab\xf6\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa4\xa2\x00\x00\x01\x94\x12\xcb\xa4\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCRC,6790.0,1400,-10.0,0.0,0.0,0.0...')])])
21:22:03,427 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:03,427 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02W\xab\xf6\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa4\xa2\x00\x00\x01\x94\x12\xcb\xa4\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCRC,6790.0,1400,-10.0,0.0,0.0,0.0...')])])
21:22:03,427 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:03,427 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 186: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02W\xab\xf6\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa4\xa2\x00\x00\x01\x94\x12\xcb\xa4\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCRC,6790.0,1400,-10.0,0.0,0.0,0.0...')])])
21:22:03,430 <kafka.protocol.parser>[DEBUG]: Received correlation id: 186
21:22:03,430 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:03,430 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 186 (2.028226852416992 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=184, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:03,431 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=184, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:03,431 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 184 log start offset 0 and error None.
21:22:03,432 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:03,752 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CSC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:03,755 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CSC,28600.0,2700,0.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:03,755 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:03,755 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:03,755 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:03,755 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:03,755 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x13\x99\x7fn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa5\xeb\x00\x00\x01\x94\x12\xcb\xa5\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCSC,28600.0,2700,0.0,0.0,0.0,0.0,...')])])}
21:22:03,756 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x13\x99\x7fn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa5\xeb\x00\x00\x01\x94\x12\xcb\xa5\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCSC,28600.0,2700,0.0,0.0,0.0,0.0,...')])])
21:22:03,756 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:03,756 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x13\x99\x7fn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa5\xeb\x00\x00\x01\x94\x12\xcb\xa5\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCSC,28600.0,2700,0.0,0.0,0.0,0.0,...')])])
21:22:03,756 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 187: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x13\x99\x7fn\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa5\xeb\x00\x00\x01\x94\x12\xcb\xa5\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCSC,28600.0,2700,0.0,0.0,0.0,0.0,...')])])
21:22:03,759 <kafka.protocol.parser>[DEBUG]: Received correlation id: 187
21:22:03,759 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:03,759 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 187 (1.9991397857666016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=185, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:03,759 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=185, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:03,760 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 185 log start offset 0 and error None.
21:22:03,762 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:04,468 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/SGP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:04,471 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'SGP,28400.0,200,700.0,0.0,0.0,0.0,False,200.0,14:58:34' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:04,471 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:04,471 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:04,471 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:04,471 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:04,471 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0`?\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa8\xb7\x00\x00\x01\x94\x12\xcb\xa8\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lSGP,28400.0,200,700.0,0.0,0.0,0.0...')])])}
21:22:04,472 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0`?\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa8\xb7\x00\x00\x01\x94\x12\xcb\xa8\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lSGP,28400.0,200,700.0,0.0,0.0,0.0...')])])
21:22:04,472 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:04,472 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0`?\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa8\xb7\x00\x00\x01\x94\x12\xcb\xa8\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lSGP,28400.0,200,700.0,0.0,0.0,0.0...')])])
21:22:04,472 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 188: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa0`?\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xa8\xb7\x00\x00\x01\x94\x12\xcb\xa8\xb7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lSGP,28400.0,200,700.0,0.0,0.0,0.0...')])])
21:22:04,475 <kafka.protocol.parser>[DEBUG]: Received correlation id: 188
21:22:04,475 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:04,475 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 188 (2.977609634399414 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=186, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:04,475 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=186, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:04,475 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 186 log start offset 0 and error None.
21:22:04,477 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:05,763 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CSM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:05,765 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CSM,15600.0,111600,-100.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:05,765 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:05,765 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:05,765 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:05,765 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:05,765 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85"\xe7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xad\xc5\x00\x00\x01\x94\x12\xcb\xad\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCSM,15600.0,111600,-100.0,0.0,0.0...')])])}
21:22:05,766 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85"\xe7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xad\xc5\x00\x00\x01\x94\x12\xcb\xad\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCSM,15600.0,111600,-100.0,0.0,0.0...')])])
21:22:05,766 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85"\xe7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xad\xc5\x00\x00\x01\x94\x12\xcb\xad\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCSM,15600.0,111600,-100.0,0.0,0.0...')])])
21:22:05,766 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 189: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85"\xe7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xad\xc5\x00\x00\x01\x94\x12\xcb\xad\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCSM,15600.0,111600,-100.0,0.0,0.0...')])])
21:22:05,766 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:05,769 <kafka.protocol.parser>[DEBUG]: Received correlation id: 189
21:22:05,769 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:05,769 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 189 (2.9633045196533203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=187, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:05,769 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=187, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:05,769 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 187 log start offset 0 and error None.
21:22:05,770 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:06,130 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CSV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:06,132 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CSV,46150.0,95800,150.0,0.0,0.0,0.0,True,-500.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:06,132 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:06,132 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:06,133 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:06,133 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:06,133 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02Y\xe5\xd3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xaf4\x00\x00\x01\x94\x12\xcb\xaf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCSV,46150.0,95800,150.0,0.0,0.0,0...')])])}
21:22:06,133 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02Y\xe5\xd3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xaf4\x00\x00\x01\x94\x12\xcb\xaf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCSV,46150.0,95800,150.0,0.0,0.0,0...')])])
21:22:06,133 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:06,134 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02Y\xe5\xd3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xaf4\x00\x00\x01\x94\x12\xcb\xaf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCSV,46150.0,95800,150.0,0.0,0.0,0...')])])
21:22:06,134 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 190: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02Y\xe5\xd3\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xaf4\x00\x00\x01\x94\x12\xcb\xaf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pCSV,46150.0,95800,150.0,0.0,0.0,0...')])])
21:22:06,136 <kafka.protocol.parser>[DEBUG]: Received correlation id: 190
21:22:06,137 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:06,137 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 190 (3.008604049682617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=188, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:06,137 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=188, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:06,137 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 188 log start offset 0 and error None.
21:22:06,139 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:11,738 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CT3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:11,740 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CT3,9900.0,100,900.0,0.1,0.0,0.0,False,0.0,10:10:40' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:11,740 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:11,741 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:11,741 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:11,741 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:11,741 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02-o3\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc5\x1d\x00\x00\x01\x94\x12\xcb\xc5\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCT3,9900.0,100,900.0,0.1,0.0,0.0,...')])])}
21:22:11,742 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02-o3\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc5\x1d\x00\x00\x01\x94\x12\xcb\xc5\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCT3,9900.0,100,900.0,0.1,0.0,0.0,...')])])
21:22:11,742 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02-o3\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc5\x1d\x00\x00\x01\x94\x12\xcb\xc5\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCT3,9900.0,100,900.0,0.1,0.0,0.0,...')])])
21:22:11,741 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:11,742 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 191: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02-o3\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc5\x1d\x00\x00\x01\x94\x12\xcb\xc5\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fCT3,9900.0,100,900.0,0.1,0.0,0.0,...')])])
21:22:11,745 <kafka.protocol.parser>[DEBUG]: Received correlation id: 191
21:22:11,745 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:11,745 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 191 (3.1480789184570312 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=189, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:11,745 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=189, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:11,745 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 189 log start offset 0 and error None.
21:22:11,747 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:12,291 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CT6/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:12,293 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CT6,10200.0,200,1000.0,0.1,0.0,0.0,False,0.0,10:05:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:12,293 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:12,293 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:12,294 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:12,294 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02wq\x94\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc7E\x00\x00\x01\x94\x12\xcb\xc7E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCT6,10200.0,200,1000.0,0.1,0.0,0....')])])}
21:22:12,294 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02wq\x94\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc7E\x00\x00\x01\x94\x12\xcb\xc7E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCT6,10200.0,200,1000.0,0.1,0.0,0....')])])
21:22:12,295 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02wq\x94\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc7E\x00\x00\x01\x94\x12\xcb\xc7E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCT6,10200.0,200,1000.0,0.1,0.0,0....')])])
21:22:12,295 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:12,295 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 192: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02wq\x94\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xc7E\x00\x00\x01\x94\x12\xcb\xc7E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCT6,10200.0,200,1000.0,0.1,0.0,0....')])])
21:22:12,295 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:12,297 <kafka.protocol.parser>[DEBUG]: Received correlation id: 192
21:22:12,298 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:12,298 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 192 (3.0069351196289062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=190, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:12,298 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=190, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:12,298 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 190 log start offset 0 and error None.
21:22:12,299 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:12,807 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:12,809 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:13,973 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:13,975 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTB,19800.0,300,-1700.0,-0.1,0.0,0.0,False,0.0,13:53:48' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:13,975 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:13,975 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:13,975 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:13,975 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:13,976 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02A"s\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xcd\xd7\x00\x00\x01\x94\x12\xcb\xcd\xd7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCTB,19800.0,300,-1700.0,-0.1,0.0,...')])])}
21:22:13,976 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02A"s\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xcd\xd7\x00\x00\x01\x94\x12\xcb\xcd\xd7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCTB,19800.0,300,-1700.0,-0.1,0.0,...')])])
21:22:13,976 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02A"s\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xcd\xd7\x00\x00\x01\x94\x12\xcb\xcd\xd7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCTB,19800.0,300,-1700.0,-0.1,0.0,...')])])
21:22:13,976 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:13,976 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 193: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02A"s\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xcd\xd7\x00\x00\x01\x94\x12\xcb\xcd\xd7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCTB,19800.0,300,-1700.0,-0.1,0.0,...')])])
21:22:13,979 <kafka.protocol.parser>[DEBUG]: Received correlation id: 193
21:22:13,979 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:13,979 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 193 (3.0226707458496094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=191, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:13,979 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=191, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:13,980 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 191 log start offset 0 and error None.
21:22:13,981 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:15,525 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:15,527 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:15,828 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:15,830 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTD,68200.0,87800,-800.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:15,831 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:15,831 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:15,831 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:15,831 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:15,832 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa9_5l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd5\x17\x00\x00\x01\x94\x12\xcb\xd5\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTD,68200.0,87800,-800.0,0.0,0.0,...')])])}
21:22:15,831 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:15,832 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa9_5l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd5\x17\x00\x00\x01\x94\x12\xcb\xd5\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTD,68200.0,87800,-800.0,0.0,0.0,...')])])
21:22:15,832 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa9_5l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd5\x17\x00\x00\x01\x94\x12\xcb\xd5\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTD,68200.0,87800,-800.0,0.0,0.0,...')])])
21:22:15,832 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 194: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa9_5l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd5\x17\x00\x00\x01\x94\x12\xcb\xd5\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTD,68200.0,87800,-800.0,0.0,0.0,...')])])
21:22:15,835 <kafka.protocol.parser>[DEBUG]: Received correlation id: 194
21:22:15,835 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:15,835 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 194 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=192, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:15,836 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=192, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:15,836 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 192 log start offset 0 and error None.
21:22:15,838 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:16,209 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:16,211 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTF,21950.0,47400,550.0,0.0,0.0,0.0,True,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:16,211 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:16,211 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:16,212 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:16,212 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa7tk)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd6\x93\x00\x00\x01\x94\x12\xcb\xd6\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCTF,21950.0,47400,550.0,0.0,0.0,0...')])])}
21:22:16,212 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:16,212 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa7tk)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd6\x93\x00\x00\x01\x94\x12\xcb\xd6\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCTF,21950.0,47400,550.0,0.0,0.0,0...')])])
21:22:16,212 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa7tk)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd6\x93\x00\x00\x01\x94\x12\xcb\xd6\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCTF,21950.0,47400,550.0,0.0,0.0,0...')])])
21:22:16,212 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 195: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xa7tk)\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd6\x93\x00\x00\x01\x94\x12\xcb\xd6\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lCTF,21950.0,47400,550.0,0.0,0.0,0...')])])
21:22:16,213 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:16,214 <kafka.protocol.parser>[DEBUG]: Received correlation id: 195
21:22:16,215 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:16,215 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 195 (3.0024051666259766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=193, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:16,215 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=193, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:16,215 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 193 log start offset 0 and error None.
21:22:16,217 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:16,702 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:16,704 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTG,38800.0,1842800,600.0,0.0,0.0,0.0,True,350.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:16,704 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:16,704 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:16,704 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:16,704 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:16,704 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x85Q\xc4\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd8\x80\x00\x00\x01\x94\x12\xcb\xd8\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTG,38800.0,1842800,600.0,0.0,0.0...')])])}
21:22:16,705 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x85Q\xc4\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd8\x80\x00\x00\x01\x94\x12\xcb\xd8\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTG,38800.0,1842800,600.0,0.0,0.0...')])])
21:22:16,705 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:16,705 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x85Q\xc4\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd8\x80\x00\x00\x01\x94\x12\xcb\xd8\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTG,38800.0,1842800,600.0,0.0,0.0...')])])
21:22:16,705 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 196: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x85Q\xc4\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xd8\x80\x00\x00\x01\x94\x12\xcb\xd8\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTG,38800.0,1842800,600.0,0.0,0.0...')])])
21:22:16,708 <kafka.protocol.parser>[DEBUG]: Received correlation id: 196
21:22:16,708 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:16,708 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 196 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=194, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:16,709 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=194, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:16,709 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 194 log start offset 0 and error None.
21:22:16,710 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:17,644 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GTS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:17,646 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:17,996 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:17,998 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTI,19000.0,143900,-850.0,0.0,0.0,0.0,True,-100.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:17,998 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:17,998 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:17,998 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:17,999 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:17,999 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xb3\xa4\xa3<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xdd\x8e\x00\x00\x01\x94\x12\xcb\xdd\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCTI,19000.0,143900,-850.0,0.0,0....')])])}
21:22:17,999 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xb3\xa4\xa3<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xdd\x8e\x00\x00\x01\x94\x12\xcb\xdd\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCTI,19000.0,143900,-850.0,0.0,0....')])])
21:22:17,999 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xb3\xa4\xa3<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xdd\x8e\x00\x00\x01\x94\x12\xcb\xdd\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCTI,19000.0,143900,-850.0,0.0,0....')])])
21:22:17,999 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:18,0 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 197: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xb3\xa4\xa3<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xdd\x8e\x00\x00\x01\x94\x12\xcb\xdd\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tCTI,19000.0,143900,-850.0,0.0,0....')])])
21:22:18,2 <kafka.protocol.parser>[DEBUG]: Received correlation id: 197
21:22:18,2 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:18,3 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 197 (3.000497817993164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=195, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:18,3 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=195, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:18,3 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 195 log start offset 0 and error None.
21:22:18,4 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:19,337 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ICT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:19,339 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ICT,13800.0,1500,-50.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:19,339 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:19,339 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:19,340 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:19,340 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:19,340 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x028\x11\x9f\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe2\xcb\x00\x00\x01\x94\x12\xcb\xe2\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICT,13800.0,1500,-50.0,0.0,0.0,0....')])])}
21:22:19,340 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:19,341 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x028\x11\x9f\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe2\xcb\x00\x00\x01\x94\x12\xcb\xe2\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICT,13800.0,1500,-50.0,0.0,0.0,0....')])])
21:22:19,341 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x028\x11\x9f\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe2\xcb\x00\x00\x01\x94\x12\xcb\xe2\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICT,13800.0,1500,-50.0,0.0,0.0,0....')])])
21:22:19,341 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 198: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x028\x11\x9f\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe2\xcb\x00\x00\x01\x94\x12\xcb\xe2\xcb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pICT,13800.0,1500,-50.0,0.0,0.0,0....')])])
21:22:19,344 <kafka.protocol.parser>[DEBUG]: Received correlation id: 198
21:22:19,344 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:19,344 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 198 (2.9625892639160156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=196, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:19,344 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=196, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:19,344 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 196 log start offset 0 and error None.
21:22:19,345 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:19,650 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:19,652 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:20,927 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:20,929 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTP,29500.0,8000,0.0,0.0,0.0,0.0,True,400.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:20,929 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:20,930 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:20,930 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:20,930 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:20,930 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02F!W\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe9\x02\x00\x00\x01\x94\x12\xcb\xe9\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCTP,29500.0,8000,0.0,0.0,0.0,0.0,...')])])}
21:22:20,930 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02F!W\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe9\x02\x00\x00\x01\x94\x12\xcb\xe9\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCTP,29500.0,8000,0.0,0.0,0.0,0.0,...')])])
21:22:20,930 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:20,931 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02F!W\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe9\x02\x00\x00\x01\x94\x12\xcb\xe9\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCTP,29500.0,8000,0.0,0.0,0.0,0.0,...')])])
21:22:20,931 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 199: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02F!W\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xe9\x02\x00\x00\x01\x94\x12\xcb\xe9\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCTP,29500.0,8000,0.0,0.0,0.0,0.0,...')])])
21:22:20,933 <kafka.protocol.parser>[DEBUG]: Received correlation id: 199
21:22:20,933 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:20,933 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 199 (2.199411392211914 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=197, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:20,933 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=197, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:20,934 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 197 log start offset 0 and error None.
21:22:20,935 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:22,799 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:22,801 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTR,122900.0,63400,-2100.0,0.0,0.0,0.0,True,-600.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:22,801 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:22,801 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:22,802 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:22,802 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xca\xa1\xa8\xe8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf0Q\x00\x00\x01\x94\x12\xcb\xf0Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCTR,122900.0,63400,-2100.0,0.0,0...')])])}
21:22:22,802 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xca\xa1\xa8\xe8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf0Q\x00\x00\x01\x94\x12\xcb\xf0Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCTR,122900.0,63400,-2100.0,0.0,0...')])])
21:22:22,802 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:22,802 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xca\xa1\xa8\xe8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf0Q\x00\x00\x01\x94\x12\xcb\xf0Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCTR,122900.0,63400,-2100.0,0.0,0...')])])
21:22:22,802 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 200: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xca\xa1\xa8\xe8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf0Q\x00\x00\x01\x94\x12\xcb\xf0Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vCTR,122900.0,63400,-2100.0,0.0,0...')])])
21:22:22,803 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:22,805 <kafka.protocol.parser>[DEBUG]: Received correlation id: 200
21:22:22,805 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:22,806 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 200 (2.997159957885742 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=198, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:22,806 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=198, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:22,806 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 198 log start offset 0 and error None.
21:22:22,808 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:23,99 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:23,102 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTS,35700.0,27800,-100.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:23,102 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:23,102 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:23,102 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:23,103 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:23,103 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:23,103 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02B\xad\r\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf1~\x00\x00\x01\x94\x12\xcb\xf1~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTS,35700.0,27800,-100.0,0.0,0.0,...')])])}
21:22:23,104 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02B\xad\r\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf1~\x00\x00\x01\x94\x12\xcb\xf1~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTS,35700.0,27800,-100.0,0.0,0.0,...')])])
21:22:23,104 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02B\xad\r\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf1~\x00\x00\x01\x94\x12\xcb\xf1~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTS,35700.0,27800,-100.0,0.0,0.0,...')])])
21:22:23,104 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 201: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02B\xad\r\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xf1~\x00\x00\x01\x94\x12\xcb\xf1~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rCTS,35700.0,27800,-100.0,0.0,0.0,...')])])
21:22:23,108 <kafka.protocol.parser>[DEBUG]: Received correlation id: 201
21:22:23,108 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:23,109 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 201 (4.663705825805664 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=199, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:23,109 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=199, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:23,109 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 199 log start offset 0 and error None.
21:22:23,111 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:26,514 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:26,519 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CTT,15000.0,700,0.0,0.0,0.0,0.0,False,0.0,11:10:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:26,519 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:26,520 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:26,521 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:26,521 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ms\x96\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xfe\xd8\x00\x00\x01\x94\x12\xcb\xfe\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCTT,15000.0,700,0.0,0.0,0.0,0.0,F...')])])}
21:22:26,521 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ms\x96\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xfe\xd8\x00\x00\x01\x94\x12\xcb\xfe\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCTT,15000.0,700,0.0,0.0,0.0,0.0,F...')])])
21:22:26,522 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ms\x96\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xfe\xd8\x00\x00\x01\x94\x12\xcb\xfe\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCTT,15000.0,700,0.0,0.0,0.0,0.0,F...')])])
21:22:26,522 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:26,522 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 202: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ms\x96\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcb\xfe\xd8\x00\x00\x01\x94\x12\xcb\xfe\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dCTT,15000.0,700,0.0,0.0,0.0,0.0,F...')])])
21:22:26,523 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:26,526 <kafka.protocol.parser>[DEBUG]: Received correlation id: 202
21:22:26,526 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:26,526 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 202 (3.2956600189208984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=200, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:26,526 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=200, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:26,526 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 200 log start offset 0 and error None.
21:22:26,527 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:26,808 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TTS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:26,810 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:28,142 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:28,144 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:28,533 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CTX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:28,534 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:29,66 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AUM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:29,68 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:30,342 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CVN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:30,344 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:30,652 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CVT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:30,654 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CVT,25750.0,400,-100.0,0.0,0.0,0.0,False,0.0,13:30:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:30,654 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:30,654 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:30,654 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:30,654 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:30,655 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:30,655 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x93d\x99\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x0e\xfe\x00\x00\x01\x94\x12\xcc\x0e\xfe\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCVT,25750.0,400,-100.0,0.0,0.0,0....')])])}
21:22:30,655 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x93d\x99\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x0e\xfe\x00\x00\x01\x94\x12\xcc\x0e\xfe\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCVT,25750.0,400,-100.0,0.0,0.0,0....')])])
21:22:30,655 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x93d\x99\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x0e\xfe\x00\x00\x01\x94\x12\xcc\x0e\xfe\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCVT,25750.0,400,-100.0,0.0,0.0,0....')])])
21:22:30,655 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 203: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x93d\x99\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x0e\xfe\x00\x00\x01\x94\x12\xcc\x0e\xfe\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jCVT,25750.0,400,-100.0,0.0,0.0,0....')])])
21:22:30,658 <kafka.protocol.parser>[DEBUG]: Received correlation id: 203
21:22:30,658 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:30,658 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 203 (2.0110607147216797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=201, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:30,659 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=201, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:30,659 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 201 log start offset 0 and error None.
21:22:30,661 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:31,353 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CX8/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:31,355 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CX8,8300.0,300,0.0,0.0,0.0,0.0,False,0.0,14:27:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:31,356 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:31,356 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:31,356 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:31,356 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:31,357 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb0\xfb\xe5\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x11\xbc\x00\x00\x01\x94\x12\xcc\x11\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCX8,8300.0,300,0.0,0.0,0.0,0.0,Fa...')])])}
21:22:31,357 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:31,357 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb0\xfb\xe5\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x11\xbc\x00\x00\x01\x94\x12\xcc\x11\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCX8,8300.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:22:31,357 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb0\xfb\xe5\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x11\xbc\x00\x00\x01\x94\x12\xcc\x11\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCX8,8300.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:22:31,357 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 204: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xb0\xfb\xe5\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x11\xbc\x00\x00\x01\x94\x12\xcc\x11\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bCX8,8300.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:22:31,360 <kafka.protocol.parser>[DEBUG]: Received correlation id: 204
21:22:31,360 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:31,360 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 204 (2.007722854614258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=202, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:31,360 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=202, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:31,361 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 202 log start offset 0 and error None.
21:22:31,362 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:31,678 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CYC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:31,680 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:32,660 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/D11/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:32,662 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'D11,10100.0,100,-100.0,0.0,0.0,0.0,False,0.0,09:21:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:32,662 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:32,662 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:32,662 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:32,663 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:32,663 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:32,663 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}O2#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x16\xd6\x00\x00\x01\x94\x12\xcc\x16\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jD11,10100.0,100,-100.0,0.0,0.0,0....')])])}
21:22:32,663 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}O2#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x16\xd6\x00\x00\x01\x94\x12\xcc\x16\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jD11,10100.0,100,-100.0,0.0,0.0,0....')])])
21:22:32,663 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}O2#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x16\xd6\x00\x00\x01\x94\x12\xcc\x16\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jD11,10100.0,100,-100.0,0.0,0.0,0....')])])
21:22:32,664 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 205: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02}O2#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x16\xd6\x00\x00\x01\x94\x12\xcc\x16\xd6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jD11,10100.0,100,-100.0,0.0,0.0,0....')])])
21:22:32,666 <kafka.protocol.parser>[DEBUG]: Received correlation id: 205
21:22:32,666 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:32,666 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 205 (2.004861831665039 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=203, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:32,667 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=203, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:32,667 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 203 log start offset 0 and error None.
21:22:32,668 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:32,963 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/D2D/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:32,965 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'D2D,31600.0,3300,-300.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:32,965 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:32,966 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:32,966 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:32,966 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:32,966 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa2d\xbd\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x18\x05\x00\x00\x01\x94\x12\xcc\x18\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rD2D,31600.0,3300,-300.0,0.0,0.0,0...')])])}
21:22:32,966 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa2d\xbd\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x18\x05\x00\x00\x01\x94\x12\xcc\x18\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rD2D,31600.0,3300,-300.0,0.0,0.0,0...')])])
21:22:32,966 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa2d\xbd\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x18\x05\x00\x00\x01\x94\x12\xcc\x18\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rD2D,31600.0,3300,-300.0,0.0,0.0,0...')])])
21:22:32,966 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 206: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa2d\xbd\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x18\x05\x00\x00\x01\x94\x12\xcc\x18\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rD2D,31600.0,3300,-300.0,0.0,0.0,0...')])])
21:22:32,967 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:32,969 <kafka.protocol.parser>[DEBUG]: Received correlation id: 206
21:22:32,969 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:32,969 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 206 (1.9946098327636719 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=204, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:32,969 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=204, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:32,970 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 204 log start offset 0 and error None.
21:22:32,971 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:33,297 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:33,302 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:34,742 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:34,744 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:35,206 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:35,208 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DAD,21100.0,1000,-100.0,0.0,0.0,0.0,False,-300.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:35,208 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:35,209 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:35,209 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:35,209 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd3\x18\xc9$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc \xc9\x00\x00\x01\x94\x12\xcc \xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDAD,21100.0,1000,-100.0,0.0,0.0,0...')])])}
21:22:35,209 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd3\x18\xc9$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc \xc9\x00\x00\x01\x94\x12\xcc \xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDAD,21100.0,1000,-100.0,0.0,0.0,0...')])])
21:22:35,209 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:35,209 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd3\x18\xc9$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc \xc9\x00\x00\x01\x94\x12\xcc \xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDAD,21100.0,1000,-100.0,0.0,0.0,0...')])])
21:22:35,210 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 207: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd3\x18\xc9$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc \xc9\x00\x00\x01\x94\x12\xcc \xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDAD,21100.0,1000,-100.0,0.0,0.0,0...')])])
21:22:35,210 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:35,212 <kafka.protocol.parser>[DEBUG]: Received correlation id: 207
21:22:35,212 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:35,212 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 207 (2.033233642578125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=205, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:35,212 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=205, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:35,212 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 205 log start offset 0 and error None.
21:22:35,214 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:35,506 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:35,508 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:35,941 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:35,943 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:36,238 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:36,240 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:37,92 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:37,867 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DAH,3540.0,13000,-20.0,0.0,0.0,0.0,False,10.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:37,867 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:37,867 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:37,868 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:37,868 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:37,869 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02y\x1a\xf7/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc++\x00\x00\x01\x94\x12\xcc++\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDAH,3540.0,13000,-20.0,0.0,0.0,0....')])])}
21:22:37,869 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02y\x1a\xf7/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc++\x00\x00\x01\x94\x12\xcc++\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDAH,3540.0,13000,-20.0,0.0,0.0,0....')])])
21:22:37,869 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02y\x1a\xf7/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc++\x00\x00\x01\x94\x12\xcc++\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDAH,3540.0,13000,-20.0,0.0,0.0,0....')])])
21:22:37,870 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 208: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02y\x1a\xf7/\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc++\x00\x00\x01\x94\x12\xcc++\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDAH,3540.0,13000,-20.0,0.0,0.0,0....')])])
21:22:37,870 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:37,874 <kafka.protocol.parser>[DEBUG]: Received correlation id: 208
21:22:37,874 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:37,874 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 208 (3.9780139923095703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=206, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:37,875 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=206, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:37,875 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 206 log start offset 0 and error None.
21:22:37,877 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:41,131 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DRG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:41,225 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DRG,7600.0,100,0.0,0.0,0.0,0.0,False,0.0,14:34:31' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:41,225 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:41,225 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:41,225 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:41,225 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:41,225 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02!ka\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc8I\x00\x00\x01\x94\x12\xcc8I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDRG,7600.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:22:41,225 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02!ka\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc8I\x00\x00\x01\x94\x12\xcc8I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDRG,7600.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:22:41,226 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02!ka\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc8I\x00\x00\x01\x94\x12\xcc8I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDRG,7600.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:22:41,226 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 209: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02!ka\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc8I\x00\x00\x01\x94\x12\xcc8I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDRG,7600.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:22:41,226 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:41,228 <kafka.protocol.parser>[DEBUG]: Received correlation id: 209
21:22:41,228 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:41,228 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 209 (1.9750595092773438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=207, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:41,229 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=207, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:41,229 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 207 log start offset 0 and error None.
21:22:41,230 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:42,6 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DRI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:42,9 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DRI,12500.0,200,-100.0,0.0,0.0,0.0,False,0.0,14:59:22' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:42,9 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:42,10 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:42,10 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:42,10 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:42,11 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:42,11 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02F\x1cE\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc;Z\x00\x00\x01\x94\x12\xcc;Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDRI,12500.0,200,-100.0,0.0,0.0,0....')])])}
21:22:42,11 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02F\x1cE\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc;Z\x00\x00\x01\x94\x12\xcc;Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDRI,12500.0,200,-100.0,0.0,0.0,0....')])])
21:22:42,12 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02F\x1cE\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc;Z\x00\x00\x01\x94\x12\xcc;Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDRI,12500.0,200,-100.0,0.0,0.0,0....')])])
21:22:42,12 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 210: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02F\x1cE\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc;Z\x00\x00\x01\x94\x12\xcc;Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDRI,12500.0,200,-100.0,0.0,0.0,0....')])])
21:22:42,16 <kafka.protocol.parser>[DEBUG]: Received correlation id: 210
21:22:42,16 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:42,16 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 210 (4.010915756225586 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=208, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:42,16 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=208, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:42,17 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 208 log start offset 0 and error None.
21:22:42,19 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:43,332 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/UDL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:43,335 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:44,855 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DWC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:44,942 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:45,265 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:45,273 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DHB,9600.0,100,100.0,0.0,0.0,0.0,False,100.0,14:41:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:45,273 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:45,274 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:45,275 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:45,276 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:45,277 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02:\xb0j\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccH\x1a\x00\x00\x01\x94\x12\xccH\x1a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDHB,9600.0,100,100.0,0.0,0.0,0.0,...')])])}
21:22:45,277 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:45,278 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02:\xb0j\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccH\x1a\x00\x00\x01\x94\x12\xccH\x1a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDHB,9600.0,100,100.0,0.0,0.0,0.0,...')])])
21:22:45,279 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02:\xb0j\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccH\x1a\x00\x00\x01\x94\x12\xccH\x1a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDHB,9600.0,100,100.0,0.0,0.0,0.0,...')])])
21:22:45,280 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 211: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02:\xb0j\xdd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccH\x1a\x00\x00\x01\x94\x12\xccH\x1a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDHB,9600.0,100,100.0,0.0,0.0,0.0,...')])])
21:22:45,289 <kafka.protocol.parser>[DEBUG]: Received correlation id: 211
21:22:45,289 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:45,290 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 211 (9.603023529052734 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=209, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:45,291 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=209, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:45,291 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 209 log start offset 0 and error None.
21:22:45,295 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:45,952 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ADS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:45,954 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ADS,8800.0,30900,-90.0,0.0,0.0,0.0,True,-180.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:45,954 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:45,954 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:45,954 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:45,955 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:45,955 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x83\xfe\x9c\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccJ\xc2\x00\x00\x01\x94\x12\xccJ\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nADS,8800.0,30900,-90.0,0.0,0.0,0....')])])}
21:22:45,955 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x83\xfe\x9c\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccJ\xc2\x00\x00\x01\x94\x12\xccJ\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nADS,8800.0,30900,-90.0,0.0,0.0,0....')])])
21:22:45,955 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x83\xfe\x9c\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccJ\xc2\x00\x00\x01\x94\x12\xccJ\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nADS,8800.0,30900,-90.0,0.0,0.0,0....')])])
21:22:45,955 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:45,955 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 212: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x83\xfe\x9c\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccJ\xc2\x00\x00\x01\x94\x12\xccJ\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nADS,8800.0,30900,-90.0,0.0,0.0,0....')])])
21:22:45,958 <kafka.protocol.parser>[DEBUG]: Received correlation id: 212
21:22:45,958 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:45,958 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 212 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=210, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:45,958 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=210, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:45,958 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 210 log start offset 0 and error None.
21:22:45,960 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:48,601 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:48,606 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:50,30 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:50,37 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:50,343 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:50,351 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:51,193 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:51,202 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:51,524 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:51,529 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DPG,46350.0,69300,-1400.0,0.0,0.0,0.0,True,-100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:51,529 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:51,529 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:51,530 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:51,530 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02S\x86)\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc`\x89\x00\x00\x01\x94\x12\xcc`\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDPG,46350.0,69300,-1400.0,0.0,0....')])])}
21:22:51,530 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:51,530 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02S\x86)\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc`\x89\x00\x00\x01\x94\x12\xcc`\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDPG,46350.0,69300,-1400.0,0.0,0....')])])
21:22:51,530 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:51,531 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02S\x86)\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc`\x89\x00\x00\x01\x94\x12\xcc`\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDPG,46350.0,69300,-1400.0,0.0,0....')])])
21:22:51,531 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 213: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02S\x86)\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc`\x89\x00\x00\x01\x94\x12\xcc`\x89\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDPG,46350.0,69300,-1400.0,0.0,0....')])])
21:22:51,533 <kafka.protocol.parser>[DEBUG]: Received correlation id: 213
21:22:51,533 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:51,533 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 213 (2.360105514526367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=211, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:51,534 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=211, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:51,534 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 211 log start offset 0 and error None.
21:22:51,535 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:51,887 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:51,889 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DBC,28550.0,322800,50.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:51,889 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:51,890 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:51,890 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:51,890 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xa2\x1aA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcca\xf2\x00\x00\x01\x94\x12\xcca\xf2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDBC,28550.0,322800,50.0,0.0,0.0,0...')])])}
21:22:51,890 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xa2\x1aA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcca\xf2\x00\x00\x01\x94\x12\xcca\xf2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDBC,28550.0,322800,50.0,0.0,0.0,0...')])])
21:22:51,890 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xa2\x1aA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcca\xf2\x00\x00\x01\x94\x12\xcca\xf2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDBC,28550.0,322800,50.0,0.0,0.0,0...')])])
21:22:51,891 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 214: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xa2\x1aA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcca\xf2\x00\x00\x01\x94\x12\xcca\xf2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDBC,28550.0,322800,50.0,0.0,0.0,0...')])])
21:22:51,891 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:51,891 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:51,894 <kafka.protocol.parser>[DEBUG]: Received correlation id: 214
21:22:51,894 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:51,894 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 214 (3.007650375366211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=212, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:51,894 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=212, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:51,894 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 212 log start offset 0 and error None.
21:22:51,896 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:52,301 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TDB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:52,303 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:53,610 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DBM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:53,612 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:54,384 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DBT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:54,386 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DBT,12150.0,400,-50.0,0.0,0.0,0.0,False,0.0,14:14:51' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:54,386 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:54,386 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:54,386 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:54,387 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:54,387 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x029\xda\xdd\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcck\xb2\x00\x00\x01\x94\x12\xcck\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDBT,12150.0,400,-50.0,0.0,0.0,0.0...')])])}
21:22:54,387 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x029\xda\xdd\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcck\xb2\x00\x00\x01\x94\x12\xcck\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDBT,12150.0,400,-50.0,0.0,0.0,0.0...')])])
21:22:54,387 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x029\xda\xdd\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcck\xb2\x00\x00\x01\x94\x12\xcck\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDBT,12150.0,400,-50.0,0.0,0.0,0.0...')])])
21:22:54,387 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:54,387 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 215: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x029\xda\xdd\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcck\xb2\x00\x00\x01\x94\x12\xcck\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDBT,12150.0,400,-50.0,0.0,0.0,0.0...')])])
21:22:54,390 <kafka.protocol.parser>[DEBUG]: Received correlation id: 215
21:22:54,390 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:54,390 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 215 (2.000093460083008 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=213, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:54,390 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=213, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:54,391 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 213 log start offset 0 and error None.
21:22:54,392 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:56,850 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DC2/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:56,852 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:57,203 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DC4/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:57,205 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DC4,13750.0,48400,-300.0,0.0,0.0,0.0,True,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:57,205 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:57,206 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:57,206 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:57,206 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:57,206 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xff\xbfR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccv\xb6\x00\x00\x01\x94\x12\xccv\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDC4,13750.0,48400,-300.0,0.0,0.0,...')])])}
21:22:57,206 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xff\xbfR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccv\xb6\x00\x00\x01\x94\x12\xccv\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDC4,13750.0,48400,-300.0,0.0,0.0,...')])])
21:22:57,206 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:57,206 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xff\xbfR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccv\xb6\x00\x00\x01\x94\x12\xccv\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDC4,13750.0,48400,-300.0,0.0,0.0,...')])])
21:22:57,207 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 216: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xff\xbfR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccv\xb6\x00\x00\x01\x94\x12\xccv\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDC4,13750.0,48400,-300.0,0.0,0.0,...')])])
21:22:57,210 <kafka.protocol.parser>[DEBUG]: Received correlation id: 216
21:22:57,210 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:57,210 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 216 (2.9540061950683594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=214, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:57,210 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=214, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:57,210 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 214 log start offset 0 and error None.
21:22:57,212 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:57,941 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:57,943 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DCL,27100.0,14000,200.0,0.0,0.0,0.0,True,200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:57,944 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:57,944 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:57,944 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:57,944 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:57,944 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc5\x84\x10\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccy\x98\x00\x00\x01\x94\x12\xccy\x98\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDCL,27100.0,14000,200.0,0.0,0.0,0...')])])}
21:22:57,944 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc5\x84\x10\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccy\x98\x00\x00\x01\x94\x12\xccy\x98\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDCL,27100.0,14000,200.0,0.0,0.0,0...')])])
21:22:57,944 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc5\x84\x10\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccy\x98\x00\x00\x01\x94\x12\xccy\x98\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDCL,27100.0,14000,200.0,0.0,0.0,0...')])])
21:22:57,945 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 217: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc5\x84\x10\xa2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xccy\x98\x00\x00\x01\x94\x12\xccy\x98\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDCL,27100.0,14000,200.0,0.0,0.0,0...')])])
21:22:57,945 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:57,947 <kafka.protocol.parser>[DEBUG]: Received correlation id: 217
21:22:57,947 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:57,947 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 217 (1.9636154174804688 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=215, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:57,948 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=215, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:57,948 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 215 log start offset 0 and error None.
21:22:57,949 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:58,379 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:58,382 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DCM,36300.0,155800,-50.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:58,382 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:58,382 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:58,382 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:58,382 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:58,383 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa6Z9Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc{N\x00\x00\x01\x94\x12\xcc{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDCM,36300.0,155800,-50.0,0.0,0.0,...')])])}
21:22:58,383 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa6Z9Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc{N\x00\x00\x01\x94\x12\xcc{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDCM,36300.0,155800,-50.0,0.0,0.0,...')])])
21:22:58,383 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa6Z9Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc{N\x00\x00\x01\x94\x12\xcc{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDCM,36300.0,155800,-50.0,0.0,0.0,...')])])
21:22:58,383 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:58,383 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 218: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xa6Z9Q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc{N\x00\x00\x01\x94\x12\xcc{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDCM,36300.0,155800,-50.0,0.0,0.0,...')])])
21:22:58,386 <kafka.protocol.parser>[DEBUG]: Received correlation id: 218
21:22:58,386 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:58,386 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 218 (3.0024051666259766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=216, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:58,386 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=216, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:58,386 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 216 log start offset 0 and error None.
21:22:58,388 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:59,662 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:22:59,665 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DCS,900.0,1700,0.0,0.0,0.0,0.0,False,0.0,14:59:28' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:22:59,665 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:22:59,665 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:22:59,665 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:22:59,666 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:22:59,666 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1e\x1aj\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x80Q\x00\x00\x01\x94\x12\xcc\x80Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDCS,900.0,1700,0.0,0.0,0.0,0.0,Fa...')])])}
21:22:59,666 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1e\x1aj\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x80Q\x00\x00\x01\x94\x12\xcc\x80Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDCS,900.0,1700,0.0,0.0,0.0,0.0,Fa...')])])
21:22:59,666 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1e\x1aj\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x80Q\x00\x00\x01\x94\x12\xcc\x80Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDCS,900.0,1700,0.0,0.0,0.0,0.0,Fa...')])])
21:22:59,667 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 219: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x1e\x1aj\xfc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x80Q\x00\x00\x01\x94\x12\xcc\x80Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDCS,900.0,1700,0.0,0.0,0.0,0.0,Fa...')])])
21:22:59,667 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:22:59,670 <kafka.protocol.parser>[DEBUG]: Received correlation id: 219
21:22:59,671 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:22:59,671 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 219 (4.013299942016602 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=217, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:59,671 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=217, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:22:59,671 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 217 log start offset 0 and error None.
21:22:59,673 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:22:59,975 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:00,367 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DCT,600.0,2000,100.0,0.2,0.0,0.0,False,0.0,13:00:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:00,367 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:00,368 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:00,368 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:00,368 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:00,368 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x99\xe8\x83v\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x83\x0f\x00\x00\x01\x94\x12\xcc\x83\x0f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDCT,600.0,2000,100.0,0.2,0.0,0.0,...')])])}
21:23:00,368 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x99\xe8\x83v\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x83\x0f\x00\x00\x01\x94\x12\xcc\x83\x0f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDCT,600.0,2000,100.0,0.2,0.0,0.0,...')])])
21:23:00,368 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:00,368 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x99\xe8\x83v\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x83\x0f\x00\x00\x01\x94\x12\xcc\x83\x0f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDCT,600.0,2000,100.0,0.2,0.0,0.0,...')])])
21:23:00,369 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 220: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x99\xe8\x83v\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x83\x0f\x00\x00\x01\x94\x12\xcc\x83\x0f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDCT,600.0,2000,100.0,0.2,0.0,0.0,...')])])
21:23:00,371 <kafka.protocol.parser>[DEBUG]: Received correlation id: 220
21:23:00,372 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:00,372 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 220 (2.99835205078125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=218, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:00,372 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=218, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:00,372 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 218 log start offset 0 and error None.
21:23:00,373 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:00,701 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VBG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:00,704 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:01,72 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DDM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:01,455 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DDM,2000.0,5600,200.0,0.1,0.0,0.0,False,200.0,14:22:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:01,455 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:01,455 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:01,455 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:01,456 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:01,456 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x0e\xfa\xe9u\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x87O\x00\x00\x01\x94\x12\xcc\x87O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDDM,2000.0,5600,200.0,0.1,0.0,0.0...')])])}
21:23:01,457 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:01,457 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x0e\xfa\xe9u\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x87O\x00\x00\x01\x94\x12\xcc\x87O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDDM,2000.0,5600,200.0,0.1,0.0,0.0...')])])
21:23:01,457 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x0e\xfa\xe9u\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x87O\x00\x00\x01\x94\x12\xcc\x87O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDDM,2000.0,5600,200.0,0.1,0.0,0.0...')])])
21:23:01,457 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 221: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x0e\xfa\xe9u\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x87O\x00\x00\x01\x94\x12\xcc\x87O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDDM,2000.0,5600,200.0,0.1,0.0,0.0...')])])
21:23:01,461 <kafka.protocol.parser>[DEBUG]: Received correlation id: 221
21:23:01,461 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:01,461 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 221 (3.0031204223632812 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=219, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:01,461 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=219, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:01,462 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 219 log start offset 0 and error None.
21:23:01,463 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:04,61 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DDN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:04,68 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DDN,7800.0,100,100.0,0.0,0.0,0.0,False,0.0,09:58:34' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:04,69 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:04,70 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:04,70 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:04,71 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:04,72 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02~md\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x91\x85\x00\x00\x01\x94\x12\xcc\x91\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDDN,7800.0,100,100.0,0.0,0.0,0.0,...')])])}
21:23:04,73 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02~md\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x91\x85\x00\x00\x01\x94\x12\xcc\x91\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDDN,7800.0,100,100.0,0.0,0.0,0.0,...')])])
21:23:04,73 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02~md\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x91\x85\x00\x00\x01\x94\x12\xcc\x91\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDDN,7800.0,100,100.0,0.0,0.0,0.0,...')])])
21:23:04,74 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 222: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02~md\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x91\x85\x00\x00\x01\x94\x12\xcc\x91\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDDN,7800.0,100,100.0,0.0,0.0,0.0,...')])])
21:23:04,75 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:04,81 <kafka.protocol.parser>[DEBUG]: Received correlation id: 222
21:23:04,82 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:04,82 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 222 (8.196353912353516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=220, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:04,82 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=220, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:04,82 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 220 log start offset 0 and error None.
21:23:04,85 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:05,233 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DDV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:05,236 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DDV,19800.0,20000,-100.0,0.0,0.0,0.0,True,-100.0,14:59:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:05,237 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:05,237 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:05,237 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:05,237 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:05,237 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1dI!x\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x96\x15\x00\x00\x01\x94\x12\xcc\x96\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDDV,19800.0,20000,-100.0,0.0,0.0,...')])])}
21:23:05,238 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:05,238 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1dI!x\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x96\x15\x00\x00\x01\x94\x12\xcc\x96\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDDV,19800.0,20000,-100.0,0.0,0.0,...')])])
21:23:05,238 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1dI!x\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x96\x15\x00\x00\x01\x94\x12\xcc\x96\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDDV,19800.0,20000,-100.0,0.0,0.0,...')])])
21:23:05,238 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 223: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1dI!x\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x96\x15\x00\x00\x01\x94\x12\xcc\x96\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDDV,19800.0,20000,-100.0,0.0,0.0,...')])])
21:23:05,245 <kafka.protocol.parser>[DEBUG]: Received correlation id: 223
21:23:05,245 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:05,245 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 223 (7.000207901000977 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=221, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:05,245 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=221, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:05,246 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 221 log start offset 0 and error None.
21:23:05,247 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:05,758 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:06,152 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:06,708 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DM7/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:06,710 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:07,591 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DFF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:07,593 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DFF,1700.0,1000,0.0,0.0,0.0,0.0,False,0.0,14:33:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:07,593 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:07,594 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:07,594 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:07,594 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:07,594 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02:\xce\x12\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x9fI\x00\x00\x01\x94\x12\xcc\x9fI\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDFF,1700.0,1000,0.0,0.0,0.0,0.0,F...')])])}
21:23:07,594 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02:\xce\x12\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x9fI\x00\x00\x01\x94\x12\xcc\x9fI\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDFF,1700.0,1000,0.0,0.0,0.0,0.0,F...')])])
21:23:07,594 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02:\xce\x12\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x9fI\x00\x00\x01\x94\x12\xcc\x9fI\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDFF,1700.0,1000,0.0,0.0,0.0,0.0,F...')])])
21:23:07,594 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:07,595 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 224: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02:\xce\x12\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\x9fI\x00\x00\x01\x94\x12\xcc\x9fI\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDFF,1700.0,1000,0.0,0.0,0.0,0.0,F...')])])
21:23:07,597 <kafka.protocol.parser>[DEBUG]: Received correlation id: 224
21:23:07,597 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:07,597 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 224 (2.009868621826172 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=222, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:07,598 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=222, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:07,598 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 222 log start offset 0 and error None.
21:23:07,599 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:08,317 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DGC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:08,319 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DGC,117000.0,319400,-600.0,0.0,0.0,0.0,True,-600.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:08,319 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:08,319 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:08,319 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:08,320 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:08,320 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc1{\x99\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xa2\x1f\x00\x00\x01\x94\x12\xcc\xa2\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDGC,117000.0,319400,-600.0,0.0,0...')])])}
21:23:08,320 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:08,320 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc1{\x99\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xa2\x1f\x00\x00\x01\x94\x12\xcc\xa2\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDGC,117000.0,319400,-600.0,0.0,0...')])])
21:23:08,320 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc1{\x99\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xa2\x1f\x00\x00\x01\x94\x12\xcc\xa2\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDGC,117000.0,319400,-600.0,0.0,0...')])])
21:23:08,320 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 225: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc1{\x99\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xa2\x1f\x00\x00\x01\x94\x12\xcc\xa2\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDGC,117000.0,319400,-600.0,0.0,0...')])])
21:23:08,329 <kafka.protocol.parser>[DEBUG]: Received correlation id: 225
21:23:08,329 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:08,329 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 225 (7.999897003173828 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=223, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:08,330 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=223, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:08,330 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 223 log start offset 0 and error None.
21:23:08,331 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:13,744 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DGT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:13,746 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DGT,6100.0,100,-200.0,0.0,0.0,0.0,False,100.0,14:59:39' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:13,746 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:13,746 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:13,746 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:13,747 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:13,747 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x90\xf8\xf6\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb7R\x00\x00\x01\x94\x12\xcc\xb7R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDGT,6100.0,100,-200.0,0.0,0.0,0.0...')])])}
21:23:13,747 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x90\xf8\xf6\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb7R\x00\x00\x01\x94\x12\xcc\xb7R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDGT,6100.0,100,-200.0,0.0,0.0,0.0...')])])
21:23:13,747 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:13,747 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x90\xf8\xf6\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb7R\x00\x00\x01\x94\x12\xcc\xb7R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDGT,6100.0,100,-200.0,0.0,0.0,0.0...')])])
21:23:13,747 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 226: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x90\xf8\xf6\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb7R\x00\x00\x01\x94\x12\xcc\xb7R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDGT,6100.0,100,-200.0,0.0,0.0,0.0...')])])
21:23:13,750 <kafka.protocol.parser>[DEBUG]: Received correlation id: 226
21:23:13,750 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:13,750 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 226 (3.003358840942383 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=224, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:13,750 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=224, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:13,750 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 224 log start offset 0 and error None.
21:23:13,751 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:14,309 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DGW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:14,312 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DGW,40850.0,52400,-150.0,0.0,0.0,0.0,True,-150.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,312 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,312 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:14,312 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:14,312 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:14,313 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x93w\xaa`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb9\x88\x00\x00\x01\x94\x12\xcc\xb9\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDGW,40850.0,52400,-150.0,0.0,0.0,...')])])}
21:23:14,313 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x93w\xaa`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb9\x88\x00\x00\x01\x94\x12\xcc\xb9\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDGW,40850.0,52400,-150.0,0.0,0.0,...')])])
21:23:14,313 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x93w\xaa`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb9\x88\x00\x00\x01\x94\x12\xcc\xb9\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDGW,40850.0,52400,-150.0,0.0,0.0,...')])])
21:23:14,313 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 227: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x93w\xaa`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xb9\x88\x00\x00\x01\x94\x12\xcc\xb9\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDGW,40850.0,52400,-150.0,0.0,0.0,...')])])
21:23:14,313 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,315 <kafka.protocol.parser>[DEBUG]: Received correlation id: 227
21:23:14,316 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:14,316 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 227 (3.0007362365722656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=225, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:14,316 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=225, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:14,316 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 225 log start offset 0 and error None.
21:23:14,317 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:14,643 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:14,644 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DHA,44400.0,700,-400.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,645 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,645 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:14,645 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:14,645 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:14,645 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,645 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x94n\xe7\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xba\xd5\x00\x00\x01\x94\x12\xcc\xba\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDHA,44400.0,700,-400.0,0.0,0.0,0....')])])}
21:23:14,646 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x94n\xe7\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xba\xd5\x00\x00\x01\x94\x12\xcc\xba\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDHA,44400.0,700,-400.0,0.0,0.0,0....')])])
21:23:14,646 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x94n\xe7\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xba\xd5\x00\x00\x01\x94\x12\xcc\xba\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDHA,44400.0,700,-400.0,0.0,0.0,0....')])])
21:23:14,646 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 228: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x94n\xe7\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xba\xd5\x00\x00\x01\x94\x12\xcc\xba\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDHA,44400.0,700,-400.0,0.0,0.0,0....')])])
21:23:14,648 <kafka.protocol.parser>[DEBUG]: Received correlation id: 228
21:23:14,648 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:14,648 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 228 (1.9676685333251953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=226, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:14,649 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=226, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:14,649 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 226 log start offset 0 and error None.
21:23:14,650 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:14,976 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:14,978 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DHC,38300.0,25000,-300.0,0.0,0.0,0.0,True,100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,978 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,978 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:14,978 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:14,978 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:14,978 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xfc\xca\xfe"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xbc"\x00\x00\x01\x94\x12\xcc\xbc"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHC,38300.0,25000,-300.0,0.0,0.0,...')])])}
21:23:14,979 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xfc\xca\xfe"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xbc"\x00\x00\x01\x94\x12\xcc\xbc"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHC,38300.0,25000,-300.0,0.0,0.0,...')])])
21:23:14,979 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xfc\xca\xfe"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xbc"\x00\x00\x01\x94\x12\xcc\xbc"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHC,38300.0,25000,-300.0,0.0,0.0,...')])])
21:23:14,979 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:14,979 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 229: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xfc\xca\xfe"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xbc"\x00\x00\x01\x94\x12\xcc\xbc"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHC,38300.0,25000,-300.0,0.0,0.0,...')])])
21:23:14,981 <kafka.protocol.parser>[DEBUG]: Received correlation id: 229
21:23:14,982 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:14,982 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 229 (2.9604434967041016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=227, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:14,982 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=227, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:14,982 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 227 log start offset 0 and error None.
21:23:14,983 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:16,689 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:16,691 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DHG,104000.0,2900,-1800.0,0.0,0.0,0.0,True,-500.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:16,692 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:16,692 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:16,692 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:16,692 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:16,692 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x027)\x009\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc2\xd4\x00\x00\x01\x94\x12\xcc\xc2\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDHG,104000.0,2900,-1800.0,0.0,0....')])])}
21:23:16,692 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x027)\x009\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc2\xd4\x00\x00\x01\x94\x12\xcc\xc2\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDHG,104000.0,2900,-1800.0,0.0,0....')])])
21:23:16,693 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x027)\x009\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc2\xd4\x00\x00\x01\x94\x12\xcc\xc2\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDHG,104000.0,2900,-1800.0,0.0,0....')])])
21:23:16,693 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:16,693 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 230: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x027)\x009\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc2\xd4\x00\x00\x01\x94\x12\xcc\xc2\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDHG,104000.0,2900,-1800.0,0.0,0....')])])
21:23:16,695 <kafka.protocol.parser>[DEBUG]: Received correlation id: 230
21:23:16,696 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:16,696 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 230 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=228, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:16,696 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=228, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:16,696 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 228 log start offset 0 and error None.
21:23:16,697 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:17,996 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:17,998 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DHM,8500.0,100,0.0,0.0,0.0,0.0,False,10.0,14:28:28' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:17,998 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:17,998 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:17,999 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:17,999 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:17,999 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02)\xdc\x99*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc7\xee\x00\x00\x01\x94\x12\xcc\xc7\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDHM,8500.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:23:17,999 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02)\xdc\x99*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc7\xee\x00\x00\x01\x94\x12\xcc\xc7\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDHM,8500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:23:17,999 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02)\xdc\x99*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc7\xee\x00\x00\x01\x94\x12\xcc\xc7\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDHM,8500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:23:17,999 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 231: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02)\xdc\x99*\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xc7\xee\x00\x00\x01\x94\x12\xcc\xc7\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDHM,8500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:23:18,0 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:18,2 <kafka.protocol.parser>[DEBUG]: Received correlation id: 231
21:23:18,2 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:18,2 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 231 (1.9915103912353516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=229, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:18,2 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=229, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:18,2 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 229 log start offset 0 and error None.
21:23:18,4 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:18,803 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:18,805 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:19,531 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:19,533 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DHT,99200.0,58000,-300.0,0.0,0.0,0.0,True,400.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:19,533 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:19,534 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:19,534 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:19,534 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:19,534 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa2\xd1<\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcd\xed\x00\x00\x01\x94\x12\xcc\xcd\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHT,99200.0,58000,-300.0,0.0,0.0,...')])])}
21:23:19,534 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa2\xd1<\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcd\xed\x00\x00\x01\x94\x12\xcc\xcd\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHT,99200.0,58000,-300.0,0.0,0.0,...')])])
21:23:19,534 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:19,535 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa2\xd1<\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcd\xed\x00\x00\x01\x94\x12\xcc\xcd\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHT,99200.0,58000,-300.0,0.0,0.0,...')])])
21:23:19,535 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 232: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa2\xd1<\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcd\xed\x00\x00\x01\x94\x12\xcc\xcd\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDHT,99200.0,58000,-300.0,0.0,0.0,...')])])
21:23:19,537 <kafka.protocol.parser>[DEBUG]: Received correlation id: 232
21:23:19,537 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:19,538 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 232 (2.9997825622558594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=230, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:19,538 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=230, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:19,538 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 230 log start offset 0 and error None.
21:23:19,540 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:19,982 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DIC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:19,984 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DIC,1000.0,2000,0.0,0.0,0.0,0.0,False,100.0,14:31:43' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:19,984 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:19,984 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:19,984 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:19,985 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:19,985 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb04U\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcf\xb0\x00\x00\x01\x94\x12\xcc\xcf\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDIC,1000.0,2000,0.0,0.0,0.0,0.0,F...')])])}
21:23:19,985 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb04U\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcf\xb0\x00\x00\x01\x94\x12\xcc\xcf\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDIC,1000.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:23:19,985 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:19,985 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb04U\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcf\xb0\x00\x00\x01\x94\x12\xcc\xcf\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDIC,1000.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:23:19,986 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 233: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb04U\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xcf\xb0\x00\x00\x01\x94\x12\xcc\xcf\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDIC,1000.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:23:19,988 <kafka.protocol.parser>[DEBUG]: Received correlation id: 233
21:23:19,988 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:19,988 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 233 (1.9936561584472656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=231, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:19,988 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=231, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:19,988 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 231 log start offset 0 and error None.
21:23:19,989 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:20,291 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DC1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:20,292 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:20,613 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DID/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:20,620 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DID,4400.0,300,0.0,0.0,0.0,0.0,False,0.0,14:25:56' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:20,620 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:20,620 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:20,620 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:20,620 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:20,620 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xd6\x94W\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd2,\x00\x00\x01\x94\x12\xcc\xd2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDID,4400.0,300,0.0,0.0,0.0,0.0,Fa...')])])}
21:23:20,620 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:20,620 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xd6\x94W\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd2,\x00\x00\x01\x94\x12\xcc\xd2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDID,4400.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:23:20,623 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xd6\x94W\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd2,\x00\x00\x01\x94\x12\xcc\xd2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDID,4400.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:23:20,624 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 234: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xd6\x94W\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd2,\x00\x00\x01\x94\x12\xcc\xd2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bDID,4400.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:23:20,631 <kafka.protocol.parser>[DEBUG]: Received correlation id: 234
21:23:20,631 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:20,631 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 234 (7.219791412353516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=232, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:20,631 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=232, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:20,631 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 232 log start offset 0 and error None.
21:23:20,631 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:20,961 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TTE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:20,963 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:21,317 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DIG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:21,320 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DIG,19000.0,1017700,-200.0,0.0,0.0,0.0,True,-50.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:21,320 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:21,320 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:21,320 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:21,320 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:21,320 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:21,320 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x024#[\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd4\xe8\x00\x00\x01\x94\x12\xcc\xd4\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDIG,19000.0,1017700,-200.0,0.0,0...')])])}
21:23:21,321 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x024#[\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd4\xe8\x00\x00\x01\x94\x12\xcc\xd4\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDIG,19000.0,1017700,-200.0,0.0,0...')])])
21:23:21,321 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x024#[\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd4\xe8\x00\x00\x01\x94\x12\xcc\xd4\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDIG,19000.0,1017700,-200.0,0.0,0...')])])
21:23:21,321 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 235: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x024#[\xda\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xd4\xe8\x00\x00\x01\x94\x12\xcc\xd4\xe8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDIG,19000.0,1017700,-200.0,0.0,0...')])])
21:23:21,324 <kafka.protocol.parser>[DEBUG]: Received correlation id: 235
21:23:21,324 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:21,324 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 235 (3.0028820037841797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=233, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:21,324 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=233, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:21,325 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 233 log start offset 0 and error None.
21:23:21,326 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:22,156 <kafka.client>[DEBUG]: Sending metadata request MetadataRequest_v1(topics=['realtimeStockData']) to node 1
21:23:22,156 <kafka.protocol.parser>[DEBUG]: Sending request MetadataRequest_v1(topics=['realtimeStockData'])
21:23:22,156 <kafka.conn>[DEBUG]: <BrokerConnection node_id=1 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Request 1: MetadataRequest_v1(topics=['realtimeStockData'])
21:23:22,159 <kafka.protocol.parser>[DEBUG]: Received correlation id: 1
21:23:22,159 <kafka.protocol.parser>[DEBUG]: Processing response MetadataResponse_v1
21:23:22,159 <kafka.conn>[DEBUG]: <BrokerConnection node_id=1 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Response 1 (2.998828887939453 ms): MetadataResponse_v1(brokers=[(node_id=2, host='localhost', port=29092, rack=None), (node_id=3, host='localhost', port=39092, rack=None), (node_id=1, host='localhost', port=19092, rack=None)], controller_id=1, topics=[(error_code=0, topic='realtimeStockData', is_internal=False, partitions=[(error_code=0, partition=0, leader=2, replicas=[2], isr=[2])])])
21:23:22,159 <kafka.cluster>[DEBUG]: Updated cluster metadata to ClusterMetadata(brokers: 3, topics: 1, groups: 0)
21:23:28,177 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DIH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:28,179 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DIH,16000.0,700,0.0,0.0,0.0,0.0,False,0.0,13:34:25' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:28,180 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:28,180 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:28,180 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:28,180 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:28,180 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xef\xc4\xd4\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xef\xb4\x00\x00\x01\x94\x12\xcc\xef\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDIH,16000.0,700,0.0,0.0,0.0,0.0,F...')])])}
21:23:28,180 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xef\xc4\xd4\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xef\xb4\x00\x00\x01\x94\x12\xcc\xef\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDIH,16000.0,700,0.0,0.0,0.0,0.0,F...')])])
21:23:28,180 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xef\xc4\xd4\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xef\xb4\x00\x00\x01\x94\x12\xcc\xef\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDIH,16000.0,700,0.0,0.0,0.0,0.0,F...')])])
21:23:28,181 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:28,181 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 236: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xef\xc4\xd4\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xef\xb4\x00\x00\x01\x94\x12\xcc\xef\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDIH,16000.0,700,0.0,0.0,0.0,0.0,F...')])])
21:23:28,183 <kafka.protocol.parser>[DEBUG]: Received correlation id: 236
21:23:28,183 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:28,183 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 236 (2.032041549682617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=234, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:28,185 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=234, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:28,185 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 234 log start offset 0 and error None.
21:23:28,185 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:30,934 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DL1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:31,40 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DL1,5300.0,10800,0.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:31,40 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:31,40 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:31,40 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:31,41 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:31,41 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:31,41 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02/\xb3\xccK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xfa\xe0\x00\x00\x01\x94\x12\xcc\xfa\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDL1,5300.0,10800,0.0,0.0,0.0,0.0,...')])])}
21:23:31,41 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02/\xb3\xccK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xfa\xe0\x00\x00\x01\x94\x12\xcc\xfa\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDL1,5300.0,10800,0.0,0.0,0.0,0.0,...')])])
21:23:31,41 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02/\xb3\xccK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xfa\xe0\x00\x00\x01\x94\x12\xcc\xfa\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDL1,5300.0,10800,0.0,0.0,0.0,0.0,...')])])
21:23:31,42 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 237: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02/\xb3\xccK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcc\xfa\xe0\x00\x00\x01\x94\x12\xcc\xfa\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDL1,5300.0,10800,0.0,0.0,0.0,0.0,...')])])
21:23:31,79 <kafka.protocol.parser>[DEBUG]: Received correlation id: 237
21:23:31,79 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:31,79 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 237 (37.001848220825195 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=235, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:31,80 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=235, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:31,80 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 235 log start offset 0 and error None.
21:23:31,81 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:31,930 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DLD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:31,932 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:33,316 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DLG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:33,400 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DLG,2130.0,7400,30.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:33,400 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:33,400 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:33,400 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:33,400 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:33,400 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:33,400 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02O\x90\x9e]\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x04\x18\x00\x00\x01\x94\x12\xcd\x04\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDLG,2130.0,7400,30.0,0.0,0.0,0.0,...')])])}
21:23:33,401 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02O\x90\x9e]\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x04\x18\x00\x00\x01\x94\x12\xcd\x04\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDLG,2130.0,7400,30.0,0.0,0.0,0.0,...')])])
21:23:33,401 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02O\x90\x9e]\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x04\x18\x00\x00\x01\x94\x12\xcd\x04\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDLG,2130.0,7400,30.0,0.0,0.0,0.0,...')])])
21:23:33,401 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 238: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02O\x90\x9e]\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x04\x18\x00\x00\x01\x94\x12\xcd\x04\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDLG,2130.0,7400,30.0,0.0,0.0,0.0,...')])])
21:23:33,403 <kafka.protocol.parser>[DEBUG]: Received correlation id: 238
21:23:33,403 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:33,403 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 238 (2.0020008087158203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=236, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:33,404 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=236, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:33,404 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 236 log start offset 0 and error None.
21:23:33,405 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:34,135 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DLM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:34,137 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:34,430 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DLR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:34,432 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:34,686 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DUS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:34,692 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:34,955 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:34,958 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DMC,68000.0,100,700.0,0.0,0.0,0.0,False,0.0,13:22:37' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:34,958 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:34,958 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:34,958 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:34,959 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:34,959 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02*d\x04e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\n.\x00\x00\x01\x94\x12\xcd\n.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDMC,68000.0,100,700.0,0.0,0.0,0.0...')])])}
21:23:34,959 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02*d\x04e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\n.\x00\x00\x01\x94\x12\xcd\n.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDMC,68000.0,100,700.0,0.0,0.0,0.0...')])])
21:23:34,959 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02*d\x04e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\n.\x00\x00\x01\x94\x12\xcd\n.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDMC,68000.0,100,700.0,0.0,0.0,0.0...')])])
21:23:34,959 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 239: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02*d\x04e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\n.\x00\x00\x01\x94\x12\xcd\n.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDMC,68000.0,100,700.0,0.0,0.0,0.0...')])])
21:23:34,959 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:34,962 <kafka.protocol.parser>[DEBUG]: Received correlation id: 239
21:23:34,962 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:34,962 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 239 (3.2100677490234375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=237, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:34,962 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=237, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:34,962 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 237 log start offset 0 and error None.
21:23:34,964 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:35,531 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NSS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:35,533 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:35,826 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:35,828 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DNC,68000.0,300,0.0,0.0,0.0,0.0,False,3000.0,14:18:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:35,828 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:35,828 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:35,828 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:35,829 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:35,829 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x80\xe4\xd2\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\r\x94\x00\x00\x01\x94\x12\xcd\r\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDNC,68000.0,300,0.0,0.0,0.0,0.0,F...')])])}
21:23:35,829 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x80\xe4\xd2\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\r\x94\x00\x00\x01\x94\x12\xcd\r\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDNC,68000.0,300,0.0,0.0,0.0,0.0,F...')])])
21:23:35,829 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x80\xe4\xd2\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\r\x94\x00\x00\x01\x94\x12\xcd\r\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDNC,68000.0,300,0.0,0.0,0.0,0.0,F...')])])
21:23:35,829 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 240: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x80\xe4\xd2\x18\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\r\x94\x00\x00\x01\x94\x12\xcd\r\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDNC,68000.0,300,0.0,0.0,0.0,0.0,F...')])])
21:23:35,829 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:35,832 <kafka.protocol.parser>[DEBUG]: Received correlation id: 240
21:23:35,832 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:35,832 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 240 (2.555370330810547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=238, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:35,833 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=238, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:35,833 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 238 log start offset 0 and error None.
21:23:35,834 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:36,157 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:36,160 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:38,50 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:38,52 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:38,755 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:38,757 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:39,100 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:39,102 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DNM,8000.0,100,500.0,0.1,0.0,0.0,False,0.0,09:49:44' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:39,102 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:39,102 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:39,103 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:39,103 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:39,103 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:39,103 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x9fl5\x1b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1a^\x00\x00\x01\x94\x12\xcd\x1a^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDNM,8000.0,100,500.0,0.1,0.0,0.0,...')])])}
21:23:39,103 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x9fl5\x1b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1a^\x00\x00\x01\x94\x12\xcd\x1a^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDNM,8000.0,100,500.0,0.1,0.0,0.0,...')])])
21:23:39,103 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x9fl5\x1b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1a^\x00\x00\x01\x94\x12\xcd\x1a^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDNM,8000.0,100,500.0,0.1,0.0,0.0,...')])])
21:23:39,103 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 241: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x9fl5\x1b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1a^\x00\x00\x01\x94\x12\xcd\x1a^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDNM,8000.0,100,500.0,0.1,0.0,0.0,...')])])
21:23:39,108 <kafka.protocol.parser>[DEBUG]: Received correlation id: 241
21:23:39,109 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:39,109 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 241 (4.961967468261719 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=239, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:39,109 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=239, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:39,109 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 239 log start offset 0 and error None.
21:23:39,110 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:39,416 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DND/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:39,418 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DND,15500.0,100,-1500.0,-0.1,0.0,0.0,False,0.0,14:10:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:39,418 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:39,418 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:39,418 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:39,418 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:39,418 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf8\xd1]{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1b\x9a\x00\x00\x01\x94\x12\xcd\x1b\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDND,15500.0,100,-1500.0,-0.1,0.0,...')])])}
21:23:39,419 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf8\xd1]{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1b\x9a\x00\x00\x01\x94\x12\xcd\x1b\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDND,15500.0,100,-1500.0,-0.1,0.0,...')])])
21:23:39,419 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf8\xd1]{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1b\x9a\x00\x00\x01\x94\x12\xcd\x1b\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDND,15500.0,100,-1500.0,-0.1,0.0,...')])])
21:23:39,419 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 242: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf8\xd1]{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1b\x9a\x00\x00\x01\x94\x12\xcd\x1b\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDND,15500.0,100,-1500.0,-0.1,0.0,...')])])
21:23:39,419 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:39,422 <kafka.protocol.parser>[DEBUG]: Received correlation id: 242
21:23:39,422 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:39,422 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 242 (2.9637813568115234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=240, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:39,422 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=240, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:39,422 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 240 log start offset 0 and error None.
21:23:39,424 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:39,750 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:39,752 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:40,43 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:40,46 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:40,461 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CDN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:40,464 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CDN,33800.0,200,-100.0,0.0,0.0,0.0,False,100.0,14:21:43' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:40,464 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:40,464 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:40,464 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:40,465 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:40,465 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x16\x03\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1f\xb0\x00\x00\x01\x94\x12\xcd\x1f\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCDN,33800.0,200,-100.0,0.0,0.0,0....')])])}
21:23:40,465 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x16\x03\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1f\xb0\x00\x00\x01\x94\x12\xcd\x1f\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCDN,33800.0,200,-100.0,0.0,0.0,0....')])])
21:23:40,465 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:40,465 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x16\x03\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1f\xb0\x00\x00\x01\x94\x12\xcd\x1f\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCDN,33800.0,200,-100.0,0.0,0.0,0....')])])
21:23:40,465 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 243: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x16\x03\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x1f\xb0\x00\x00\x01\x94\x12\xcd\x1f\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nCDN,33800.0,200,-100.0,0.0,0.0,0....')])])
21:23:40,468 <kafka.protocol.parser>[DEBUG]: Received correlation id: 243
21:23:40,468 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:40,468 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 243 (1.9979476928710938 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=241, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:40,469 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=241, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:40,469 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 241 log start offset 0 and error None.
21:23:40,470 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:40,769 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DSC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:40,770 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DSC,16900.0,10500,-200.0,0.0,0.0,0.0,False,-200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:40,770 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:40,770 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:40,770 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:40,771 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:40,771 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02q\xb9\x92\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd \xe2\x00\x00\x01\x94\x12\xcd \xe2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDSC,16900.0,10500,-200.0,0.0,0.0...')])])}
21:23:40,771 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:40,771 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02q\xb9\x92\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd \xe2\x00\x00\x01\x94\x12\xcd \xe2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDSC,16900.0,10500,-200.0,0.0,0.0...')])])
21:23:40,771 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02q\xb9\x92\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd \xe2\x00\x00\x01\x94\x12\xcd \xe2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDSC,16900.0,10500,-200.0,0.0,0.0...')])])
21:23:40,772 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 244: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02q\xb9\x92\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd \xe2\x00\x00\x01\x94\x12\xcd \xe2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tDSC,16900.0,10500,-200.0,0.0,0.0...')])])
21:23:40,775 <kafka.protocol.parser>[DEBUG]: Received correlation id: 244
21:23:40,776 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:40,776 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 244 (4.036903381347656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=242, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:40,776 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=242, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:40,776 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 242 log start offset 0 and error None.
21:23:40,777 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:42,216 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DNT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:42,218 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:43,770 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DOC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:43,772 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:44,103 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:44,106 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:49,763 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BSD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:50,183 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:51,762 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DMN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:51,851 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DMN,5400.0,1000,-200.0,0.0,0.0,0.0,False,-100.0,14:58:11' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:51,851 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:51,851 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:51,852 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:51,852 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:51,852 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb4\xcaR\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdL+\x00\x00\x01\x94\x12\xcdL+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDMN,5400.0,1000,-200.0,0.0,0.0,0....')])])}
21:23:51,852 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:51,852 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb4\xcaR\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdL+\x00\x00\x01\x94\x12\xcdL+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDMN,5400.0,1000,-200.0,0.0,0.0,0....')])])
21:23:51,853 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb4\xcaR\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdL+\x00\x00\x01\x94\x12\xcdL+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDMN,5400.0,1000,-200.0,0.0,0.0,0....')])])
21:23:51,853 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 245: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xb4\xcaR\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdL+\x00\x00\x01\x94\x12\xcdL+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDMN,5400.0,1000,-200.0,0.0,0.0,0....')])])
21:23:51,855 <kafka.protocol.parser>[DEBUG]: Received correlation id: 245
21:23:51,856 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:51,856 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 245 (3.0019283294677734 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=243, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:51,856 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=243, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:51,856 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 243 log start offset 0 and error None.
21:23:51,858 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:52,451 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DOP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:52,453 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:52,756 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CDR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:52,758 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:53,239 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:53,241 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:54,571 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DWS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:54,573 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:55,264 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:55,349 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:56,367 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:56,420 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DPM,35600.0,274500,400.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:56,420 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:56,420 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:56,420 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:56,421 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:56,421 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:56,421 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02*i\t\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd^\x04\x00\x00\x01\x94\x12\xcd^\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDPM,35600.0,274500,400.0,0.0,0.0,...')])])}
21:23:56,421 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02*i\t\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd^\x04\x00\x00\x01\x94\x12\xcd^\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDPM,35600.0,274500,400.0,0.0,0.0,...')])])
21:23:56,421 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02*i\t\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd^\x04\x00\x00\x01\x94\x12\xcd^\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDPM,35600.0,274500,400.0,0.0,0.0,...')])])
21:23:56,422 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 246: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02*i\t\x15\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd^\x04\x00\x00\x01\x94\x12\xcd^\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDPM,35600.0,274500,400.0,0.0,0.0,...')])])
21:23:56,434 <kafka.protocol.parser>[DEBUG]: Received correlation id: 246
21:23:56,434 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:56,434 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 246 (11.99483871459961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=244, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:56,435 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=244, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:56,435 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 244 log start offset 0 and error None.
21:23:56,436 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:57,776 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:57,778 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:58,82 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:58,85 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DPR,38850.0,2200,0.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:58,85 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:58,85 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:58,85 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:58,85 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:58,85 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:58,86 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x067oO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdd\x85\x00\x00\x01\x94\x12\xcdd\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDPR,38850.0,2200,0.0,0.0,0.0,0.0,...')])])}
21:23:58,86 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x067oO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdd\x85\x00\x00\x01\x94\x12\xcdd\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDPR,38850.0,2200,0.0,0.0,0.0,0.0,...')])])
21:23:58,86 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x067oO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdd\x85\x00\x00\x01\x94\x12\xcdd\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDPR,38850.0,2200,0.0,0.0,0.0,0.0,...')])])
21:23:58,86 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 247: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x067oO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdd\x85\x00\x00\x01\x94\x12\xcdd\x85\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDPR,38850.0,2200,0.0,0.0,0.0,0.0,...')])])
21:23:58,88 <kafka.protocol.parser>[DEBUG]: Received correlation id: 247
21:23:58,89 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:58,89 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 247 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=245, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:58,89 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=245, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:58,89 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 245 log start offset 0 and error None.
21:23:58,90 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:58,928 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:59,18 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:59,311 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DP2/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:59,313 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:23:59,803 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DQC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:23:59,805 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DQC,12700.0,1500,-150.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:23:59,805 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:23:59,805 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:23:59,806 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:23:59,806 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:23:59,806 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02P\x03/\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdk=\x00\x00\x01\x94\x12\xcdk=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDQC,12700.0,1500,-150.0,0.0,0.0,0...')])])}
21:23:59,806 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02P\x03/\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdk=\x00\x00\x01\x94\x12\xcdk=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDQC,12700.0,1500,-150.0,0.0,0.0,0...')])])
21:23:59,806 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:23:59,807 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02P\x03/\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdk=\x00\x00\x01\x94\x12\xcdk=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDQC,12700.0,1500,-150.0,0.0,0.0,0...')])])
21:23:59,807 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 248: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02P\x03/\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcdk=\x00\x00\x01\x94\x12\xcdk=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDQC,12700.0,1500,-150.0,0.0,0.0,0...')])])
21:23:59,809 <kafka.protocol.parser>[DEBUG]: Received correlation id: 248
21:23:59,809 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:23:59,809 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 248 (2.144336700439453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=246, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:59,809 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=246, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:23:59,809 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 246 log start offset 0 and error None.
21:23:59,811 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:04,135 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DRC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:04,141 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DRC,29200.0,40600,-300.0,0.0,0.0,0.0,True,-200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:04,141 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:04,142 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:04,142 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:04,142 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:04,142 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:04,142 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02F4G\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd|.\x00\x00\x01\x94\x12\xcd|.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDRC,29200.0,40600,-300.0,0.0,0.0,...')])])}
21:24:04,144 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02F4G\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd|.\x00\x00\x01\x94\x12\xcd|.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDRC,29200.0,40600,-300.0,0.0,0.0,...')])])
21:24:04,144 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02F4G\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd|.\x00\x00\x01\x94\x12\xcd|.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDRC,29200.0,40600,-300.0,0.0,0.0,...')])])
21:24:04,145 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 249: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02F4G\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd|.\x00\x00\x01\x94\x12\xcd|.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rDRC,29200.0,40600,-300.0,0.0,0.0,...')])])
21:24:04,150 <kafka.protocol.parser>[DEBUG]: Received correlation id: 249
21:24:04,150 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:04,150 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 249 (5.956411361694336 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=247, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:04,150 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=247, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:04,150 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 247 log start offset 0 and error None.
21:24:04,153 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:04,441 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DRH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:04,443 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:05,229 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DRL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:05,231 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DRL,58000.0,400,500.0,0.0,0.0,0.0,False,0.0,14:05:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,231 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,231 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:05,231 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:05,232 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:05,232 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x90\xec\xc5e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x80o\x00\x00\x01\x94\x12\xcd\x80o\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDRL,58000.0,400,500.0,0.0,0.0,0.0...')])])}
21:24:05,232 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x90\xec\xc5e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x80o\x00\x00\x01\x94\x12\xcd\x80o\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDRL,58000.0,400,500.0,0.0,0.0,0.0...')])])
21:24:05,232 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,232 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x90\xec\xc5e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x80o\x00\x00\x01\x94\x12\xcd\x80o\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDRL,58000.0,400,500.0,0.0,0.0,0.0...')])])
21:24:05,233 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 250: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x90\xec\xc5e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x80o\x00\x00\x01\x94\x12\xcd\x80o\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDRL,58000.0,400,500.0,0.0,0.0,0.0...')])])
21:24:05,235 <kafka.protocol.parser>[DEBUG]: Received correlation id: 250
21:24:05,235 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:05,235 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 250 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=248, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:05,235 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=248, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:05,236 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 248 log start offset 0 and error None.
21:24:05,237 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:05,540 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DSN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:05,543 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DSN,53500.0,1000,-500.0,0.0,0.0,0.0,False,0.0,14:25:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,544 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,544 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:05,544 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:05,545 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:05,545 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,545 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05j\x05\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x81\xa8\x00\x00\x01\x94\x12\xcd\x81\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDSN,53500.0,1000,-500.0,0.0,0.0,0...')])])}
21:24:05,546 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05j\x05\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x81\xa8\x00\x00\x01\x94\x12\xcd\x81\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDSN,53500.0,1000,-500.0,0.0,0.0,0...')])])
21:24:05,546 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05j\x05\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x81\xa8\x00\x00\x01\x94\x12\xcd\x81\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDSN,53500.0,1000,-500.0,0.0,0.0,0...')])])
21:24:05,546 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 251: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x05j\x05\xab\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x81\xa8\x00\x00\x01\x94\x12\xcd\x81\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lDSN,53500.0,1000,-500.0,0.0,0.0,0...')])])
21:24:05,550 <kafka.protocol.parser>[DEBUG]: Received correlation id: 251
21:24:05,550 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:05,550 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 251 (3.9949417114257812 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=249, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:05,551 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=249, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:05,552 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 249 log start offset 0 and error None.
21:24:05,554 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:05,829 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DST/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:05,831 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DST,5600.0,1600,100.0,0.0,0.0,0.0,False,0.0,14:45:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,831 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,831 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:05,831 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:05,832 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:05,832 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02U&#\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x82\xc7\x00\x00\x01\x94\x12\xcd\x82\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDST,5600.0,1600,100.0,0.0,0.0,0.0...')])])}
21:24:05,832 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02U&#\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x82\xc7\x00\x00\x01\x94\x12\xcd\x82\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDST,5600.0,1600,100.0,0.0,0.0,0.0...')])])
21:24:05,832 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:05,832 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02U&#\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x82\xc7\x00\x00\x01\x94\x12\xcd\x82\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDST,5600.0,1600,100.0,0.0,0.0,0.0...')])])
21:24:05,832 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 252: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02U&#\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x82\xc7\x00\x00\x01\x94\x12\xcd\x82\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hDST,5600.0,1600,100.0,0.0,0.0,0.0...')])])
21:24:05,835 <kafka.protocol.parser>[DEBUG]: Received correlation id: 252
21:24:05,835 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:05,835 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 252 (2.014636993408203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=250, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:05,835 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=250, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:05,836 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 250 log start offset 0 and error None.
21:24:05,837 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:06,147 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DSV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:06,150 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:07,532 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:07,626 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DTA,4090.0,800,220.0,0.1,0.0,0.0,False,190.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:07,626 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:07,626 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:07,626 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:07,627 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:07,627 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xd8Q\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x89\xca\x00\x00\x01\x94\x12\xcd\x89\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTA,4090.0,800,220.0,0.1,0.0,0.0,...')])])}
21:24:07,627 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xd8Q\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x89\xca\x00\x00\x01\x94\x12\xcd\x89\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTA,4090.0,800,220.0,0.1,0.0,0.0,...')])])
21:24:07,627 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xd8Q\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x89\xca\x00\x00\x01\x94\x12\xcd\x89\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTA,4090.0,800,220.0,0.1,0.0,0.0,...')])])
21:24:07,627 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:07,627 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 253: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xd8Q\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x89\xca\x00\x00\x01\x94\x12\xcd\x89\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTA,4090.0,800,220.0,0.1,0.0,0.0,...')])])
21:24:07,630 <kafka.protocol.parser>[DEBUG]: Received correlation id: 253
21:24:07,630 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:07,630 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 253 (2.0172595977783203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=251, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:07,630 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=251, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:07,630 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 251 log start offset 0 and error None.
21:24:07,632 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:07,955 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BDT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:07,957 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BDT,7000.0,500,-200.0,0.0,0.0,0.0,False,100.0,14:24:44' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:07,957 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:07,957 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:07,958 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:07,958 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe9\xce\x88\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8b\x15\x00\x00\x01\x94\x12\xcd\x8b\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBDT,7000.0,500,-200.0,0.0,0.0,0.0...')])])}
21:24:07,958 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe9\xce\x88\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8b\x15\x00\x00\x01\x94\x12\xcd\x8b\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBDT,7000.0,500,-200.0,0.0,0.0,0.0...')])])
21:24:07,958 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:07,958 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe9\xce\x88\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8b\x15\x00\x00\x01\x94\x12\xcd\x8b\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBDT,7000.0,500,-200.0,0.0,0.0,0.0...')])])
21:24:07,958 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:07,959 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 254: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe9\xce\x88\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8b\x15\x00\x00\x01\x94\x12\xcd\x8b\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBDT,7000.0,500,-200.0,0.0,0.0,0.0...')])])
21:24:07,961 <kafka.protocol.parser>[DEBUG]: Received correlation id: 254
21:24:07,962 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:07,962 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 254 (2.987384796142578 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=252, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:07,962 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=252, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:07,962 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 252 log start offset 0 and error None.
21:24:07,963 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:08,351 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:08,353 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DTC,4700.0,400,100.0,0.0,0.0,0.0,False,100.0,14:18:57' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:08,354 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:08,354 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:08,354 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:08,354 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:08,354 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02EA)\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8c\xa2\x00\x00\x01\x94\x12\xcd\x8c\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTC,4700.0,400,100.0,0.0,0.0,0.0,...')])])}
21:24:08,354 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02EA)\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8c\xa2\x00\x00\x01\x94\x12\xcd\x8c\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTC,4700.0,400,100.0,0.0,0.0,0.0,...')])])
21:24:08,355 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02EA)\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8c\xa2\x00\x00\x01\x94\x12\xcd\x8c\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTC,4700.0,400,100.0,0.0,0.0,0.0,...')])])
21:24:08,355 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:08,355 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 255: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02EA)\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x8c\xa2\x00\x00\x01\x94\x12\xcd\x8c\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTC,4700.0,400,100.0,0.0,0.0,0.0,...')])])
21:24:08,357 <kafka.protocol.parser>[DEBUG]: Received correlation id: 255
21:24:08,358 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:08,358 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 255 (2.9969215393066406 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=253, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:08,358 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=253, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:08,358 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 253 log start offset 0 and error None.
21:24:08,359 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:09,764 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:09,766 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:10,97 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:10,99 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DTI,2300.0,2000,0.0,0.0,0.0,0.0,False,0.0,14:49:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:10,99 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:10,99 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:10,99 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:10,99 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:10,100 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:10,100 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7\xd8g\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x93s\x00\x00\x01\x94\x12\xcd\x93s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTI,2300.0,2000,0.0,0.0,0.0,0.0,F...')])])}
21:24:10,100 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7\xd8g\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x93s\x00\x00\x01\x94\x12\xcd\x93s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTI,2300.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:24:10,100 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7\xd8g\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x93s\x00\x00\x01\x94\x12\xcd\x93s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTI,2300.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:24:10,100 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 256: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe7\xd8g\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x93s\x00\x00\x01\x94\x12\xcd\x93s\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTI,2300.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:24:10,102 <kafka.protocol.parser>[DEBUG]: Received correlation id: 256
21:24:10,103 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:10,103 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 256 (3.2682418823242188 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=254, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:10,103 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=254, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:10,103 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 254 log start offset 0 and error None.
21:24:10,104 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:10,515 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:10,518 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DTL,10050.0,100,0.0,0.0,0.0,0.0,False,0.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:10,519 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:10,519 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:10,519 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:10,519 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:10,520 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:10,520 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02eW\xe1\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x95\x17\x00\x00\x01\x94\x12\xcd\x95\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTL,10050.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:24:10,520 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02eW\xe1\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x95\x17\x00\x00\x01\x94\x12\xcd\x95\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTL,10050.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:10,520 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02eW\xe1\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x95\x17\x00\x00\x01\x94\x12\xcd\x95\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTL,10050.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:10,521 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 257: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02eW\xe1\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\x95\x17\x00\x00\x01\x94\x12\xcd\x95\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDTL,10050.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:10,524 <kafka.protocol.parser>[DEBUG]: Received correlation id: 257
21:24:10,524 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:10,525 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 257 (4.0073394775390625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=255, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:10,525 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=255, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:10,525 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 255 log start offset 0 and error None.
21:24:10,527 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:13,77 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:13,143 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:14,270 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:14,272 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DTT,19400.0,100,1250.0,0.1,0.0,0.0,False,0.0,13:25:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:14,272 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:14,272 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:14,272 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:14,273 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:14,273 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\nj\x87I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa3\xc0\x00\x00\x01\x94\x12\xcd\xa3\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTT,19400.0,100,1250.0,0.1,0.0,0....')])])}
21:24:14,273 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\nj\x87I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa3\xc0\x00\x00\x01\x94\x12\xcd\xa3\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTT,19400.0,100,1250.0,0.1,0.0,0....')])])
21:24:14,273 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\nj\x87I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa3\xc0\x00\x00\x01\x94\x12\xcd\xa3\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTT,19400.0,100,1250.0,0.1,0.0,0....')])])
21:24:14,273 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 258: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\nj\x87I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa3\xc0\x00\x00\x01\x94\x12\xcd\xa3\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDTT,19400.0,100,1250.0,0.1,0.0,0....')])])
21:24:14,273 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:14,276 <kafka.protocol.parser>[DEBUG]: Received correlation id: 258
21:24:14,276 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:14,276 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 258 (3.168821334838867 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=256, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:14,276 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=256, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:14,276 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 256 log start offset 0 and error None.
21:24:14,277 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:14,698 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DTV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:14,700 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:15,35 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MTV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:15,37 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:15,359 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MGG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:15,361 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MGG,26200.0,100,200.0,0.0,0.0,0.0,False,0.0,14:13:59' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:15,361 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:15,362 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:15,362 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:15,362 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:15,362 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02Y\x16ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa8\x02\x00\x00\x01\x94\x12\xcd\xa8\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMGG,26200.0,100,200.0,0.0,0.0,0.0...')])])}
21:24:15,362 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02Y\x16ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa8\x02\x00\x00\x01\x94\x12\xcd\xa8\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMGG,26200.0,100,200.0,0.0,0.0,0.0...')])])
21:24:15,362 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:15,362 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02Y\x16ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa8\x02\x00\x00\x01\x94\x12\xcd\xa8\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMGG,26200.0,100,200.0,0.0,0.0,0.0...')])])
21:24:15,363 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 259: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02Y\x16ev\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xa8\x02\x00\x00\x01\x94\x12\xcd\xa8\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMGG,26200.0,100,200.0,0.0,0.0,0.0...')])])
21:24:15,365 <kafka.protocol.parser>[DEBUG]: Received correlation id: 259
21:24:15,365 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:15,365 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 259 (2.0036697387695312 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=257, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:15,366 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=257, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:15,366 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 257 log start offset 0 and error None.
21:24:15,367 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:15,772 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DVC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:15,774 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:16,122 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DVG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:16,124 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DVG,1200.0,2300,0.0,0.0,0.0,0.0,False,0.0,14:47:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:16,124 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:16,124 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:16,124 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:16,124 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:16,125 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x06\x16\xb8o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xaa\xfc\x00\x00\x01\x94\x12\xcd\xaa\xfc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDVG,1200.0,2300,0.0,0.0,0.0,0.0,F...')])])}
21:24:16,125 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x06\x16\xb8o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xaa\xfc\x00\x00\x01\x94\x12\xcd\xaa\xfc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDVG,1200.0,2300,0.0,0.0,0.0,0.0,F...')])])
21:24:16,125 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:16,125 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x06\x16\xb8o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xaa\xfc\x00\x00\x01\x94\x12\xcd\xaa\xfc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDVG,1200.0,2300,0.0,0.0,0.0,0.0,F...')])])
21:24:16,125 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 260: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x06\x16\xb8o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xaa\xfc\x00\x00\x01\x94\x12\xcd\xaa\xfc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDVG,1200.0,2300,0.0,0.0,0.0,0.0,F...')])])
21:24:16,128 <kafka.protocol.parser>[DEBUG]: Received correlation id: 260
21:24:16,128 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:16,128 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 260 (2.9668807983398438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=258, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:16,128 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=258, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:16,128 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 258 log start offset 0 and error None.
21:24:16,129 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:16,662 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DVP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:18,0 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DVP,82800.0,1100,1500.0,0.0,0.0,0.0,False,200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:18,0 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:18,1 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:18,1 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:18,1 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:18,1 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02`\x96g\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb2Q\x00\x00\x01\x94\x12\xcd\xb2Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDVP,82800.0,1100,1500.0,0.0,0.0,0...')])])}
21:24:18,1 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:18,1 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02`\x96g\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb2Q\x00\x00\x01\x94\x12\xcd\xb2Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDVP,82800.0,1100,1500.0,0.0,0.0,0...')])])
21:24:18,2 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02`\x96g\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb2Q\x00\x00\x01\x94\x12\xcd\xb2Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDVP,82800.0,1100,1500.0,0.0,0.0,0...')])])
21:24:18,2 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 261: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02`\x96g\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb2Q\x00\x00\x01\x94\x12\xcd\xb2Q\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pDVP,82800.0,1100,1500.0,0.0,0.0,0...')])])
21:24:18,4 <kafka.protocol.parser>[DEBUG]: Received correlation id: 261
21:24:18,5 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:18,5 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 261 (2.9954910278320312 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=259, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:18,5 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=259, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:18,5 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 259 log start offset 0 and error None.
21:24:18,6 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:19,357 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DSG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:19,359 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DSG,5200.0,100,600.0,0.1,0.0,0.0,False,700.0,14:08:25' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:19,359 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:19,359 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:19,359 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:19,360 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:19,360 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02D\x85\x87`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb7\x9f\x00\x00\x01\x94\x12\xcd\xb7\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDSG,5200.0,100,600.0,0.1,0.0,0.0,...')])])}
21:24:19,360 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02D\x85\x87`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb7\x9f\x00\x00\x01\x94\x12\xcd\xb7\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDSG,5200.0,100,600.0,0.1,0.0,0.0,...')])])
21:24:19,360 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:19,360 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02D\x85\x87`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb7\x9f\x00\x00\x01\x94\x12\xcd\xb7\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDSG,5200.0,100,600.0,0.1,0.0,0.0,...')])])
21:24:19,361 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 262: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02D\x85\x87`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xb7\x9f\x00\x00\x01\x94\x12\xcd\xb7\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jDSG,5200.0,100,600.0,0.1,0.0,0.0,...')])])
21:24:19,363 <kafka.protocol.parser>[DEBUG]: Received correlation id: 262
21:24:19,363 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:19,364 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 262 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=260, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:19,364 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=260, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:19,364 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 260 log start offset 0 and error None.
21:24:19,365 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:19,689 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DVW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:19,691 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:23,283 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DXG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:23,287 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DXG,15700.0,1859600,-300.0,0.0,0.0,0.0,True,-150.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:23,288 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:23,288 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:23,289 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:23,289 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:23,290 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x025\x9e\xb2\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xc6\xf8\x00\x00\x01\x94\x12\xcd\xc6\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDXG,15700.0,1859600,-300.0,0.0,0...')])])}
21:24:23,290 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x025\x9e\xb2\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xc6\xf8\x00\x00\x01\x94\x12\xcd\xc6\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDXG,15700.0,1859600,-300.0,0.0,0...')])])
21:24:23,290 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x025\x9e\xb2\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xc6\xf8\x00\x00\x01\x94\x12\xcd\xc6\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDXG,15700.0,1859600,-300.0,0.0,0...')])])
21:24:23,291 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 263: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x025\x9e\xb2\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xc6\xf8\x00\x00\x01\x94\x12\xcd\xc6\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vDXG,15700.0,1859600,-300.0,0.0,0...')])])
21:24:23,291 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:23,296 <kafka.protocol.parser>[DEBUG]: Received correlation id: 263
21:24:23,296 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:23,296 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 263 (5.305767059326172 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=261, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:23,297 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=261, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:23,297 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 261 log start offset 0 and error None.
21:24:23,300 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:24,758 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DXL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:24,760 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:25,94 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DXP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:25,96 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DXP,11600.0,25400,0.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:25,96 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:25,96 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:25,96 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:25,96 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:25,97 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\t\xf1\xe47\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xce\x08\x00\x00\x01\x94\x12\xcd\xce\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDXP,11600.0,25400,0.0,0.0,0.0,0.0...')])])}
21:24:25,97 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\t\xf1\xe47\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xce\x08\x00\x00\x01\x94\x12\xcd\xce\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDXP,11600.0,25400,0.0,0.0,0.0,0.0...')])])
21:24:25,97 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\t\xf1\xe47\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xce\x08\x00\x00\x01\x94\x12\xcd\xce\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDXP,11600.0,25400,0.0,0.0,0.0,0.0...')])])
21:24:25,97 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:25,97 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 264: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\t\xf1\xe47\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xce\x08\x00\x00\x01\x94\x12\xcd\xce\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fDXP,11600.0,25400,0.0,0.0,0.0,0.0...')])])
21:24:25,100 <kafka.protocol.parser>[DEBUG]: Received correlation id: 264
21:24:25,100 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:25,100 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 264 (3.030061721801758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=262, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:25,100 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=262, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:25,100 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 262 log start offset 0 and error None.
21:24:25,101 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:25,454 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DXS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:26,194 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DXS,7160.0,264100,-130.0,0.0,0.0,0.0,True,50.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:26,194 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:26,194 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:26,194 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:26,195 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:26,195 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc9\x1aSx\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd2R\x00\x00\x01\x94\x12\xcd\xd2R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDXS,7160.0,264100,-130.0,0.0,0.0,...')])])}
21:24:26,195 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc9\x1aSx\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd2R\x00\x00\x01\x94\x12\xcd\xd2R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDXS,7160.0,264100,-130.0,0.0,0.0,...')])])
21:24:26,195 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:26,195 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc9\x1aSx\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd2R\x00\x00\x01\x94\x12\xcd\xd2R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDXS,7160.0,264100,-130.0,0.0,0.0,...')])])
21:24:26,195 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 265: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc9\x1aSx\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd2R\x00\x00\x01\x94\x12\xcd\xd2R\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDXS,7160.0,264100,-130.0,0.0,0.0,...')])])
21:24:26,198 <kafka.protocol.parser>[DEBUG]: Received correlation id: 265
21:24:26,198 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:26,198 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 265 (3.0002593994140625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=263, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:26,198 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=263, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:26,198 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 263 log start offset 0 and error None.
21:24:26,199 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:27,688 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DXV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:27,690 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DXV,3740.0,200,10.0,0.0,0.0,0.0,False,0.0,14:21:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:27,690 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:27,690 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:27,690 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:27,690 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:27,691 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x0f\xad\xdc\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd8*\x00\x00\x01\x94\x12\xcd\xd8*\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDXV,3740.0,200,10.0,0.0,0.0,0.0,F...')])])}
21:24:27,691 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x0f\xad\xdc\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd8*\x00\x00\x01\x94\x12\xcd\xd8*\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDXV,3740.0,200,10.0,0.0,0.0,0.0,F...')])])
21:24:27,691 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:27,691 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x0f\xad\xdc\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd8*\x00\x00\x01\x94\x12\xcd\xd8*\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDXV,3740.0,200,10.0,0.0,0.0,0.0,F...')])])
21:24:27,691 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 266: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\x0f\xad\xdc\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xd8*\x00\x00\x01\x94\x12\xcd\xd8*\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dDXV,3740.0,200,10.0,0.0,0.0,0.0,F...')])])
21:24:27,694 <kafka.protocol.parser>[DEBUG]: Received correlation id: 266
21:24:27,694 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:27,694 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 266 (2.9938220977783203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=264, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:27,694 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=264, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:27,694 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 264 log start offset 0 and error None.
21:24:27,695 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:28,17 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DZM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:28,19 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:28,344 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUESSV50/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:28,346 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUESSV50,20130.0,100,90.0,0.0,0.0,0.0,False,10.0,14:13:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:28,346 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:28,346 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:28,346 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:28,346 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:28,347 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02+\xea\xf7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xda\xba\x00\x00\x01\x94\x12\xcd\xda\xba\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUESSV50,20130.0,100,90.0,0.0,0.0...')])])}
21:24:28,347 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02+\xea\xf7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xda\xba\x00\x00\x01\x94\x12\xcd\xda\xba\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUESSV50,20130.0,100,90.0,0.0,0.0...')])])
21:24:28,347 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02+\xea\xf7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xda\xba\x00\x00\x01\x94\x12\xcd\xda\xba\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUESSV50,20130.0,100,90.0,0.0,0.0...')])])
21:24:28,347 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:28,347 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 267: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02+\xea\xf7\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xda\xba\x00\x00\x01\x94\x12\xcd\xda\xba\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUESSV50,20130.0,100,90.0,0.0,0.0...')])])
21:24:28,350 <kafka.protocol.parser>[DEBUG]: Received correlation id: 267
21:24:28,350 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:28,350 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 267 (3.0035972595214844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=265, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:28,350 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=265, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:28,350 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 265 log start offset 0 and error None.
21:24:28,352 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:29,243 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/E1VFVN30/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:29,244 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'E1VFVN30,23560.0,14200,110.0,0.0,0.0,0.0,True,40.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:29,244 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:29,244 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:29,244 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:29,245 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:29,245 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x9d\x04\xe9\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xde<\x00\x00\x01\x94\x12\xcd\xde<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vE1VFVN30,23560.0,14200,110.0,0.0...')])])}
21:24:29,245 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x9d\x04\xe9\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xde<\x00\x00\x01\x94\x12\xcd\xde<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vE1VFVN30,23560.0,14200,110.0,0.0...')])])
21:24:29,245 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:29,245 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x9d\x04\xe9\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xde<\x00\x00\x01\x94\x12\xcd\xde<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vE1VFVN30,23560.0,14200,110.0,0.0...')])])
21:24:29,245 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 268: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x9d\x04\xe9\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xde<\x00\x00\x01\x94\x12\xcd\xde<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vE1VFVN30,23560.0,14200,110.0,0.0...')])])
21:24:29,248 <kafka.protocol.parser>[DEBUG]: Received correlation id: 268
21:24:29,248 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:29,248 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 268 (1.9931793212890625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=266, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:29,248 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=266, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:29,248 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 266 log start offset 0 and error None.
21:24:29,250 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:29,963 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EBS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:29,965 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EBS,11200.0,100,100.0,0.0,0.0,0.0,False,0.0,13:28:16' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:29,965 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:29,965 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:29,965 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:29,965 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:29,966 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:29,966 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf9\x81\x02\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe1\r\x00\x00\x01\x94\x12\xcd\xe1\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEBS,11200.0,100,100.0,0.0,0.0,0.0...')])])}
21:24:29,966 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf9\x81\x02\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe1\r\x00\x00\x01\x94\x12\xcd\xe1\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEBS,11200.0,100,100.0,0.0,0.0,0.0...')])])
21:24:29,966 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf9\x81\x02\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe1\r\x00\x00\x01\x94\x12\xcd\xe1\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEBS,11200.0,100,100.0,0.0,0.0,0.0...')])])
21:24:29,966 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 269: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xf9\x81\x02\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe1\r\x00\x00\x01\x94\x12\xcd\xe1\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEBS,11200.0,100,100.0,0.0,0.0,0.0...')])])
21:24:29,969 <kafka.protocol.parser>[DEBUG]: Received correlation id: 269
21:24:29,969 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:29,969 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 269 (2.991914749145508 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=267, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:29,969 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=267, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:29,969 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 267 log start offset 0 and error None.
21:24:29,971 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:30,268 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/E29/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:30,270 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'E29,6000.0,300,-300.0,0.0,0.0,0.0,False,0.0,13:31:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:30,270 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:30,270 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:30,270 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:30,270 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:30,271 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02a\xf40I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe2>\x00\x00\x01\x94\x12\xcd\xe2>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hE29,6000.0,300,-300.0,0.0,0.0,0.0...')])])}
21:24:30,271 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02a\xf40I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe2>\x00\x00\x01\x94\x12\xcd\xe2>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hE29,6000.0,300,-300.0,0.0,0.0,0.0...')])])
21:24:30,271 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02a\xf40I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe2>\x00\x00\x01\x94\x12\xcd\xe2>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hE29,6000.0,300,-300.0,0.0,0.0,0.0...')])])
21:24:30,271 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 270: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02a\xf40I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xe2>\x00\x00\x01\x94\x12\xcd\xe2>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hE29,6000.0,300,-300.0,0.0,0.0,0.0...')])])
21:24:30,271 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:30,274 <kafka.protocol.parser>[DEBUG]: Received correlation id: 270
21:24:30,274 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:30,274 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 270 (3.002166748046875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=268, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:30,274 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=268, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:30,274 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 268 log start offset 0 and error None.
21:24:30,275 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:31,863 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ECI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:31,962 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:33,36 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EFI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:33,135 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EFI,1500.0,200,-200.0,-0.1,0.0,0.0,False,-300.0,14:17:45' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:33,135 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:33,135 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:33,135 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:33,136 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:33,136 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\n\x00\xd0\xa4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xedo\x00\x00\x01\x94\x12\xcd\xedo\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEFI,1500.0,200,-200.0,-0.1,0.0,0....')])])}
21:24:33,136 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\n\x00\xd0\xa4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xedo\x00\x00\x01\x94\x12\xcd\xedo\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEFI,1500.0,200,-200.0,-0.1,0.0,0....')])])
21:24:33,136 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\n\x00\xd0\xa4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xedo\x00\x00\x01\x94\x12\xcd\xedo\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEFI,1500.0,200,-200.0,-0.1,0.0,0....')])])
21:24:33,136 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 271: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\n\x00\xd0\xa4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xedo\x00\x00\x01\x94\x12\xcd\xedo\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEFI,1500.0,200,-200.0,-0.1,0.0,0....')])])
21:24:33,137 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:33,140 <kafka.protocol.parser>[DEBUG]: Received correlation id: 271
21:24:33,140 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:33,140 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 271 (2.964019775390625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=269, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:33,141 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=269, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:33,141 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 269 log start offset 0 and error None.
21:24:33,143 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:34,214 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EIB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:34,294 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EIB,19450.0,326600,200.0,0.0,0.0,0.0,True,-100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:34,294 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:34,294 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:34,294 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:34,294 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:34,294 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02H"\x1e\x82\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf1\xf6\x00\x00\x01\x94\x12\xcd\xf1\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rEIB,19450.0,326600,200.0,0.0,0.0,...')])])}
21:24:34,295 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02H"\x1e\x82\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf1\xf6\x00\x00\x01\x94\x12\xcd\xf1\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rEIB,19450.0,326600,200.0,0.0,0.0,...')])])
21:24:34,295 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02H"\x1e\x82\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf1\xf6\x00\x00\x01\x94\x12\xcd\xf1\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rEIB,19450.0,326600,200.0,0.0,0.0,...')])])
21:24:34,295 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 272: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02H"\x1e\x82\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf1\xf6\x00\x00\x01\x94\x12\xcd\xf1\xf6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rEIB,19450.0,326600,200.0,0.0,0.0,...')])])
21:24:34,295 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:34,297 <kafka.protocol.parser>[DEBUG]: Received correlation id: 272
21:24:34,297 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:34,298 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 272 (1.9710063934326172 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=270, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:34,298 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=270, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:34,298 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 270 log start offset 0 and error None.
21:24:34,299 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:34,986 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EID/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:34,988 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EID,26300.0,100,0.0,0.0,0.0,0.0,False,100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:34,988 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:34,988 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:34,989 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:34,989 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:34,989 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:34,989 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1q$X\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf4\xac\x00\x00\x01\x94\x12\xcd\xf4\xac\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEID,26300.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:24:34,989 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1q$X\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf4\xac\x00\x00\x01\x94\x12\xcd\xf4\xac\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEID,26300.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:34,989 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1q$X\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf4\xac\x00\x00\x01\x94\x12\xcd\xf4\xac\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEID,26300.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:34,989 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 273: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa1q$X\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf4\xac\x00\x00\x01\x94\x12\xcd\xf4\xac\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEID,26300.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:34,992 <kafka.protocol.parser>[DEBUG]: Received correlation id: 273
21:24:34,992 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:34,992 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 273 (2.0029544830322266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=271, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:34,992 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=271, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:34,993 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 271 log start offset 0 and error None.
21:24:34,994 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:35,410 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ELC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:35,414 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ELC,26950.0,144900,-950.0,0.0,0.0,0.0,True,-550.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:35,414 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:35,414 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:35,414 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:35,415 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:35,416 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:35,416 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf0\x97\x9br\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf6V\x00\x00\x01\x94\x12\xcd\xf6V\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tELC,26950.0,144900,-950.0,0.0,0....')])])}
21:24:35,416 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf0\x97\x9br\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf6V\x00\x00\x01\x94\x12\xcd\xf6V\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tELC,26950.0,144900,-950.0,0.0,0....')])])
21:24:35,416 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf0\x97\x9br\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf6V\x00\x00\x01\x94\x12\xcd\xf6V\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tELC,26950.0,144900,-950.0,0.0,0....')])])
21:24:35,417 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 274: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf0\x97\x9br\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xf6V\x00\x00\x01\x94\x12\xcd\xf6V\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tELC,26950.0,144900,-950.0,0.0,0....')])])
21:24:35,420 <kafka.protocol.parser>[DEBUG]: Received correlation id: 274
21:24:35,420 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:35,421 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 274 (3.751039505004883 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=272, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:35,421 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=272, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:35,421 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 272 log start offset 0 and error None.
21:24:35,423 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:35,774 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:35,776 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:36,622 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EME/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:36,624 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EME,26500.0,100,-2900.0,-0.1,0.0,0.0,False,0.0,11:16:08' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:36,624 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:36,624 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:36,624 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:36,624 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:36,625 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02T\xf7\x8d\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xfb\x10\x00\x00\x01\x94\x12\xcd\xfb\x10\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nEME,26500.0,100,-2900.0,-0.1,0.0,...')])])}
21:24:36,625 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02T\xf7\x8d\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xfb\x10\x00\x00\x01\x94\x12\xcd\xfb\x10\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nEME,26500.0,100,-2900.0,-0.1,0.0,...')])])
21:24:36,625 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:36,625 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02T\xf7\x8d\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xfb\x10\x00\x00\x01\x94\x12\xcd\xfb\x10\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nEME,26500.0,100,-2900.0,-0.1,0.0,...')])])
21:24:36,625 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 275: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02T\xf7\x8d\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcd\xfb\x10\x00\x00\x01\x94\x12\xcd\xfb\x10\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nEME,26500.0,100,-2900.0,-0.1,0.0,...')])])
21:24:36,628 <kafka.protocol.parser>[DEBUG]: Received correlation id: 275
21:24:36,628 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:36,628 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 275 (1.9922256469726562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=273, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:36,628 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=273, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:36,628 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 273 log start offset 0 and error None.
21:24:36,630 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:38,782 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EMG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:38,785 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:39,116 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EMS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:39,118 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EMS,27700.0,100,-900.0,0.0,0.0,0.0,False,0.0,14:24:40' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:39,118 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:39,118 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:39,119 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:39,119 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:39,119 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02x#\xc4\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x04\xce\x00\x00\x01\x94\x12\xce\x04\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEMS,27700.0,100,-900.0,0.0,0.0,0....')])])}
21:24:39,119 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02x#\xc4\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x04\xce\x00\x00\x01\x94\x12\xce\x04\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEMS,27700.0,100,-900.0,0.0,0.0,0....')])])
21:24:39,119 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02x#\xc4\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x04\xce\x00\x00\x01\x94\x12\xce\x04\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEMS,27700.0,100,-900.0,0.0,0.0,0....')])])
21:24:39,120 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 276: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02x#\xc4\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x04\xce\x00\x00\x01\x94\x12\xce\x04\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEMS,27700.0,100,-900.0,0.0,0.0,0....')])])
21:24:39,120 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:39,122 <kafka.protocol.parser>[DEBUG]: Received correlation id: 276
21:24:39,122 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:39,122 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 276 (1.9991397857666016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=274, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:39,123 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=274, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:39,123 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 274 log start offset 0 and error None.
21:24:39,124 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:39,429 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EPC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:39,431 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:39,757 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUESSVFL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:39,759 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUESSVFL,21970.0,1300,220.0,0.0,0.0,0.0,False,20.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:39,759 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:39,759 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:39,759 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:39,759 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:39,760 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:39,760 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x95:L\x83\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x07O\x00\x00\x01\x94\x12\xce\x07O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFUESSVFL,21970.0,1300,220.0,0.0,...')])])}
21:24:39,760 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x95:L\x83\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x07O\x00\x00\x01\x94\x12\xce\x07O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFUESSVFL,21970.0,1300,220.0,0.0,...')])])
21:24:39,760 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x95:L\x83\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x07O\x00\x00\x01\x94\x12\xce\x07O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFUESSVFL,21970.0,1300,220.0,0.0,...')])])
21:24:39,760 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 277: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\x95:L\x83\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x07O\x00\x00\x01\x94\x12\xce\x07O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFUESSVFL,21970.0,1300,220.0,0.0,...')])])
21:24:39,763 <kafka.protocol.parser>[DEBUG]: Received correlation id: 277
21:24:39,763 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:39,763 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 277 (3.008127212524414 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=275, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:39,763 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=275, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:39,763 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 275 log start offset 0 and error None.
21:24:39,765 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:42,450 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EVE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:42,544 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EVE,10500.0,700,50.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:42,544 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:42,545 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:42,545 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:42,545 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:42,545 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02J\xcb7\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x121\x00\x00\x01\x94\x12\xce\x121\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEVE,10500.0,700,50.0,0.0,0.0,0.0,...')])])}
21:24:42,545 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02J\xcb7\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x121\x00\x00\x01\x94\x12\xce\x121\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEVE,10500.0,700,50.0,0.0,0.0,0.0,...')])])
21:24:42,545 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02J\xcb7\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x121\x00\x00\x01\x94\x12\xce\x121\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEVE,10500.0,700,50.0,0.0,0.0,0.0,...')])])
21:24:42,545 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:42,546 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 278: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02J\xcb7\x97\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x121\x00\x00\x01\x94\x12\xce\x121\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jEVE,10500.0,700,50.0,0.0,0.0,0.0,...')])])
21:24:42,548 <kafka.protocol.parser>[DEBUG]: Received correlation id: 278
21:24:42,548 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:42,548 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 278 (2.018451690673828 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=276, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:42,549 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=276, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:42,549 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 276 log start offset 0 and error None.
21:24:42,550 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:43,361 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EVG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:43,450 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EVG,6390.0,22400,-120.0,0.0,0.0,0.0,False,-20.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:43,451 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:43,451 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:43,451 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:43,452 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:43,452 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xc6J\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x15\xbb\x00\x00\x01\x94\x12\xce\x15\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVG,6390.0,22400,-120.0,0.0,0.0,0...')])])}
21:24:43,453 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xc6J\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x15\xbb\x00\x00\x01\x94\x12\xce\x15\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVG,6390.0,22400,-120.0,0.0,0.0,0...')])])
21:24:43,453 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xc6J\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x15\xbb\x00\x00\x01\x94\x12\xce\x15\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVG,6390.0,22400,-120.0,0.0,0.0,0...')])])
21:24:43,453 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 279: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b\xc6J\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x15\xbb\x00\x00\x01\x94\x12\xce\x15\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVG,6390.0,22400,-120.0,0.0,0.0,0...')])])
21:24:43,454 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:43,459 <kafka.protocol.parser>[DEBUG]: Received correlation id: 279
21:24:43,460 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:43,460 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 279 (6.010532379150391 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=277, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:43,461 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=277, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:43,461 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 277 log start offset 0 and error None.
21:24:43,463 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:43,824 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EVF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:43,826 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EVF,9550.0,866100,-200.0,0.0,0.0,0.0,True,-50.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:43,826 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:43,827 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:43,827 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:43,827 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:43,827 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x8e(\xfd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x172\x00\x00\x01\x94\x12\xce\x172\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVF,9550.0,866100,-200.0,0.0,0.0,...')])])}
21:24:43,827 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x8e(\xfd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x172\x00\x00\x01\x94\x12\xce\x172\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVF,9550.0,866100,-200.0,0.0,0.0,...')])])
21:24:43,827 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:43,827 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x8e(\xfd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x172\x00\x00\x01\x94\x12\xce\x172\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVF,9550.0,866100,-200.0,0.0,0.0,...')])])
21:24:43,828 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 280: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x8e(\xfd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x172\x00\x00\x01\x94\x12\xce\x172\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pEVF,9550.0,866100,-200.0,0.0,0.0,...')])])
21:24:43,830 <kafka.protocol.parser>[DEBUG]: Received correlation id: 280
21:24:43,830 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:43,830 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 280 (2.0041465759277344 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=278, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:43,830 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=278, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:43,830 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 278 log start offset 0 and error None.
21:24:43,832 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:44,553 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EIC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:44,556 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EIC,22000.0,400,0.0,0.0,0.0,0.0,False,500.0,13:25:24' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:44,557 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:44,557 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:44,557 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:44,557 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:44,557 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb2\xb4`2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x1a\r\x00\x00\x01\x94\x12\xce\x1a\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEIC,22000.0,400,0.0,0.0,0.0,0.0,F...')])])}
21:24:44,558 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb2\xb4`2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x1a\r\x00\x00\x01\x94\x12\xce\x1a\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEIC,22000.0,400,0.0,0.0,0.0,0.0,F...')])])
21:24:44,558 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb2\xb4`2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x1a\r\x00\x00\x01\x94\x12\xce\x1a\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEIC,22000.0,400,0.0,0.0,0.0,0.0,F...')])])
21:24:44,558 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 281: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb2\xb4`2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x1a\r\x00\x00\x01\x94\x12\xce\x1a\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hEIC,22000.0,400,0.0,0.0,0.0,0.0,F...')])])
21:24:44,558 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:44,560 <kafka.protocol.parser>[DEBUG]: Received correlation id: 281
21:24:44,561 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:44,561 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 281 (3.0007362365722656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=279, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:44,561 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=279, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:44,561 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 279 log start offset 0 and error None.
21:24:44,562 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:45,82 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LEC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:45,83 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:46,390 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FHS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:46,392 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:46,689 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ROS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:46,691 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:47,97 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FBA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:47,101 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:47,871 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:47,873 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FCM,3650.0,10600,170.0,0.0,0.0,0.0,False,90.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:47,873 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:47,873 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:47,873 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:47,873 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:47,873 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:47,874 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02W\t\xdb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce'\x01\x00\x00\x01\x94\x12\xce'\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCM,3650.0,10600,170.0,0.0,0.0,0....")])])}
21:24:47,874 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02W\t\xdb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce'\x01\x00\x00\x01\x94\x12\xce'\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCM,3650.0,10600,170.0,0.0,0.0,0....")])])
21:24:47,874 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02W\t\xdb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce'\x01\x00\x00\x01\x94\x12\xce'\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCM,3650.0,10600,170.0,0.0,0.0,0....")])])
21:24:47,874 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 282: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02W\t\xdb\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce'\x01\x00\x00\x01\x94\x12\xce'\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCM,3650.0,10600,170.0,0.0,0.0,0....")])])
21:24:47,876 <kafka.protocol.parser>[DEBUG]: Received correlation id: 282
21:24:47,876 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:47,876 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 282 (2.003192901611328 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=280, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:47,877 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=280, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:47,877 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 280 log start offset 0 and error None.
21:24:47,878 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:48,197 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FCN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:48,206 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FCN,14600.0,76900,100.0,0.0,0.0,0.0,True,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:48,206 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:48,207 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:48,207 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:48,208 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:48,208 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9b\x7f(n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce(O\x00\x00\x01\x94\x12\xce(O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCN,14600.0,76900,100.0,0.0,0.0,0...')])])}
21:24:48,209 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9b\x7f(n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce(O\x00\x00\x01\x94\x12\xce(O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCN,14600.0,76900,100.0,0.0,0.0,0...')])])
21:24:48,209 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9b\x7f(n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce(O\x00\x00\x01\x94\x12\xce(O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCN,14600.0,76900,100.0,0.0,0.0,0...')])])
21:24:48,210 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 283: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9b\x7f(n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce(O\x00\x00\x01\x94\x12\xce(O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lFCN,14600.0,76900,100.0,0.0,0.0,0...')])])
21:24:48,211 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:48,215 <kafka.protocol.parser>[DEBUG]: Received correlation id: 283
21:24:48,215 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:48,215 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 283 (4.970788955688477 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=281, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:48,216 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=281, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:48,216 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 281 log start offset 0 and error None.
21:24:48,218 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:48,608 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:48,610 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FDC,16800.0,100,0.0,0.0,0.0,0.0,False,1150.0,13:28:42' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:48,610 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:48,611 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:48,611 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:48,611 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:48,611 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03MRD\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce)\xe3\x00\x00\x01\x94\x12\xce)\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jFDC,16800.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:24:48,611 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03MRD\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce)\xe3\x00\x00\x01\x94\x12\xce)\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jFDC,16800.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:48,611 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03MRD\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce)\xe3\x00\x00\x01\x94\x12\xce)\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jFDC,16800.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:48,611 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 284: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03MRD\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce)\xe3\x00\x00\x01\x94\x12\xce)\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jFDC,16800.0,100,0.0,0.0,0.0,0.0,F...')])])
21:24:48,612 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:48,614 <kafka.protocol.parser>[DEBUG]: Received correlation id: 284
21:24:48,614 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:48,614 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 284 (1.9741058349609375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=282, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:48,614 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=282, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:48,615 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 282 log start offset 0 and error None.
21:24:48,616 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:49,957 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FIC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:49,959 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FIC,14200.0,600,-300.0,0.0,0.0,0.0,False,-100.0,14:48:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:49,959 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:49,959 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:49,960 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:49,960 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:49,960 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xe59\xcc\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce/'\x00\x00\x01\x94\x12\xce/'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFIC,14200.0,600,-300.0,0.0,0.0,0....")])])}
21:24:49,960 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:49,960 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xe59\xcc\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce/'\x00\x00\x01\x94\x12\xce/'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFIC,14200.0,600,-300.0,0.0,0.0,0....")])])
21:24:49,961 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xe59\xcc\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce/'\x00\x00\x01\x94\x12\xce/'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFIC,14200.0,600,-300.0,0.0,0.0,0....")])])
21:24:49,961 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 285: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xe59\xcc\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce/'\x00\x00\x01\x94\x12\xce/'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFIC,14200.0,600,-300.0,0.0,0.0,0....")])])
21:24:49,963 <kafka.protocol.parser>[DEBUG]: Received correlation id: 285
21:24:49,964 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:49,964 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 285 (2.9790401458740234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=283, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:49,964 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=283, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:49,964 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 283 log start offset 0 and error None.
21:24:49,965 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:50,491 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FID/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:50,493 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FID,1500.0,10100,100.0,0.1,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:50,493 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:50,493 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:50,493 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:50,493 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:50,494 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02a\xf14\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce1=\x00\x00\x01\x94\x12\xce1=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFID,1500.0,10100,100.0,0.1,0.0,0....')])])}
21:24:50,494 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02a\xf14\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce1=\x00\x00\x01\x94\x12\xce1=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFID,1500.0,10100,100.0,0.1,0.0,0....')])])
21:24:50,494 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02a\xf14\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce1=\x00\x00\x01\x94\x12\xce1=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFID,1500.0,10100,100.0,0.1,0.0,0....')])])
21:24:50,494 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:50,494 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 286: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02a\xf14\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce1=\x00\x00\x01\x94\x12\xce1=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFID,1500.0,10100,100.0,0.1,0.0,0....')])])
21:24:50,497 <kafka.protocol.parser>[DEBUG]: Received correlation id: 286
21:24:50,497 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:50,497 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 286 (2.0134449005126953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=284, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:50,497 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=284, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:50,497 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 284 log start offset 0 and error None.
21:24:50,498 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:56,192 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FIR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:56,194 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FIR,6100.0,88500,150.0,0.0,0.0,0.0,True,0.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:56,195 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:56,195 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:56,195 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:56,196 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:56,196 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:56,196 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcf\x84\xe4Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceG\x83\x00\x00\x01\x94\x12\xceG\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hFIR,6100.0,88500,150.0,0.0,0.0,0....')])])}
21:24:56,196 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcf\x84\xe4Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceG\x83\x00\x00\x01\x94\x12\xceG\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hFIR,6100.0,88500,150.0,0.0,0.0,0....')])])
21:24:56,196 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcf\x84\xe4Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceG\x83\x00\x00\x01\x94\x12\xceG\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hFIR,6100.0,88500,150.0,0.0,0.0,0....')])])
21:24:56,196 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 287: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcf\x84\xe4Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceG\x83\x00\x00\x01\x94\x12\xceG\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hFIR,6100.0,88500,150.0,0.0,0.0,0....')])])
21:24:56,198 <kafka.protocol.parser>[DEBUG]: Received correlation id: 287
21:24:56,199 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:56,199 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 287 (2.998828887939453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=285, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:56,199 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=285, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:56,199 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 285 log start offset 0 and error None.
21:24:56,201 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:56,523 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FSO/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:56,525 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:57,981 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FIT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:57,982 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FIT,4270.0,69300,0.0,0.0,0.0,0.0,True,40.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:24:57,982 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:24:57,982 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:24:57,983 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:24:57,983 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:24:57,983 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc5\xf2\xfc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceN~\x00\x00\x01\x94\x12\xceN~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fFIT,4270.0,69300,0.0,0.0,0.0,0.0,...')])])}
21:24:57,983 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc5\xf2\xfc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceN~\x00\x00\x01\x94\x12\xceN~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fFIT,4270.0,69300,0.0,0.0,0.0,0.0,...')])])
21:24:57,983 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc5\xf2\xfc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceN~\x00\x00\x01\x94\x12\xceN~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fFIT,4270.0,69300,0.0,0.0,0.0,0.0,...')])])
21:24:57,983 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:24:57,983 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 288: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc5\xf2\xfc\xaf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceN~\x00\x00\x01\x94\x12\xceN~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fFIT,4270.0,69300,0.0,0.0,0.0,0.0,...')])])
21:24:57,986 <kafka.protocol.parser>[DEBUG]: Received correlation id: 288
21:24:57,986 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:24:57,986 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 288 (1.992940902709961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=286, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:57,986 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=286, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:24:57,986 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 286 log start offset 0 and error None.
21:24:57,988 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:59,492 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FLC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:59,582 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:24:59,981 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ART/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:24:59,984 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:00,315 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:00,317 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FMC,46850.0,2100,-850.0,0.0,0.0,0.0,False,-200.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:00,317 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:00,317 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:00,318 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:00,318 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:00,318 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02]*\xe2\x08\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceW\x9d\x00\x00\x01\x94\x12\xceW\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFMC,46850.0,2100,-850.0,0.0,0.0,0...')])])}
21:25:00,318 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:00,318 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02]*\xe2\x08\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceW\x9d\x00\x00\x01\x94\x12\xceW\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFMC,46850.0,2100,-850.0,0.0,0.0,0...')])])
21:25:00,319 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02]*\xe2\x08\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceW\x9d\x00\x00\x01\x94\x12\xceW\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFMC,46850.0,2100,-850.0,0.0,0.0,0...')])])
21:25:00,319 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 289: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02]*\xe2\x08\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceW\x9d\x00\x00\x01\x94\x12\xceW\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFMC,46850.0,2100,-850.0,0.0,0.0,0...')])])
21:25:00,321 <kafka.protocol.parser>[DEBUG]: Received correlation id: 289
21:25:00,321 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:00,322 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 289 (3.008604049682617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=287, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:00,322 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=287, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:00,322 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 287 log start offset 0 and error None.
21:25:00,323 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:00,834 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FOC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:00,836 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FOC,82200.0,100,-400.0,0.0,0.0,0.0,False,200.0,14:52:38' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:00,836 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:00,837 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:00,837 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:00,838 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\h\xdf\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceY\xa4\x00\x00\x01\x94\x12\xceY\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFOC,82200.0,100,-400.0,0.0,0.0,0....')])])}
21:25:00,838 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:00,838 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\h\xdf\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceY\xa4\x00\x00\x01\x94\x12\xceY\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFOC,82200.0,100,-400.0,0.0,0.0,0....')])])
21:25:00,838 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:00,838 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\h\xdf\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceY\xa4\x00\x00\x01\x94\x12\xceY\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFOC,82200.0,100,-400.0,0.0,0.0,0....')])])
21:25:00,838 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 290: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\h\xdf\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceY\xa4\x00\x00\x01\x94\x12\xceY\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFOC,82200.0,100,-400.0,0.0,0.0,0....')])])
21:25:00,840 <kafka.protocol.parser>[DEBUG]: Received correlation id: 290
21:25:00,841 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:00,841 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 290 (2.5146007537841797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=288, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:00,841 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=288, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:00,841 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 288 log start offset 0 and error None.
21:25:00,843 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:01,281 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:01,283 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:02,173 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FCS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:02,268 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:03,737 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FRM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:03,830 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:04,127 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DP3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:04,129 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DP3,57800.0,700,-200.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,129 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,129 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:04,129 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:04,130 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:04,130 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,130 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\xc0\xf6<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcef\x81\x00\x00\x01\x94\x12\xcef\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDP3,57800.0,700,-200.0,0.0,0.0,0....')])])}
21:25:04,130 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\xc0\xf6<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcef\x81\x00\x00\x01\x94\x12\xcef\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDP3,57800.0,700,-200.0,0.0,0.0,0....')])])
21:25:04,130 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\xc0\xf6<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcef\x81\x00\x00\x01\x94\x12\xcef\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDP3,57800.0,700,-200.0,0.0,0.0,0....')])])
21:25:04,130 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 291: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\xc0\xf6<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcef\x81\x00\x00\x01\x94\x12\xcef\x81\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDP3,57800.0,700,-200.0,0.0,0.0,0....')])])
21:25:04,133 <kafka.protocol.parser>[DEBUG]: Received correlation id: 291
21:25:04,133 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:04,133 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 291 (3.0019283294677734 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=289, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:04,134 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=289, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:04,134 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 289 log start offset 0 and error None.
21:25:04,135 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:04,434 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FTM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:04,437 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FTM,800.0,100,100.0,0.1,0.0,0.0,False,0.0,14:43:41' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,437 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,437 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:04,438 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:04,438 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xc0\x84\x01\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceg\xb5\x00\x00\x01\x94\x12\xceg\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dFTM,800.0,100,100.0,0.1,0.0,0.0,F...')])])}
21:25:04,438 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:04,438 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xc0\x84\x01\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceg\xb5\x00\x00\x01\x94\x12\xceg\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dFTM,800.0,100,100.0,0.1,0.0,0.0,F...')])])
21:25:04,439 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xc0\x84\x01\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceg\xb5\x00\x00\x01\x94\x12\xceg\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dFTM,800.0,100,100.0,0.1,0.0,0.0,F...')])])
21:25:04,439 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,439 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 292: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xc0\x84\x01\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceg\xb5\x00\x00\x01\x94\x12\xceg\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dFTM,800.0,100,100.0,0.1,0.0,0.0,F...')])])
21:25:04,442 <kafka.protocol.parser>[DEBUG]: Received correlation id: 292
21:25:04,442 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:04,442 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 292 (3.002643585205078 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=290, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:04,442 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=290, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:04,443 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 290 log start offset 0 and error None.
21:25:04,444 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:04,900 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FPT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:04,902 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FPT,149600.0,332000,-200.0,0.0,0.0,0.0,True,-200.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,902 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,902 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:04,903 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:04,903 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:04,903 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:04,903 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02h\xc8wK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcei\x86\x00\x00\x01\x94\x12\xcei\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFPT,149600.0,332000,-200.0,0.0,0...')])])}
21:25:04,904 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02h\xc8wK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcei\x86\x00\x00\x01\x94\x12\xcei\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFPT,149600.0,332000,-200.0,0.0,0...')])])
21:25:04,904 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02h\xc8wK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcei\x86\x00\x00\x01\x94\x12\xcei\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFPT,149600.0,332000,-200.0,0.0,0...')])])
21:25:04,904 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 293: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02h\xc8wK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcei\x86\x00\x00\x01\x94\x12\xcei\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vFPT,149600.0,332000,-200.0,0.0,0...')])])
21:25:04,906 <kafka.protocol.parser>[DEBUG]: Received correlation id: 293
21:25:04,907 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:04,907 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 293 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=291, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:04,907 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=291, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:04,907 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 291 log start offset 0 and error None.
21:25:04,909 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:05,616 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FRT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:05,617 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FRT,183800.0,169000,0.0,0.0,0.0,0.0,True,300.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:05,618 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:05,618 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:05,618 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:05,618 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:05,618 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:05,618 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x9dKR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcelR\x00\x00\x01\x94\x12\xcelR\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFRT,183800.0,169000,0.0,0.0,0.0,0...')])])}
21:25:05,619 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x9dKR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcelR\x00\x00\x01\x94\x12\xcelR\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFRT,183800.0,169000,0.0,0.0,0.0,0...')])])
21:25:05,619 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x9dKR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcelR\x00\x00\x01\x94\x12\xcelR\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFRT,183800.0,169000,0.0,0.0,0.0,0...')])])
21:25:05,619 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 294: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02%\x9dKR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcelR\x00\x00\x01\x94\x12\xcelR\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFRT,183800.0,169000,0.0,0.0,0.0,0...')])])
21:25:05,622 <kafka.protocol.parser>[DEBUG]: Received correlation id: 294
21:25:05,622 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:05,622 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 294 (3.0057430267333984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=292, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:05,623 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=292, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:05,623 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 292 log start offset 0 and error None.
21:25:05,625 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:05,947 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FTS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:05,949 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FTS,42800.0,85400,50.0,0.0,0.0,0.0,True,-150.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:05,949 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:05,949 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:05,949 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:05,949 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:05,949 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~;\xc78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcem\x9d\x00\x00\x01\x94\x12\xcem\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFTS,42800.0,85400,50.0,0.0,0.0,0....')])])}
21:25:05,950 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~;\xc78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcem\x9d\x00\x00\x01\x94\x12\xcem\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFTS,42800.0,85400,50.0,0.0,0.0,0....')])])
21:25:05,950 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:05,950 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~;\xc78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcem\x9d\x00\x00\x01\x94\x12\xcem\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFTS,42800.0,85400,50.0,0.0,0.0,0....')])])
21:25:05,950 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 295: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~;\xc78\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcem\x9d\x00\x00\x01\x94\x12\xcem\x9d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nFTS,42800.0,85400,50.0,0.0,0.0,0....')])])
21:25:05,953 <kafka.protocol.parser>[DEBUG]: Received correlation id: 295
21:25:05,953 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:05,953 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 295 (3.126859664916992 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=293, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:05,954 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=293, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:05,954 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 293 log start offset 0 and error None.
21:25:05,956 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:06,246 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FRC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:06,248 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:06,551 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FT1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:06,553 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:06,817 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FOX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:06,819 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FOX,95500.0,400,-1600.0,0.0,0.0,0.0,False,-100.0,14:59:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:06,819 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:06,819 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:06,820 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:06,820 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:06,822 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:06,822 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdd<\xc7\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceq\x03\x00\x00\x01\x94\x12\xceq\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFOX,95500.0,400,-1600.0,0.0,0.0,0...')])])}
21:25:06,822 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdd<\xc7\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceq\x03\x00\x00\x01\x94\x12\xceq\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFOX,95500.0,400,-1600.0,0.0,0.0,0...')])])
21:25:06,822 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdd<\xc7\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceq\x03\x00\x00\x01\x94\x12\xceq\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFOX,95500.0,400,-1600.0,0.0,0.0,0...')])])
21:25:06,823 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 296: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdd<\xc7\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xceq\x03\x00\x00\x01\x94\x12\xceq\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFOX,95500.0,400,-1600.0,0.0,0.0,0...')])])
21:25:06,829 <kafka.protocol.parser>[DEBUG]: Received correlation id: 296
21:25:06,829 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:06,830 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 296 (5.996227264404297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=294, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:06,830 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=294, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:06,830 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 294 log start offset 0 and error None.
21:25:06,832 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:08,225 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FTI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:08,612 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:09,132 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUEMAV30/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:09,134 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUEMAV30,16270.0,400,70.0,0.0,0.0,0.0,False,70.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,134 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,134 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:09,134 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:09,135 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,135 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:09,135 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\x99A\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcez\x0e\x00\x00\x01\x94\x12\xcez\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEMAV30,16270.0,400,70.0,0.0,0.0...')])])}
21:25:09,135 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\x99A\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcez\x0e\x00\x00\x01\x94\x12\xcez\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEMAV30,16270.0,400,70.0,0.0,0.0...')])])
21:25:09,135 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\x99A\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcez\x0e\x00\x00\x01\x94\x12\xcez\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEMAV30,16270.0,400,70.0,0.0,0.0...')])])
21:25:09,135 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 297: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\x99A\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcez\x0e\x00\x00\x01\x94\x12\xcez\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rFUEMAV30,16270.0,400,70.0,0.0,0.0...')])])
21:25:09,138 <kafka.protocol.parser>[DEBUG]: Received correlation id: 297
21:25:09,138 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:09,138 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 297 (3.006458282470703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=295, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:09,138 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=295, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:09,139 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 295 log start offset 0 and error None.
21:25:09,140 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:09,452 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUESSV30/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:09,453 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUESSV30,16740.0,200,80.0,0.0,0.0,0.0,False,0.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,453 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,454 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:09,454 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:09,454 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc6\x8a\xee\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce{N\x00\x00\x01\x94\x12\xce{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUESSV30,16740.0,200,80.0,0.0,0.0...')])])}
21:25:09,454 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc6\x8a\xee\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce{N\x00\x00\x01\x94\x12\xce{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUESSV30,16740.0,200,80.0,0.0,0.0...')])])
21:25:09,454 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc6\x8a\xee\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce{N\x00\x00\x01\x94\x12\xce{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUESSV30,16740.0,200,80.0,0.0,0.0...')])])
21:25:09,454 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 298: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc6\x8a\xee\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce{N\x00\x00\x01\x94\x12\xce{N\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pFUESSV30,16740.0,200,80.0,0.0,0.0...')])])
21:25:09,455 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:09,455 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,457 <kafka.protocol.parser>[DEBUG]: Received correlation id: 298
21:25:09,457 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:09,457 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 298 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=296, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:09,457 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=296, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:09,457 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 296 log start offset 0 and error None.
21:25:09,459 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:09,762 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUEVFVND/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:09,764 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUEVFVND,33560.0,6700,150.0,0.0,0.0,0.0,True,30.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,764 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,764 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:09,765 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:09,765 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:09,765 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xee\x9a\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce|\x84\x00\x00\x01\x94\x12\xce|\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVFVND,33560.0,6700,150.0,0.0,...')])])}
21:25:09,765 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xee\x9a\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce|\x84\x00\x00\x01\x94\x12\xce|\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVFVND,33560.0,6700,150.0,0.0,...')])])
21:25:09,765 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xee\x9a\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce|\x84\x00\x00\x01\x94\x12\xce|\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVFVND,33560.0,6700,150.0,0.0,...')])])
21:25:09,765 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 299: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xee\x9a\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce|\x84\x00\x00\x01\x94\x12\xce|\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVFVND,33560.0,6700,150.0,0.0,...')])])
21:25:09,766 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:09,768 <kafka.protocol.parser>[DEBUG]: Received correlation id: 299
21:25:09,768 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:09,768 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 299 (1.9991397857666016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=297, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:09,768 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=297, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:09,769 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 297 log start offset 0 and error None.
21:25:09,770 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:10,80 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FUEVN100/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:10,82 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'FUEVN100,17980.0,2100,80.0,0.0,0.0,0.0,False,10.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:10,82 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:10,82 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:10,82 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:10,82 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:10,83 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xe1\x16$\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce}\xc2\x00\x00\x01\x94\x12\xce}\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVN100,17980.0,2100,80.0,0.0,0...')])])}
21:25:10,83 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xe1\x16$\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce}\xc2\x00\x00\x01\x94\x12\xce}\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVN100,17980.0,2100,80.0,0.0,0...')])])
21:25:10,83 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xe1\x16$\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce}\xc2\x00\x00\x01\x94\x12\xce}\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVN100,17980.0,2100,80.0,0.0,0...')])])
21:25:10,83 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:10,83 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 300: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xe1\x16$\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce}\xc2\x00\x00\x01\x94\x12\xce}\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tFUEVN100,17980.0,2100,80.0,0.0,0...')])])
21:25:10,86 <kafka.protocol.parser>[DEBUG]: Received correlation id: 300
21:25:10,86 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:10,86 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 300 (2.996683120727539 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=298, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:10,86 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=298, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:10,86 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 298 log start offset 0 and error None.
21:25:10,88 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:10,405 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/G20/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:10,407 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'G20,600.0,2500,100.0,0.2,0.0,0.0,False,0.0,13:00:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:10,407 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:10,407 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:10,407 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:10,408 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:10,408 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02>\xb36'\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x7f\x07\x00\x00\x01\x94\x12\xce\x7f\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fG20,600.0,2500,100.0,0.2,0.0,0.0,...")])])}
21:25:10,408 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02>\xb36'\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x7f\x07\x00\x00\x01\x94\x12\xce\x7f\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fG20,600.0,2500,100.0,0.2,0.0,0.0,...")])])
21:25:10,408 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02>\xb36'\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x7f\x07\x00\x00\x01\x94\x12\xce\x7f\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fG20,600.0,2500,100.0,0.2,0.0,0.0,...")])])
21:25:10,408 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:10,408 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 301: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02>\xb36'\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x7f\x07\x00\x00\x01\x94\x12\xce\x7f\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fG20,600.0,2500,100.0,0.2,0.0,0.0,...")])])
21:25:10,411 <kafka.protocol.parser>[DEBUG]: Received correlation id: 301
21:25:10,411 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:10,411 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 301 (1.9917488098144531 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=299, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:10,411 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=299, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:10,411 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 299 log start offset 0 and error None.
21:25:10,413 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:11,137 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GAB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:11,138 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:12,307 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/M10/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:12,308 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'M10,27100.0,500,900.0,0.0,0.0,0.0,False,-300.0,14:58:08' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:12,309 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:12,309 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:12,309 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:12,309 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:12,309 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02.r\xa1\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x86u\x00\x00\x01\x94\x12\xce\x86u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nM10,27100.0,500,900.0,0.0,0.0,0.0...')])])}
21:25:12,309 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02.r\xa1\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x86u\x00\x00\x01\x94\x12\xce\x86u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nM10,27100.0,500,900.0,0.0,0.0,0.0...')])])
21:25:12,309 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02.r\xa1\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x86u\x00\x00\x01\x94\x12\xce\x86u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nM10,27100.0,500,900.0,0.0,0.0,0.0...')])])
21:25:12,310 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 302: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02.r\xa1\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x86u\x00\x00\x01\x94\x12\xce\x86u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nM10,27100.0,500,900.0,0.0,0.0,0.0...')])])
21:25:12,310 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:12,312 <kafka.protocol.parser>[DEBUG]: Received correlation id: 302
21:25:12,312 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:12,312 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 302 (1.9984245300292969 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=300, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:12,312 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=300, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:12,313 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 300 log start offset 0 and error None.
21:25:12,314 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:13,648 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:13,649 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GAS,68500.0,263800,0.0,0.0,0.0,0.0,True,-300.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:13,649 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:13,650 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:13,650 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:13,650 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:13,650 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02Bg_R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8b\xb2\x00\x00\x01\x94\x12\xce\x8b\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGAS,68500.0,263800,0.0,0.0,0.0,0....')])])}
21:25:13,650 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02Bg_R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8b\xb2\x00\x00\x01\x94\x12\xce\x8b\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGAS,68500.0,263800,0.0,0.0,0.0,0....')])])
21:25:13,651 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02Bg_R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8b\xb2\x00\x00\x01\x94\x12\xce\x8b\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGAS,68500.0,263800,0.0,0.0,0.0,0....')])])
21:25:13,650 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:13,651 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 303: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02Bg_R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8b\xb2\x00\x00\x01\x94\x12\xce\x8b\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGAS,68500.0,263800,0.0,0.0,0.0,0....')])])
21:25:13,654 <kafka.protocol.parser>[DEBUG]: Received correlation id: 303
21:25:13,654 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:13,654 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 303 (2.0093917846679688 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=301, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:13,655 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=301, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:13,655 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 301 log start offset 0 and error None.
21:25:13,656 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:13,979 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BVB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:14,706 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BVB,11600.0,5000,-200.0,0.0,0.0,0.0,False,0.0,14:59:35' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:14,706 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:14,706 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:14,707 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:14,707 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:14,707 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:14,707 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02H}Oi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8f\xd2\x00\x00\x01\x94\x12\xce\x8f\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVB,11600.0,5000,-200.0,0.0,0.0,0...')])])}
21:25:14,707 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02H}Oi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8f\xd2\x00\x00\x01\x94\x12\xce\x8f\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVB,11600.0,5000,-200.0,0.0,0.0,0...')])])
21:25:14,707 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02H}Oi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8f\xd2\x00\x00\x01\x94\x12\xce\x8f\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVB,11600.0,5000,-200.0,0.0,0.0,0...')])])
21:25:14,708 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 304: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02H}Oi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x8f\xd2\x00\x00\x01\x94\x12\xce\x8f\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lBVB,11600.0,5000,-200.0,0.0,0.0,0...')])])
21:25:14,710 <kafka.protocol.parser>[DEBUG]: Received correlation id: 304
21:25:14,710 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:14,711 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 304 (2.9973983764648438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=302, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:14,711 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=302, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:14,711 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 302 log start offset 0 and error None.
21:25:14,712 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:14,990 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GDT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:14,994 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GDT,27000.0,15200,0.0,0.0,0.0,0.0,True,-50.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:14,995 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:14,995 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:14,996 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:14,996 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:14,997 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\x125\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x90\xf3\x00\x00\x01\x94\x12\xce\x90\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGDT,27000.0,15200,0.0,0.0,0.0,0.0...')])])}
21:25:14,997 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\x125\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x90\xf3\x00\x00\x01\x94\x12\xce\x90\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGDT,27000.0,15200,0.0,0.0,0.0,0.0...')])])
21:25:14,997 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\x125\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x90\xf3\x00\x00\x01\x94\x12\xce\x90\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGDT,27000.0,15200,0.0,0.0,0.0,0.0...')])])
21:25:14,998 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 305: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x95\x125\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x90\xf3\x00\x00\x01\x94\x12\xce\x90\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGDT,27000.0,15200,0.0,0.0,0.0,0.0...')])])
21:25:14,998 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:15,3 <kafka.protocol.parser>[DEBUG]: Received correlation id: 305
21:25:15,3 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:15,4 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 305 (4.951238632202148 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=303, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:15,4 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=303, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:15,4 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 303 log start offset 0 and error None.
21:25:15,7 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:15,723 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GDW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:15,725 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:16,48 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GEX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:16,50 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GEX,19350.0,369000,0.0,0.0,0.0,0.0,True,0.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,50 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,50 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:16,50 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:16,50 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:16,50 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x14Gm\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x95\x12\x00\x00\x01\x94\x12\xce\x95\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGEX,19350.0,369000,0.0,0.0,0.0,0....')])])}
21:25:16,51 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x14Gm\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x95\x12\x00\x00\x01\x94\x12\xce\x95\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGEX,19350.0,369000,0.0,0.0,0.0,0....')])])
21:25:16,51 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x14Gm\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x95\x12\x00\x00\x01\x94\x12\xce\x95\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGEX,19350.0,369000,0.0,0.0,0.0,0....')])])
21:25:16,51 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,51 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 306: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x14Gm\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x95\x12\x00\x00\x01\x94\x12\xce\x95\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hGEX,19350.0,369000,0.0,0.0,0.0,0....')])])
21:25:16,53 <kafka.protocol.parser>[DEBUG]: Received correlation id: 306
21:25:16,54 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:16,54 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 306 (2.9680728912353516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=304, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:16,54 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=304, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:16,54 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 304 log start offset 0 and error None.
21:25:16,55 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:16,386 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GEE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:16,393 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GEE,33550.0,4300,-100.0,0.0,0.0,0.0,False,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,393 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,393 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:16,393 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:16,394 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:16,395 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02G+\xef\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x96i\x00\x00\x01\x94\x12\xce\x96i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGEE,33550.0,4300,-100.0,0.0,0.0,0...')])])}
21:25:16,395 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02G+\xef\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x96i\x00\x00\x01\x94\x12\xce\x96i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGEE,33550.0,4300,-100.0,0.0,0.0,0...')])])
21:25:16,396 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,396 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02G+\xef\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x96i\x00\x00\x01\x94\x12\xce\x96i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGEE,33550.0,4300,-100.0,0.0,0.0,0...')])])
21:25:16,398 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 307: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02G+\xef\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x96i\x00\x00\x01\x94\x12\xce\x96i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGEE,33550.0,4300,-100.0,0.0,0.0,0...')])])
21:25:16,403 <kafka.protocol.parser>[DEBUG]: Received correlation id: 307
21:25:16,403 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:16,405 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 307 (7.006645202636719 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=305, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:16,405 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=305, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:16,405 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 305 log start offset 0 and error None.
21:25:16,409 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:16,694 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PGV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:16,697 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PGV,20900.0,3500,250.0,0.0,0.0,0.0,False,-200.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,697 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,697 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:16,697 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:16,699 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:16,699 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:16,699 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x024\xab\x08\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x97\x99\x00\x00\x01\x94\x12\xce\x97\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPGV,20900.0,3500,250.0,0.0,0.0,0....')])])}
21:25:16,699 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x024\xab\x08\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x97\x99\x00\x00\x01\x94\x12\xce\x97\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPGV,20900.0,3500,250.0,0.0,0.0,0....')])])
21:25:16,699 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x024\xab\x08\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x97\x99\x00\x00\x01\x94\x12\xce\x97\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPGV,20900.0,3500,250.0,0.0,0.0,0....')])])
21:25:16,699 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 308: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x024\xab\x08\x03\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\x97\x99\x00\x00\x01\x94\x12\xce\x97\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPGV,20900.0,3500,250.0,0.0,0.0,0....')])])
21:25:16,703 <kafka.protocol.parser>[DEBUG]: Received correlation id: 308
21:25:16,703 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:16,704 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 308 (4.592180252075195 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=306, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:16,704 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=306, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:16,704 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 306 log start offset 0 and error None.
21:25:16,706 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:19,568 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GER/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:19,661 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:19,963 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GGG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:19,971 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GGG,2000.0,800,100.0,0.1,0.0,0.0,False,0.0,14:31:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:19,971 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:19,972 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:19,973 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:19,974 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:19,974 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02d\xcb`\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa4d\x00\x00\x01\x94\x12\xce\xa4d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGGG,2000.0,800,100.0,0.1,0.0,0.0,...')])])}
21:25:19,975 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02d\xcb`\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa4d\x00\x00\x01\x94\x12\xce\xa4d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGGG,2000.0,800,100.0,0.1,0.0,0.0,...')])])
21:25:19,975 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02d\xcb`\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa4d\x00\x00\x01\x94\x12\xce\xa4d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGGG,2000.0,800,100.0,0.1,0.0,0.0,...')])])
21:25:19,976 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 309: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02d\xcb`\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa4d\x00\x00\x01\x94\x12\xce\xa4d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGGG,2000.0,800,100.0,0.1,0.0,0.0,...')])])
21:25:19,977 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:19,981 <kafka.protocol.parser>[DEBUG]: Received correlation id: 309
21:25:19,981 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:19,982 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 309 (5.939006805419922 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=307, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:19,982 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=307, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:19,982 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 307 log start offset 0 and error None.
21:25:19,985 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:20,545 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:20,547 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GHC,28400.0,300,100.0,0.0,0.0,0.0,False,200.0,14:57:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:20,547 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:20,547 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:20,547 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:20,548 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:20,548 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:20,548 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02 >\xd1Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa6\xa3\x00\x00\x01\x94\x12\xce\xa6\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lGHC,28400.0,300,100.0,0.0,0.0,0.0...')])])}
21:25:20,548 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02 >\xd1Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa6\xa3\x00\x00\x01\x94\x12\xce\xa6\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lGHC,28400.0,300,100.0,0.0,0.0,0.0...')])])
21:25:20,548 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02 >\xd1Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa6\xa3\x00\x00\x01\x94\x12\xce\xa6\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lGHC,28400.0,300,100.0,0.0,0.0,0.0...')])])
21:25:20,548 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 310: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02 >\xd1Z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xa6\xa3\x00\x00\x01\x94\x12\xce\xa6\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lGHC,28400.0,300,100.0,0.0,0.0,0.0...')])])
21:25:20,550 <kafka.protocol.parser>[DEBUG]: Received correlation id: 310
21:25:20,551 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:20,551 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 310 (2.9931068420410156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=308, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:20,551 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=308, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:20,551 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 308 log start offset 0 and error None.
21:25:20,552 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:20,868 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FGL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:20,871 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:21,187 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GLW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:21,189 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:21,602 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GIL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:21,604 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GIL,21350.0,29300,-100.0,0.0,0.0,0.0,True,-50.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:21,605 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:21,605 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:21,605 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:21,605 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:21,605 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xed\xc6\xe1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xaa\xc5\x00\x00\x01\x94\x12\xce\xaa\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGIL,21350.0,29300,-100.0,0.0,0.0,...')])])}
21:25:21,605 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xed\xc6\xe1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xaa\xc5\x00\x00\x01\x94\x12\xce\xaa\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGIL,21350.0,29300,-100.0,0.0,0.0,...')])])
21:25:21,606 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:21,606 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xed\xc6\xe1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xaa\xc5\x00\x00\x01\x94\x12\xce\xaa\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGIL,21350.0,29300,-100.0,0.0,0.0,...')])])
21:25:21,606 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 311: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87\xed\xc6\xe1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xaa\xc5\x00\x00\x01\x94\x12\xce\xaa\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGIL,21350.0,29300,-100.0,0.0,0.0,...')])])
21:25:21,608 <kafka.protocol.parser>[DEBUG]: Received correlation id: 311
21:25:21,608 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:21,609 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 311 (2.0020008087158203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=309, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:21,609 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=309, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:21,609 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 309 log start offset 0 and error None.
21:25:21,611 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:22,313 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GLC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:22,315 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:22,628 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GEG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:22,630 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GEG,11750.0,312600,-50.0,0.0,0.0,0.0,True,150.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:22,630 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:22,631 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:22,631 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:22,631 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:22,631 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x91\xe0\x86\x8f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xae\xc6\x00\x00\x01\x94\x12\xce\xae\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGEG,11750.0,312600,-50.0,0.0,0.0,...')])])}
21:25:22,631 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:22,631 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x91\xe0\x86\x8f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xae\xc6\x00\x00\x01\x94\x12\xce\xae\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGEG,11750.0,312600,-50.0,0.0,0.0,...')])])
21:25:22,632 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x91\xe0\x86\x8f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xae\xc6\x00\x00\x01\x94\x12\xce\xae\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGEG,11750.0,312600,-50.0,0.0,0.0,...')])])
21:25:22,632 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 312: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x91\xe0\x86\x8f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xae\xc6\x00\x00\x01\x94\x12\xce\xae\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pGEG,11750.0,312600,-50.0,0.0,0.0,...')])])
21:25:22,634 <kafka.protocol.parser>[DEBUG]: Received correlation id: 312
21:25:22,634 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:22,635 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 312 (1.997232437133789 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=310, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:22,635 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=310, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:22,635 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 310 log start offset 0 and error None.
21:25:22,636 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:23,463 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GLT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:23,854 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:24,138 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GMA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:24,139 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:24,469 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:24,880 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GMC,7400.0,100,0.0,0.0,0.0,0.0,False,0.0,11:10:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:24,880 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:24,880 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:24,881 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:24,881 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:24,881 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xe8\xe4\x9cr\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb7\x90\x00\x00\x01\x94\x12\xce\xb7\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bGMC,7400.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:25:24,881 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xe8\xe4\x9cr\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb7\x90\x00\x00\x01\x94\x12\xce\xb7\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bGMC,7400.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:25:24,881 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xe8\xe4\x9cr\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb7\x90\x00\x00\x01\x94\x12\xce\xb7\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bGMC,7400.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:25:24,881 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:24,881 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 313: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xe8\xe4\x9cr\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb7\x90\x00\x00\x01\x94\x12\xce\xb7\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bGMC,7400.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:25:24,884 <kafka.protocol.parser>[DEBUG]: Received correlation id: 313
21:25:24,884 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:24,885 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 313 (2.5854110717773438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=311, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:24,885 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=311, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:24,885 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 311 log start offset 0 and error None.
21:25:24,886 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:25,172 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GMD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:25,173 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GMD,66500.0,155700,-300.0,0.0,0.0,0.0,True,200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:25,173 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:25,173 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:25,173 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:25,175 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:25,175 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\x96\xe2\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb8\xb5\x00\x00\x01\x94\x12\xce\xb8\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGMD,66500.0,155700,-300.0,0.0,0.0...')])])}
21:25:25,175 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\x96\xe2\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb8\xb5\x00\x00\x01\x94\x12\xce\xb8\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGMD,66500.0,155700,-300.0,0.0,0.0...')])])
21:25:25,175 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\x96\xe2\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb8\xb5\x00\x00\x01\x94\x12\xce\xb8\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGMD,66500.0,155700,-300.0,0.0,0.0...')])])
21:25:25,175 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 314: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xf0\x96\xe2\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xb8\xb5\x00\x00\x01\x94\x12\xce\xb8\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGMD,66500.0,155700,-300.0,0.0,0.0...')])])
21:25:25,176 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:25,178 <kafka.protocol.parser>[DEBUG]: Received correlation id: 314
21:25:25,178 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:25,178 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 314 (3.023862838745117 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=312, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:25,178 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=312, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:25,178 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 312 log start offset 0 and error None.
21:25:25,179 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:25,861 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GMX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:25,863 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:26,201 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GIC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:26,203 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GIC,15600.0,4400,300.0,0.0,0.0,0.0,False,0.0,14:07:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:26,204 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:26,204 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:26,204 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:26,205 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:26,205 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:26,205 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x10\x7f\x17\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbc\xbc\x00\x00\x01\x94\x12\xce\xbc\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGIC,15600.0,4400,300.0,0.0,0.0,0....')])])}
21:25:26,205 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x10\x7f\x17\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbc\xbc\x00\x00\x01\x94\x12\xce\xbc\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGIC,15600.0,4400,300.0,0.0,0.0,0....')])])
21:25:26,205 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x10\x7f\x17\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbc\xbc\x00\x00\x01\x94\x12\xce\xbc\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGIC,15600.0,4400,300.0,0.0,0.0,0....')])])
21:25:26,206 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 315: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x10\x7f\x17\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbc\xbc\x00\x00\x01\x94\x12\xce\xbc\xbc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jGIC,15600.0,4400,300.0,0.0,0.0,0....')])])
21:25:26,208 <kafka.protocol.parser>[DEBUG]: Received correlation id: 315
21:25:26,208 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:26,208 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 315 (2.0024776458740234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=313, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:26,209 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=313, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:26,209 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 313 log start offset 0 and error None.
21:25:26,211 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:26,922 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GSM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:26,925 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GSM,24000.0,100,-500.0,0.0,0.0,0.0,False,400.0,14:28:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:26,925 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:26,925 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:26,925 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:26,926 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:26,926 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:26,926 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02C\xdb\xe4\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbf\x8d\x00\x00\x01\x94\x12\xce\xbf\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGSM,24000.0,100,-500.0,0.0,0.0,0....')])])}
21:25:26,926 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02C\xdb\xe4\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbf\x8d\x00\x00\x01\x94\x12\xce\xbf\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGSM,24000.0,100,-500.0,0.0,0.0,0....')])])
21:25:26,926 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02C\xdb\xe4\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbf\x8d\x00\x00\x01\x94\x12\xce\xbf\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGSM,24000.0,100,-500.0,0.0,0.0,0....')])])
21:25:26,926 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 316: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02C\xdb\xe4\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xbf\x8d\x00\x00\x01\x94\x12\xce\xbf\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nGSM,24000.0,100,-500.0,0.0,0.0,0....')])])
21:25:26,929 <kafka.protocol.parser>[DEBUG]: Received correlation id: 316
21:25:26,929 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:26,929 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 316 (2.999544143676758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=314, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:26,929 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=314, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:26,929 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 314 log start offset 0 and error None.
21:25:26,930 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:28,9 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GSP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:28,11 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GSP,14100.0,84900,-400.0,0.0,0.0,0.0,True,-200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:28,12 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:28,12 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:28,12 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:28,12 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:28,12 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02v\x12\xe4\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xc3\xcc\x00\x00\x01\x94\x12\xce\xc3\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGSP,14100.0,84900,-400.0,0.0,0.0,...')])])}
21:25:28,12 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02v\x12\xe4\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xc3\xcc\x00\x00\x01\x94\x12\xce\xc3\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGSP,14100.0,84900,-400.0,0.0,0.0,...')])])
21:25:28,12 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:28,13 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02v\x12\xe4\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xc3\xcc\x00\x00\x01\x94\x12\xce\xc3\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGSP,14100.0,84900,-400.0,0.0,0.0,...')])])
21:25:28,13 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 317: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02v\x12\xe4\xc8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xc3\xcc\x00\x00\x01\x94\x12\xce\xc3\xcc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGSP,14100.0,84900,-400.0,0.0,0.0,...')])])
21:25:28,15 <kafka.protocol.parser>[DEBUG]: Received correlation id: 317
21:25:28,15 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:28,15 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 317 (1.9614696502685547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=315, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:28,16 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=315, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:28,16 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 315 log start offset 0 and error None.
21:25:28,17 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:28,432 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/C36/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:28,434 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:29,746 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GTA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:29,748 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GTA,10400.0,200,50.0,0.0,0.0,0.0,False,0.0,14:18:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:29,748 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:29,748 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:29,748 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:29,749 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:29,749 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\x0f\xd9(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xca\x94\x00\x00\x01\x94\x12\xce\xca\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGTA,10400.0,200,50.0,0.0,0.0,0.0,...')])])}
21:25:29,749 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\x0f\xd9(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xca\x94\x00\x00\x01\x94\x12\xce\xca\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGTA,10400.0,200,50.0,0.0,0.0,0.0,...')])])
21:25:29,749 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:29,749 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\x0f\xd9(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xca\x94\x00\x00\x01\x94\x12\xce\xca\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGTA,10400.0,200,50.0,0.0,0.0,0.0,...')])])
21:25:29,750 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 318: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\x0f\xd9(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xca\x94\x00\x00\x01\x94\x12\xce\xca\x94\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fGTA,10400.0,200,50.0,0.0,0.0,0.0,...')])])
21:25:29,752 <kafka.protocol.parser>[DEBUG]: Received correlation id: 318
21:25:29,752 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:29,753 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 318 (2.2649765014648438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=316, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:29,753 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=316, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:29,753 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 316 log start offset 0 and error None.
21:25:29,754 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:33,714 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DDH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:33,717 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:34,17 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GTH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:34,19 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:35,272 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GTT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:35,274 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:35,576 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/H11/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:35,578 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'H11,5500.0,100,0.0,0.0,0.0,0.0,False,-200.0,14:17:07' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:35,578 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:35,578 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:35,578 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:35,579 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:35,579 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\x1c\xed.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe1Z\x00\x00\x01\x94\x12\xce\xe1Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hH11,5500.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:25:35,579 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\x1c\xed.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe1Z\x00\x00\x01\x94\x12\xce\xe1Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hH11,5500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:25:35,579 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:35,579 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\x1c\xed.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe1Z\x00\x00\x01\x94\x12\xce\xe1Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hH11,5500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:25:35,579 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 319: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe3\x1c\xed.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe1Z\x00\x00\x01\x94\x12\xce\xe1Z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hH11,5500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:25:35,581 <kafka.protocol.parser>[DEBUG]: Received correlation id: 319
21:25:35,582 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:35,582 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 319 (3.0012130737304688 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=317, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:35,582 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=317, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:35,582 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 317 log start offset 0 and error None.
21:25:35,583 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:35,984 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PHN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:35,986 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:36,301 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HC1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:36,302 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HC1,11700.0,100,900.0,0.1,0.0,0.0,False,0.0,09:34:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:36,302 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:36,303 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:36,303 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:36,303 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:36,303 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc98\x95U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe4/\x00\x00\x01\x94\x12\xce\xe4/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHC1,11700.0,100,900.0,0.1,0.0,0.0...')])])}
21:25:36,303 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc98\x95U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe4/\x00\x00\x01\x94\x12\xce\xe4/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHC1,11700.0,100,900.0,0.1,0.0,0.0...')])])
21:25:36,303 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:36,304 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc98\x95U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe4/\x00\x00\x01\x94\x12\xce\xe4/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHC1,11700.0,100,900.0,0.1,0.0,0.0...')])])
21:25:36,304 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 320: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc98\x95U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xe4/\x00\x00\x01\x94\x12\xce\xe4/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHC1,11700.0,100,900.0,0.1,0.0,0.0...')])])
21:25:36,306 <kafka.protocol.parser>[DEBUG]: Received correlation id: 320
21:25:36,307 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:36,307 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 320 (3.0074119567871094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=318, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:36,307 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=318, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:36,307 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 318 log start offset 0 and error None.
21:25:36,308 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:36,595 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HCB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:36,597 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:38,547 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HC3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:38,626 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:39,259 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:39,261 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:39,808 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:40,238 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:40,637 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:40,639 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAG,12000.0,1129400,-500.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:40,639 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:40,639 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:40,639 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:40,639 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:40,640 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02(L\xb6\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf5\x1f\x00\x00\x01\x94\x12\xce\xf5\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHAG,12000.0,1129400,-500.0,0.0,0...')])])}
21:25:40,640 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02(L\xb6\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf5\x1f\x00\x00\x01\x94\x12\xce\xf5\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHAG,12000.0,1129400,-500.0,0.0,0...')])])
21:25:40,640 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:40,640 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02(L\xb6\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf5\x1f\x00\x00\x01\x94\x12\xce\xf5\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHAG,12000.0,1129400,-500.0,0.0,0...')])])
21:25:40,640 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 321: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02(L\xb6\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf5\x1f\x00\x00\x01\x94\x12\xce\xf5\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHAG,12000.0,1129400,-500.0,0.0,0...')])])
21:25:40,643 <kafka.protocol.parser>[DEBUG]: Received correlation id: 321
21:25:40,643 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:40,643 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 321 (2.9997825622558594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=319, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:40,643 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=319, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:40,643 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 319 log start offset 0 and error None.
21:25:40,645 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:40,977 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:40,981 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAH,49000.0,109000,-50.0,0.0,0.0,0.0,True,150.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:40,981 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:40,982 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:40,982 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:40,982 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:40,983 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa7\xf3U\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf6u\x00\x00\x01\x94\x12\xce\xf6u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAH,49000.0,109000,-50.0,0.0,0.0,...')])])}
21:25:40,983 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:40,983 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa7\xf3U\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf6u\x00\x00\x01\x94\x12\xce\xf6u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAH,49000.0,109000,-50.0,0.0,0.0,...')])])
21:25:40,984 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa7\xf3U\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf6u\x00\x00\x01\x94\x12\xce\xf6u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAH,49000.0,109000,-50.0,0.0,0.0,...')])])
21:25:40,984 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 322: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa7\xf3U\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xf6u\x00\x00\x01\x94\x12\xce\xf6u\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAH,49000.0,109000,-50.0,0.0,0.0,...')])])
21:25:40,988 <kafka.protocol.parser>[DEBUG]: Received correlation id: 322
21:25:40,989 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:40,989 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 322 (4.757881164550781 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=320, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:40,989 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=320, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:40,989 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 320 log start offset 0 and error None.
21:25:40,992 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:41,733 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:41,735 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:42,632 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:42,635 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HPX,4900.0,67400,-110.0,0.0,0.0,0.0,True,-10.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:42,635 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:42,635 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:42,636 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:42,636 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:42,636 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:42,636 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\\n~\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xfc\xeb\x00\x00\x01\x94\x12\xce\xfc\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHPX,4900.0,67400,-110.0,0.0,0.0,0...')])])}
21:25:42,637 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\\n~\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xfc\xeb\x00\x00\x01\x94\x12\xce\xfc\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHPX,4900.0,67400,-110.0,0.0,0.0,0...')])])
21:25:42,637 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\\n~\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xfc\xeb\x00\x00\x01\x94\x12\xce\xfc\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHPX,4900.0,67400,-110.0,0.0,0.0,0...')])])
21:25:42,637 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 323: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\\\n~\x85\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xce\xfc\xeb\x00\x00\x01\x94\x12\xce\xfc\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHPX,4900.0,67400,-110.0,0.0,0.0,0...')])])
21:25:42,640 <kafka.protocol.parser>[DEBUG]: Received correlation id: 323
21:25:42,640 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:42,641 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 323 (4.015922546386719 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=321, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:42,641 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=321, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:42,641 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 321 log start offset 0 and error None.
21:25:42,642 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:45,540 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HID/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:45,542 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HID,2660.0,600,-20.0,0.0,0.0,0.0,False,0.0,14:24:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:45,543 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:45,543 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:45,543 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:45,543 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:45,543 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:45,544 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02(J\x0c\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x08G\x00\x00\x01\x94\x12\xcf\x08G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHID,2660.0,600,-20.0,0.0,0.0,0.0,...')])])}
21:25:45,544 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02(J\x0c\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x08G\x00\x00\x01\x94\x12\xcf\x08G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHID,2660.0,600,-20.0,0.0,0.0,0.0,...')])])
21:25:45,544 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02(J\x0c\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x08G\x00\x00\x01\x94\x12\xcf\x08G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHID,2660.0,600,-20.0,0.0,0.0,0.0,...')])])
21:25:45,544 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 324: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02(J\x0c\xb0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x08G\x00\x00\x01\x94\x12\xcf\x08G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHID,2660.0,600,-20.0,0.0,0.0,0.0,...')])])
21:25:45,547 <kafka.protocol.parser>[DEBUG]: Received correlation id: 324
21:25:45,547 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:45,547 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 324 (2.9714107513427734 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=322, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:45,547 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=322, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:45,548 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 322 log start offset 0 and error None.
21:25:45,549 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:45,874 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:45,876 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:46,209 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:46,211 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:46,526 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:46,528 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:46,795 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:46,798 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAM,30000.0,300,0.0,0.0,0.0,0.0,False,0.0,10:23:18' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:46,798 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:46,798 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:46,798 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:46,799 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:46,799 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xee\xcd\xc9#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\r.\x00\x00\x01\x94\x12\xcf\r.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHAM,30000.0,300,0.0,0.0,0.0,0.0,F...')])])}
21:25:46,799 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xee\xcd\xc9#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\r.\x00\x00\x01\x94\x12\xcf\r.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHAM,30000.0,300,0.0,0.0,0.0,0.0,F...')])])
21:25:46,799 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:46,799 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xee\xcd\xc9#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\r.\x00\x00\x01\x94\x12\xcf\r.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHAM,30000.0,300,0.0,0.0,0.0,0.0,F...')])])
21:25:46,800 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 325: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xee\xcd\xc9#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\r.\x00\x00\x01\x94\x12\xcf\r.\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHAM,30000.0,300,0.0,0.0,0.0,0.0,F...')])])
21:25:46,803 <kafka.protocol.parser>[DEBUG]: Received correlation id: 325
21:25:46,803 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:46,803 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 325 (3.2854080200195312 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=323, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:46,803 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=323, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:46,803 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 323 log start offset 0 and error None.
21:25:46,805 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:47,340 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HHV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:47,342 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HHV,11800.0,203800,150.0,0.0,0.0,0.0,True,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:47,342 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:47,342 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:47,342 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:47,342 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:47,342 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa6\xd6b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x0fN\x00\x00\x01\x94\x12\xcf\x0fN\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHHV,11800.0,203800,150.0,0.0,0.0,...')])])}
21:25:47,343 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa6\xd6b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x0fN\x00\x00\x01\x94\x12\xcf\x0fN\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHHV,11800.0,203800,150.0,0.0,0.0,...')])])
21:25:47,343 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:47,343 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa6\xd6b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x0fN\x00\x00\x01\x94\x12\xcf\x0fN\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHHV,11800.0,203800,150.0,0.0,0.0,...')])])
21:25:47,343 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 326: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa6\xd6b\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x0fN\x00\x00\x01\x94\x12\xcf\x0fN\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHHV,11800.0,203800,150.0,0.0,0.0,...')])])
21:25:47,346 <kafka.protocol.parser>[DEBUG]: Received correlation id: 326
21:25:47,346 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:47,346 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 326 (2.9959678649902344 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=324, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:47,346 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=324, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:47,346 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 324 log start offset 0 and error None.
21:25:47,348 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:48,819 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:48,821 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AAS,8900.0,100,200.0,0.0,0.0,0.0,False,200.0,14:59:31' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:48,821 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:48,821 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:48,822 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:48,822 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:48,822 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf6\xcc\xfa<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x15\x15\x00\x00\x01\x94\x12\xcf\x15\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAS,8900.0,100,200.0,0.0,0.0,0.0,...')])])}
21:25:48,822 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf6\xcc\xfa<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x15\x15\x00\x00\x01\x94\x12\xcf\x15\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAS,8900.0,100,200.0,0.0,0.0,0.0,...')])])
21:25:48,822 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf6\xcc\xfa<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x15\x15\x00\x00\x01\x94\x12\xcf\x15\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAS,8900.0,100,200.0,0.0,0.0,0.0,...')])])
21:25:48,822 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 327: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf6\xcc\xfa<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x15\x15\x00\x00\x01\x94\x12\xcf\x15\x15\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jAAS,8900.0,100,200.0,0.0,0.0,0.0,...')])])
21:25:48,823 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:48,825 <kafka.protocol.parser>[DEBUG]: Received correlation id: 327
21:25:48,825 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:48,825 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 327 (2.1562576293945312 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=325, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:48,825 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=325, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:48,825 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 325 log start offset 0 and error None.
21:25:48,826 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:49,122 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BBM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:49,124 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:49,746 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:49,748 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAN,10100.0,1000,100.0,0.0,0.0,0.0,False,0.0,14:59:16' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:49,748 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:49,748 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:49,748 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:49,749 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:49,749 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:49,749 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9b\xe2\x13{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x18\xb4\x00\x00\x01\x94\x12\xcf\x18\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAN,10100.0,1000,100.0,0.0,0.0,0....')])])}
21:25:49,749 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9b\xe2\x13{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x18\xb4\x00\x00\x01\x94\x12\xcf\x18\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAN,10100.0,1000,100.0,0.0,0.0,0....')])])
21:25:49,749 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9b\xe2\x13{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x18\xb4\x00\x00\x01\x94\x12\xcf\x18\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAN,10100.0,1000,100.0,0.0,0.0,0....')])])
21:25:49,749 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 328: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9b\xe2\x13{\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x18\xb4\x00\x00\x01\x94\x12\xcf\x18\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAN,10100.0,1000,100.0,0.0,0.0,0....')])])
21:25:49,752 <kafka.protocol.parser>[DEBUG]: Received correlation id: 328
21:25:49,752 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:49,752 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 328 (2.001523971557617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=326, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:49,752 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=326, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:49,752 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 326 log start offset 0 and error None.
21:25:49,756 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:50,47 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HD6/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:50,49 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HD6,12500.0,100,0.0,0.0,0.0,0.0,False,100.0,14:51:40' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,49 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,49 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:50,49 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:50,50 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,50 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:50,50 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\n\x1a\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x19\xe1\x00\x00\x01\x94\x12\xcf\x19\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD6,12500.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:25:50,50 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\n\x1a\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x19\xe1\x00\x00\x01\x94\x12\xcf\x19\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD6,12500.0,100,0.0,0.0,0.0,0.0,F...')])])
21:25:50,50 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\n\x1a\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x19\xe1\x00\x00\x01\x94\x12\xcf\x19\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD6,12500.0,100,0.0,0.0,0.0,0.0,F...')])])
21:25:50,50 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 329: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x11\n\x1a\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x19\xe1\x00\x00\x01\x94\x12\xcf\x19\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD6,12500.0,100,0.0,0.0,0.0,0.0,F...')])])
21:25:50,53 <kafka.protocol.parser>[DEBUG]: Received correlation id: 329
21:25:50,53 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:50,53 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 329 (3.148317337036133 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=327, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:50,53 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=327, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:50,53 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 327 log start offset 0 and error None.
21:25:50,55 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:50,374 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:50,376 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:50,705 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HSM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:50,707 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HSM,5400.0,200,0.0,0.0,0.0,0.0,False,0.0,09:58:44' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,707 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,707 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:50,708 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:50,708 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:50,708 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa2\xfe\x8bk\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1cs\x00\x00\x01\x94\x12\xcf\x1cs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHSM,5400.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:25:50,708 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa2\xfe\x8bk\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1cs\x00\x00\x01\x94\x12\xcf\x1cs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHSM,5400.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:25:50,708 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa2\xfe\x8bk\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1cs\x00\x00\x01\x94\x12\xcf\x1cs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHSM,5400.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:25:50,708 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 330: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa2\xfe\x8bk\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1cs\x00\x00\x01\x94\x12\xcf\x1cs\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHSM,5400.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:25:50,709 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,711 <kafka.protocol.parser>[DEBUG]: Received correlation id: 330
21:25:50,711 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:50,711 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 330 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=328, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:50,711 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=328, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:50,712 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 328 log start offset 0 and error None.
21:25:50,713 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:50,994 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:50,997 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAP,4490.0,7300,10.0,0.0,0.0,0.0,False,10.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,998 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:50,998 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:50,998 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:50,999 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:50,999 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xbe F\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1d\x96\x00\x00\x01\x94\x12\xcf\x1d\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAP,4490.0,7300,10.0,0.0,0.0,0.0,...')])])}
21:25:51,0 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xbe F\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1d\x96\x00\x00\x01\x94\x12\xcf\x1d\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAP,4490.0,7300,10.0,0.0,0.0,0.0,...')])])
21:25:51,0 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xbe F\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1d\x96\x00\x00\x01\x94\x12\xcf\x1d\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAP,4490.0,7300,10.0,0.0,0.0,0.0,...')])])
21:25:51,1 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:51,1 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 331: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xbe F\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x1d\x96\x00\x00\x01\x94\x12\xcf\x1d\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAP,4490.0,7300,10.0,0.0,0.0,0.0,...')])])
21:25:51,7 <kafka.protocol.parser>[DEBUG]: Received correlation id: 331
21:25:51,7 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:51,8 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 331 (7.002115249633789 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=329, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:51,8 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=329, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:51,9 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 329 log start offset 0 and error None.
21:25:51,11 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:53,698 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:54,90 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTM,10600.0,1400,-1100.0,-0.1,0.0,0.0,False,-100.0,13:07:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,90 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,90 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:54,91 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:54,91 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:54,91 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,91 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xd1\xa3\xc8\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf)\xaa\x00\x00\x01\x94\x12\xcf)\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHTM,10600.0,1400,-1100.0,-0.1,0....')])])}
21:25:54,92 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xd1\xa3\xc8\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf)\xaa\x00\x00\x01\x94\x12\xcf)\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHTM,10600.0,1400,-1100.0,-0.1,0....')])])
21:25:54,92 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xd1\xa3\xc8\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf)\xaa\x00\x00\x01\x94\x12\xcf)\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHTM,10600.0,1400,-1100.0,-0.1,0....')])])
21:25:54,92 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 332: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xd1\xa3\xc8\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf)\xaa\x00\x00\x01\x94\x12\xcf)\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHTM,10600.0,1400,-1100.0,-0.1,0....')])])
21:25:54,96 <kafka.protocol.parser>[DEBUG]: Received correlation id: 332
21:25:54,96 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:54,96 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 332 (2.991199493408203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=330, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:54,96 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=330, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:54,97 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 330 log start offset 0 and error None.
21:25:54,98 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:54,410 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:54,413 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAR,3400.0,9900,-60.0,0.0,0.0,0.0,False,0.0,14:25:56' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,413 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,413 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:54,413 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:54,413 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:54,414 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcfn\x8f3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf*\xed\x00\x00\x01\x94\x12\xcf*\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAR,3400.0,9900,-60.0,0.0,0.0,0.0...')])])}
21:25:54,414 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,414 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcfn\x8f3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf*\xed\x00\x00\x01\x94\x12\xcf*\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAR,3400.0,9900,-60.0,0.0,0.0,0.0...')])])
21:25:54,414 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcfn\x8f3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf*\xed\x00\x00\x01\x94\x12\xcf*\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAR,3400.0,9900,-60.0,0.0,0.0,0.0...')])])
21:25:54,414 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 333: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xcfn\x8f3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf*\xed\x00\x00\x01\x94\x12\xcf*\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHAR,3400.0,9900,-60.0,0.0,0.0,0.0...')])])
21:25:54,417 <kafka.protocol.parser>[DEBUG]: Received correlation id: 333
21:25:54,417 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:54,417 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 333 (3.0083656311035156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=331, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:54,417 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=331, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:54,417 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 331 log start offset 0 and error None.
21:25:54,418 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:54,732 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:54,734 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAS,8100.0,100,300.0,0.0,0.0,0.0,False,0.0,13:22:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,735 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,735 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:54,735 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:54,735 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:54,735 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02i\xf0W[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf,/\x00\x00\x01\x94\x12\xcf,/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHAS,8100.0,100,300.0,0.0,0.0,0.0,...')])])}
21:25:54,735 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02i\xf0W[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf,/\x00\x00\x01\x94\x12\xcf,/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHAS,8100.0,100,300.0,0.0,0.0,0.0,...')])])
21:25:54,736 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:54,736 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02i\xf0W[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf,/\x00\x00\x01\x94\x12\xcf,/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHAS,8100.0,100,300.0,0.0,0.0,0.0,...')])])
21:25:54,736 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 334: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02i\xf0W[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf,/\x00\x00\x01\x94\x12\xcf,/\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHAS,8100.0,100,300.0,0.0,0.0,0.0,...')])])
21:25:54,739 <kafka.protocol.parser>[DEBUG]: Received correlation id: 334
21:25:54,739 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:54,739 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 334 (2.9997825622558594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=332, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:54,739 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=332, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:54,739 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 332 log start offset 0 and error None.
21:25:54,740 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:55,244 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HES/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:55,653 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:56,106 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:56,108 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAT,41900.0,100,-600.0,0.0,0.0,0.0,False,1000.0,14:27:44' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:56,108 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:56,108 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:56,109 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:56,109 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:56,109 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02"*H\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf1\x8c\x00\x00\x01\x94\x12\xcf1\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAT,41900.0,100,-600.0,0.0,0.0,0....')])])}
21:25:56,109 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02"*H\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf1\x8c\x00\x00\x01\x94\x12\xcf1\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAT,41900.0,100,-600.0,0.0,0.0,0....')])])
21:25:56,109 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02"*H\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf1\x8c\x00\x00\x01\x94\x12\xcf1\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAT,41900.0,100,-600.0,0.0,0.0,0....')])])
21:25:56,109 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 335: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02"*H\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf1\x8c\x00\x00\x01\x94\x12\xcf1\x8c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAT,41900.0,100,-600.0,0.0,0.0,0....')])])
21:25:56,110 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:56,112 <kafka.protocol.parser>[DEBUG]: Received correlation id: 335
21:25:56,112 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:56,112 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 335 (1.992940902709961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=333, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:56,112 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=333, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:56,112 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 333 log start offset 0 and error None.
21:25:56,114 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:58,553 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GH3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:58,555 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:58,883 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:58,885 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAV,3400.0,300,300.0,0.1,0.0,0.0,False,100.0,14:14:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:25:58,885 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:25:58,885 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:25:58,885 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:25:58,886 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9fe\xf3\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf<e\x00\x00\x01\x94\x12\xcf<e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAV,3400.0,300,300.0,0.1,0.0,0.0,...')])])}
21:25:58,886 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9fe\xf3\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf<e\x00\x00\x01\x94\x12\xcf<e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAV,3400.0,300,300.0,0.1,0.0,0.0,...')])])
21:25:58,886 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:25:58,886 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9fe\xf3\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf<e\x00\x00\x01\x94\x12\xcf<e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAV,3400.0,300,300.0,0.1,0.0,0.0,...')])])
21:25:58,886 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 336: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x9fe\xf3\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf<e\x00\x00\x01\x94\x12\xcf<e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHAV,3400.0,300,300.0,0.1,0.0,0.0,...')])])
21:25:58,886 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:25:58,888 <kafka.protocol.parser>[DEBUG]: Received correlation id: 336
21:25:58,889 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:25:58,889 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 336 (3.0002593994140625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=334, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:58,889 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=334, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:25:58,889 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 334 log start offset 0 and error None.
21:25:58,890 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:59,306 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HGW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:59,308 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:25:59,615 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:25:59,617 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:01,956 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:01,958 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAX,17650.0,32000,-300.0,0.0,0.0,0.0,True,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:01,958 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:01,958 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:01,958 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:01,958 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:01,959 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:01,959 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x99\xb8\r\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfHf\x00\x00\x01\x94\x12\xcfHf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHAX,17650.0,32000,-300.0,0.0,0.0,...')])])}
21:26:01,959 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x99\xb8\r\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfHf\x00\x00\x01\x94\x12\xcfHf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHAX,17650.0,32000,-300.0,0.0,0.0,...')])])
21:26:01,959 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x99\xb8\r\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfHf\x00\x00\x01\x94\x12\xcfHf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHAX,17650.0,32000,-300.0,0.0,0.0,...')])])
21:26:01,959 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 337: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x99\xb8\r\xc3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfHf\x00\x00\x01\x94\x12\xcfHf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHAX,17650.0,32000,-300.0,0.0,0.0,...')])])
21:26:01,961 <kafka.protocol.parser>[DEBUG]: Received correlation id: 337
21:26:01,961 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:01,962 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 337 (2.9997825622558594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=335, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:01,962 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=335, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:01,962 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 335 log start offset 0 and error None.
21:26:01,963 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:02,854 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:02,857 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HBC,6200.0,200,-600.0,-0.1,0.0,0.0,False,100.0,14:59:08' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:02,857 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:02,857 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:02,857 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:02,857 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:02,857 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r]\x13_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfK\xe9\x00\x00\x01\x94\x12\xcfK\xe9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHBC,6200.0,200,-600.0,-0.1,0.0,0....')])])}
21:26:02,858 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r]\x13_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfK\xe9\x00\x00\x01\x94\x12\xcfK\xe9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHBC,6200.0,200,-600.0,-0.1,0.0,0....')])])
21:26:02,858 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r]\x13_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfK\xe9\x00\x00\x01\x94\x12\xcfK\xe9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHBC,6200.0,200,-600.0,-0.1,0.0,0....')])])
21:26:02,858 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:02,858 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 338: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r]\x13_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfK\xe9\x00\x00\x01\x94\x12\xcfK\xe9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHBC,6200.0,200,-600.0,-0.1,0.0,0....')])])
21:26:02,861 <kafka.protocol.parser>[DEBUG]: Received correlation id: 338
21:26:02,861 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:02,861 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 338 (2.9916763305664062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=336, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:02,861 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=336, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:02,861 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 336 log start offset 0 and error None.
21:26:02,863 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:03,161 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HBD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:03,163 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:03,427 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HBH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:03,429 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HBH,4800.0,200,100.0,0.0,0.0,0.0,False,0.0,13:13:58' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:03,429 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:03,429 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:03,429 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:03,430 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:03,430 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe9rOs\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfN%\x00\x00\x01\x94\x12\xcfN%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHBH,4800.0,200,100.0,0.0,0.0,0.0,...')])])}
21:26:03,430 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe9rOs\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfN%\x00\x00\x01\x94\x12\xcfN%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHBH,4800.0,200,100.0,0.0,0.0,0.0,...')])])
21:26:03,430 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe9rOs\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfN%\x00\x00\x01\x94\x12\xcfN%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHBH,4800.0,200,100.0,0.0,0.0,0.0,...')])])
21:26:03,430 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:03,430 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 339: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xe9rOs\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfN%\x00\x00\x01\x94\x12\xcfN%\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHBH,4800.0,200,100.0,0.0,0.0,0.0,...')])])
21:26:03,433 <kafka.protocol.parser>[DEBUG]: Received correlation id: 339
21:26:03,433 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:03,433 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 339 (1.9998550415039062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=337, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:03,433 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=337, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:03,433 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 337 log start offset 0 and error None.
21:26:03,434 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:03,742 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HBS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:03,745 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HBS,6600.0,12200,200.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:03,745 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:03,745 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:03,745 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:03,745 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:03,745 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02i\xa09%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfOa\x00\x00\x01\x94\x12\xcfOa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHBS,6600.0,12200,200.0,0.0,0.0,0....')])])}
21:26:03,746 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02i\xa09%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfOa\x00\x00\x01\x94\x12\xcfOa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHBS,6600.0,12200,200.0,0.0,0.0,0....')])])
21:26:03,746 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02i\xa09%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfOa\x00\x00\x01\x94\x12\xcfOa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHBS,6600.0,12200,200.0,0.0,0.0,0....')])])
21:26:03,746 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 340: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02i\xa09%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfOa\x00\x00\x01\x94\x12\xcfOa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHBS,6600.0,12200,200.0,0.0,0.0,0....')])])
21:26:03,746 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:03,748 <kafka.protocol.parser>[DEBUG]: Received correlation id: 340
21:26:03,748 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:03,748 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 340 (2.0012855529785156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=338, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:03,749 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=338, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:03,749 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 338 log start offset 0 and error None.
21:26:03,750 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:04,141 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HCC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:04,143 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HCC,12500.0,1000,100.0,0.0,0.0,0.0,False,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:04,143 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:04,143 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:04,143 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:04,143 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:04,144 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:04,144 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02Y\x84\xeaq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfP\xef\x00\x00\x01\x94\x12\xcfP\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHCC,12500.0,1000,100.0,0.0,0.0,0....')])])}
21:26:04,144 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02Y\x84\xeaq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfP\xef\x00\x00\x01\x94\x12\xcfP\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHCC,12500.0,1000,100.0,0.0,0.0,0....')])])
21:26:04,144 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02Y\x84\xeaq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfP\xef\x00\x00\x01\x94\x12\xcfP\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHCC,12500.0,1000,100.0,0.0,0.0,0....')])])
21:26:04,144 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 341: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02Y\x84\xeaq\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfP\xef\x00\x00\x01\x94\x12\xcfP\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHCC,12500.0,1000,100.0,0.0,0.0,0....')])])
21:26:04,146 <kafka.protocol.parser>[DEBUG]: Received correlation id: 341
21:26:04,146 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:04,147 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 341 (2.9921531677246094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=339, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:04,147 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=339, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:04,147 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 339 log start offset 0 and error None.
21:26:04,148 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:04,743 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/XDH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:04,745 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:06,188 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HCD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:06,190 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HCD,8930.0,5600,-110.0,0.0,0.0,0.0,False,-50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:06,190 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:06,191 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:06,191 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:06,191 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:06,191 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf3'\x88\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfX\xef\x00\x00\x01\x94\x12\xcfX\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHCD,8930.0,5600,-110.0,0.0,0.0,0....")])])}
21:26:06,191 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf3'\x88\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfX\xef\x00\x00\x01\x94\x12\xcfX\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHCD,8930.0,5600,-110.0,0.0,0.0,0....")])])
21:26:06,191 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf3'\x88\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfX\xef\x00\x00\x01\x94\x12\xcfX\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHCD,8930.0,5600,-110.0,0.0,0.0,0....")])])
21:26:06,191 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:06,192 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 342: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xf3'\x88\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfX\xef\x00\x00\x01\x94\x12\xcfX\xef\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHCD,8930.0,5600,-110.0,0.0,0.0,0....")])])
21:26:06,194 <kafka.protocol.parser>[DEBUG]: Received correlation id: 342
21:26:06,194 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:06,194 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 342 (1.970052719116211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=340, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:06,195 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=340, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:06,195 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 340 log start offset 0 and error None.
21:26:06,196 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:06,516 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HCI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:06,518 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:07,499 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:07,500 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HCM,29450.0,441400,150.0,0.0,0.0,0.0,True,-100.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:07,500 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:07,502 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:07,502 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:07,502 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:07,502 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\x01I\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf^\x0c\x00\x00\x01\x94\x12\xcf^\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHCM,29450.0,441400,150.0,0.0,0.0,...')])])}
21:26:07,502 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\x01I\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf^\x0c\x00\x00\x01\x94\x12\xcf^\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHCM,29450.0,441400,150.0,0.0,0.0,...')])])
21:26:07,502 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\x01I\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf^\x0c\x00\x00\x01\x94\x12\xcf^\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHCM,29450.0,441400,150.0,0.0,0.0,...')])])
21:26:07,502 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:07,502 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 343: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\x01I\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf^\x0c\x00\x00\x01\x94\x12\xcf^\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHCM,29450.0,441400,150.0,0.0,0.0,...')])])
21:26:07,505 <kafka.protocol.parser>[DEBUG]: Received correlation id: 343
21:26:07,505 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:07,505 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 343 (1.9993782043457031 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=341, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:07,506 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=341, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:07,506 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 341 log start offset 0 and error None.
21:26:07,507 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:08,64 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:08,66 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTE,3900.0,200,0.0,0.0,0.0,0.0,False,100.0,14:59:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:08,66 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:08,66 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:08,66 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:08,66 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:08,66 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x84b\xa4P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf`B\x00\x00\x01\x94\x12\xcf`B\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHTE,3900.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:26:08,67 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x84b\xa4P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf`B\x00\x00\x01\x94\x12\xcf`B\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHTE,3900.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:26:08,67 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x84b\xa4P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf`B\x00\x00\x01\x94\x12\xcf`B\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHTE,3900.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:26:08,66 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:08,67 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 344: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x84b\xa4P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf`B\x00\x00\x01\x94\x12\xcf`B\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHTE,3900.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:26:08,69 <kafka.protocol.parser>[DEBUG]: Received correlation id: 344
21:26:08,70 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:08,70 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 344 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=342, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:08,70 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=342, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:08,71 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 342 log start offset 0 and error None.
21:26:08,72 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:09,406 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HCT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:09,799 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:10,556 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:10,645 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HDA,3700.0,4700,0.0,0.0,0.0,0.0,False,0.0,13:30:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:10,645 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:10,645 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:10,646 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:10,646 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:10,646 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x0214\xb14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfjU\x00\x00\x01\x94\x12\xcfjU\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHDA,3700.0,4700,0.0,0.0,0.0,0.0,F...')])])}
21:26:10,646 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x0214\xb14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfjU\x00\x00\x01\x94\x12\xcfjU\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHDA,3700.0,4700,0.0,0.0,0.0,0.0,F...')])])
21:26:10,646 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x0214\xb14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfjU\x00\x00\x01\x94\x12\xcfjU\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHDA,3700.0,4700,0.0,0.0,0.0,0.0,F...')])])
21:26:10,646 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 345: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x0214\xb14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfjU\x00\x00\x01\x94\x12\xcfjU\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHDA,3700.0,4700,0.0,0.0,0.0,0.0,F...')])])
21:26:10,647 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:10,649 <kafka.protocol.parser>[DEBUG]: Received correlation id: 345
21:26:10,649 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:10,649 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 345 (1.9998550415039062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=343, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:10,649 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=343, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:10,649 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 343 log start offset 0 and error None.
21:26:10,651 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:11,992 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:11,993 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HDB,24950.0,2245600,800.0,0.0,0.0,0.0,True,550.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:11,994 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:11,994 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:11,994 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:11,994 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:11,994 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\xed]S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfo\x9a\x00\x00\x01\x94\x12\xcfo\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHDB,24950.0,2245600,800.0,0.0,0.0...')])])}
21:26:11,994 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\xed]S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfo\x9a\x00\x00\x01\x94\x12\xcfo\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHDB,24950.0,2245600,800.0,0.0,0.0...')])])
21:26:11,995 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:11,995 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\xed]S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfo\x9a\x00\x00\x01\x94\x12\xcfo\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHDB,24950.0,2245600,800.0,0.0,0.0...')])])
21:26:11,995 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 346: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xe3\xed]S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfo\x9a\x00\x00\x01\x94\x12\xcfo\x9a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHDB,24950.0,2245600,800.0,0.0,0.0...')])])
21:26:11,997 <kafka.protocol.parser>[DEBUG]: Received correlation id: 346
21:26:11,998 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:11,998 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 346 (2.9697418212890625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=344, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:11,998 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=344, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:11,998 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 344 log start offset 0 and error None.
21:26:11,999 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:12,439 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:12,441 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HDC,25150.0,112000,-200.0,0.0,0.0,0.0,True,-150.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:12,441 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:12,441 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:12,441 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:12,441 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:12,441 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:12,441 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeaO\x8f\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfqY\x00\x00\x01\x94\x12\xcfqY\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDC,25150.0,112000,-200.0,0.0,0....')])])}
21:26:12,443 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeaO\x8f\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfqY\x00\x00\x01\x94\x12\xcfqY\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDC,25150.0,112000,-200.0,0.0,0....')])])
21:26:12,443 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeaO\x8f\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfqY\x00\x00\x01\x94\x12\xcfqY\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDC,25150.0,112000,-200.0,0.0,0....')])])
21:26:12,443 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 347: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xeaO\x8f\x93\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfqY\x00\x00\x01\x94\x12\xcfqY\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDC,25150.0,112000,-200.0,0.0,0....')])])
21:26:12,445 <kafka.protocol.parser>[DEBUG]: Received correlation id: 347
21:26:12,445 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:12,445 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 347 (2.866983413696289 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=345, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:12,445 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=345, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:12,445 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 345 log start offset 0 and error None.
21:26:12,446 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:13,250 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:13,252 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HDG,29050.0,799300,-750.0,0.0,0.0,0.0,True,-200.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:13,252 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:13,252 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:13,252 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:13,253 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:13,253 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x90\xd7\x013\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcft\x84\x00\x00\x01\x94\x12\xcft\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDG,29050.0,799300,-750.0,0.0,0....')])])}
21:26:13,253 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x90\xd7\x013\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcft\x84\x00\x00\x01\x94\x12\xcft\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDG,29050.0,799300,-750.0,0.0,0....')])])
21:26:13,253 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:13,253 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x90\xd7\x013\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcft\x84\x00\x00\x01\x94\x12\xcft\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDG,29050.0,799300,-750.0,0.0,0....')])])
21:26:13,254 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 348: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x90\xd7\x013\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcft\x84\x00\x00\x01\x94\x12\xcft\x84\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tHDG,29050.0,799300,-750.0,0.0,0....')])])
21:26:13,256 <kafka.protocol.parser>[DEBUG]: Received correlation id: 348
21:26:13,256 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:13,257 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 348 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=346, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:13,257 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=346, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:13,257 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 346 log start offset 0 and error None.
21:26:13,258 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:13,807 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:13,809 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HDM,32500.0,500,200.0,0.0,0.0,0.0,False,-100.0,14:52:17' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:13,810 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:13,810 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:13,810 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:13,810 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:13,810 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02nw\x01\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfv\xb2\x00\x00\x01\x94\x12\xcfv\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHDM,32500.0,500,200.0,0.0,0.0,0.0...')])])}
21:26:13,810 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02nw\x01\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfv\xb2\x00\x00\x01\x94\x12\xcfv\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHDM,32500.0,500,200.0,0.0,0.0,0.0...')])])
21:26:13,811 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02nw\x01\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfv\xb2\x00\x00\x01\x94\x12\xcfv\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHDM,32500.0,500,200.0,0.0,0.0,0.0...')])])
21:26:13,810 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:13,811 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 349: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02nw\x01\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcfv\xb2\x00\x00\x01\x94\x12\xcfv\xb2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHDM,32500.0,500,200.0,0.0,0.0,0.0...')])])
21:26:13,814 <kafka.protocol.parser>[DEBUG]: Received correlation id: 349
21:26:13,814 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:13,814 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 349 (3.0155181884765625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=347, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:13,814 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=347, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:13,814 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 347 log start offset 0 and error None.
21:26:13,816 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:14,122 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDO/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:14,124 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:14,445 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:14,447 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:14,824 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HDW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:14,826 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:16,239 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HEC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:16,330 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:16,608 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HEJ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:16,616 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HEJ,10000.0,100,1300.0,0.1,0.0,0.0,False,1000.0,10:44:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:16,616 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:16,617 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:16,617 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:16,619 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:16,619 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02u\t\x15\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x81\xa9\x00\x00\x01\x94\x12\xcf\x81\xa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHEJ,10000.0,100,1300.0,0.1,0.0,0....')])])}
21:26:16,620 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02u\t\x15\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x81\xa9\x00\x00\x01\x94\x12\xcf\x81\xa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHEJ,10000.0,100,1300.0,0.1,0.0,0....')])])
21:26:16,622 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02u\t\x15\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x81\xa9\x00\x00\x01\x94\x12\xcf\x81\xa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHEJ,10000.0,100,1300.0,0.1,0.0,0....')])])
21:26:16,623 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 350: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02u\t\x15\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x81\xa9\x00\x00\x01\x94\x12\xcf\x81\xa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHEJ,10000.0,100,1300.0,0.1,0.0,0....')])])
21:26:16,624 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:16,630 <kafka.protocol.parser>[DEBUG]: Received correlation id: 350
21:26:16,630 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:16,631 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 350 (6.659507751464844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=348, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:16,631 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=348, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:16,631 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 348 log start offset 0 and error None.
21:26:16,634 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:16,956 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HEM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:16,958 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:18,797 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HEP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:18,798 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:19,440 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HEV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:19,441 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:19,783 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HFC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:19,785 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HFC,7200.0,1000,800.0,0.1,0.0,0.0,False,-100.0,13:14:57' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:19,785 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:19,786 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:19,786 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:19,786 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:19,786 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:19,786 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02QB\x0b\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x8e\t\x00\x00\x01\x94\x12\xcf\x8e\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHFC,7200.0,1000,800.0,0.1,0.0,0.0...')])])}
21:26:19,787 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02QB\x0b\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x8e\t\x00\x00\x01\x94\x12\xcf\x8e\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHFC,7200.0,1000,800.0,0.1,0.0,0.0...')])])
21:26:19,787 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02QB\x0b\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x8e\t\x00\x00\x01\x94\x12\xcf\x8e\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHFC,7200.0,1000,800.0,0.1,0.0,0.0...')])])
21:26:19,787 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 351: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02QB\x0b\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x8e\t\x00\x00\x01\x94\x12\xcf\x8e\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHFC,7200.0,1000,800.0,0.1,0.0,0.0...')])])
21:26:19,795 <kafka.protocol.parser>[DEBUG]: Received correlation id: 351
21:26:19,795 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:19,795 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 351 (8.044958114624023 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=349, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:19,795 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=349, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:19,796 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 349 log start offset 0 and error None.
21:26:19,797 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:20,292 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HFX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:20,294 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:20,604 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HGM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:20,606 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HGM,232200.0,100,-7600.0,0.0,0.0,0.0,False,100.0,14:10:18' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:20,606 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:20,606 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:20,606 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:20,607 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:20,607 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xad\x8e{U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x91>\x00\x00\x01\x94\x12\xcf\x91>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHGM,232200.0,100,-7600.0,0.0,0.0,...')])])}
21:26:20,607 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xad\x8e{U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x91>\x00\x00\x01\x94\x12\xcf\x91>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHGM,232200.0,100,-7600.0,0.0,0.0,...')])])
21:26:20,607 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xad\x8e{U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x91>\x00\x00\x01\x94\x12\xcf\x91>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHGM,232200.0,100,-7600.0,0.0,0.0,...')])])
21:26:20,607 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:20,607 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 352: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xad\x8e{U\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x91>\x00\x00\x01\x94\x12\xcf\x91>\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHGM,232200.0,100,-7600.0,0.0,0.0,...')])])
21:26:20,610 <kafka.protocol.parser>[DEBUG]: Received correlation id: 352
21:26:20,610 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:20,610 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 352 (2.964496612548828 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=350, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:20,610 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=350, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:20,610 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 350 log start offset 0 and error None.
21:26:20,611 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:20,892 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HGT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:20,894 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:21,181 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:21,183 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HHC,134000.0,100,-6000.0,0.0,0.0,0.0,False,-19000.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:21,183 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:21,184 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:21,184 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:21,184 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:21,184 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00u\x00\x00\x00\x00\x02\xf3\x06\xd4\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x93\x7f\x00\x00\x01\x94\x12\xcf\x93\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x84\x01\x00\x00\x00\x01xHHC,134000.0,100,-6000.0,0.0,0.0...')])])}
21:26:21,184 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00u\x00\x00\x00\x00\x02\xf3\x06\xd4\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x93\x7f\x00\x00\x01\x94\x12\xcf\x93\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x84\x01\x00\x00\x00\x01xHHC,134000.0,100,-6000.0,0.0,0.0...')])])
21:26:21,184 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:21,185 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00u\x00\x00\x00\x00\x02\xf3\x06\xd4\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x93\x7f\x00\x00\x01\x94\x12\xcf\x93\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x84\x01\x00\x00\x00\x01xHHC,134000.0,100,-6000.0,0.0,0.0...')])])
21:26:21,185 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 353: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00u\x00\x00\x00\x00\x02\xf3\x06\xd4\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x93\x7f\x00\x00\x01\x94\x12\xcf\x93\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x84\x01\x00\x00\x00\x01xHHC,134000.0,100,-6000.0,0.0,0.0...')])])
21:26:21,188 <kafka.protocol.parser>[DEBUG]: Received correlation id: 353
21:26:21,188 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:21,188 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 353 (2.9938220977783203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=351, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:21,188 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=351, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:21,188 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 351 log start offset 0 and error None.
21:26:21,190 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:21,853 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HHG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:21,855 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HHG,1600.0,1000,200.0,0.1,0.0,0.0,False,0.0,14:28:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:21,855 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:21,856 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:21,856 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:21,856 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:21,856 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:21,856 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x89\xb4`\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x96 \x00\x00\x01\x94\x12\xcf\x96 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHG,1600.0,1000,200.0,0.1,0.0,0.0...')])])}
21:26:21,857 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x89\xb4`\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x96 \x00\x00\x01\x94\x12\xcf\x96 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHG,1600.0,1000,200.0,0.1,0.0,0.0...')])])
21:26:21,857 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x89\xb4`\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x96 \x00\x00\x01\x94\x12\xcf\x96 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHG,1600.0,1000,200.0,0.1,0.0,0.0...')])])
21:26:21,857 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 354: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x89\xb4`\xa8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\x96 \x00\x00\x01\x94\x12\xcf\x96 \xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHG,1600.0,1000,200.0,0.1,0.0,0.0...')])])
21:26:21,859 <kafka.protocol.parser>[DEBUG]: Received correlation id: 354
21:26:21,859 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:21,860 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 354 (3.0112266540527344 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=352, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:21,860 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=352, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:21,860 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 352 log start offset 0 and error None.
21:26:21,861 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:23,171 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HHN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:23,173 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:24,507 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HHP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:24,509 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HHP,8320.0,500,-50.0,0.0,0.0,0.0,False,90.0,14:19:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:24,509 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:24,509 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:24,509 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:24,509 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:24,510 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x95\xeb{5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa0}\x00\x00\x01\x94\x12\xcf\xa0}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHP,8320.0,500,-50.0,0.0,0.0,0.0,...')])])}
21:26:24,510 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x95\xeb{5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa0}\x00\x00\x01\x94\x12\xcf\xa0}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHP,8320.0,500,-50.0,0.0,0.0,0.0,...')])])
21:26:24,510 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x95\xeb{5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa0}\x00\x00\x01\x94\x12\xcf\xa0}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHP,8320.0,500,-50.0,0.0,0.0,0.0,...')])])
21:26:24,510 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:24,510 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 355: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x95\xeb{5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa0}\x00\x00\x01\x94\x12\xcf\xa0}\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHHP,8320.0,500,-50.0,0.0,0.0,0.0,...')])])
21:26:24,513 <kafka.protocol.parser>[DEBUG]: Received correlation id: 355
21:26:24,513 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:24,513 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 355 (2.9916763305664062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=353, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:24,513 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=353, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:24,513 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 353 log start offset 0 and error None.
21:26:24,514 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:24,934 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HHR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:24,937 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:25,280 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HHS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:25,282 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HHS,7430.0,166100,-150.0,0.0,0.0,0.0,True,-40.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:25,282 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:25,283 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:25,283 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:25,283 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:25,283 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02[\xc3\xee\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa3\x83\x00\x00\x01\x94\x12\xcf\xa3\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHHS,7430.0,166100,-150.0,0.0,0.0,...')])])}
21:26:25,283 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02[\xc3\xee\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa3\x83\x00\x00\x01\x94\x12\xcf\xa3\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHHS,7430.0,166100,-150.0,0.0,0.0,...')])])
21:26:25,283 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02[\xc3\xee\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa3\x83\x00\x00\x01\x94\x12\xcf\xa3\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHHS,7430.0,166100,-150.0,0.0,0.0,...')])])
21:26:25,284 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 356: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02[\xc3\xee\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa3\x83\x00\x00\x01\x94\x12\xcf\xa3\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHHS,7430.0,166100,-150.0,0.0,0.0,...')])])
21:26:25,284 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:25,286 <kafka.protocol.parser>[DEBUG]: Received correlation id: 356
21:26:25,287 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:25,287 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 356 (2.9976367950439453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=354, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:25,287 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=354, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:25,287 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 354 log start offset 0 and error None.
21:26:25,288 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:25,593 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TCH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:25,595 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'TCH,15450.0,346700,-200.0,0.0,0.0,0.0,True,-100.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:25,595 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:25,595 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:25,595 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:25,595 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:25,596 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf1,h\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa4\xbb\x00\x00\x01\x94\x12\xcf\xa4\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tTCH,15450.0,346700,-200.0,0.0,0....')])])}
21:26:25,596 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf1,h\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa4\xbb\x00\x00\x01\x94\x12\xcf\xa4\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tTCH,15450.0,346700,-200.0,0.0,0....')])])
21:26:25,596 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf1,h\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa4\xbb\x00\x00\x01\x94\x12\xcf\xa4\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tTCH,15450.0,346700,-200.0,0.0,0....')])])
21:26:25,596 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:25,596 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 357: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xf1,h\xc0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xa4\xbb\x00\x00\x01\x94\x12\xcf\xa4\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tTCH,15450.0,346700,-200.0,0.0,0....')])])
21:26:25,599 <kafka.protocol.parser>[DEBUG]: Received correlation id: 357
21:26:25,599 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:25,599 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 357 (2.3107528686523438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=355, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:25,599 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=355, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:25,599 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 355 log start offset 0 and error None.
21:26:25,601 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:27,307 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HSL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:27,309 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HSL,4150.0,600,30.0,0.0,0.0,0.0,False,0.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:27,309 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:27,309 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:27,309 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:27,309 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:27,309 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xda>3\xba\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xabm\x00\x00\x01\x94\x12\xcf\xabm\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSL,4150.0,600,30.0,0.0,0.0,0.0,F...')])])}
21:26:27,310 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xda>3\xba\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xabm\x00\x00\x01\x94\x12\xcf\xabm\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSL,4150.0,600,30.0,0.0,0.0,0.0,F...')])])
21:26:27,310 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xda>3\xba\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xabm\x00\x00\x01\x94\x12\xcf\xabm\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSL,4150.0,600,30.0,0.0,0.0,0.0,F...')])])
21:26:27,310 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:27,310 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 358: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xda>3\xba\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xabm\x00\x00\x01\x94\x12\xcf\xabm\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHSL,4150.0,600,30.0,0.0,0.0,0.0,F...')])])
21:26:27,313 <kafka.protocol.parser>[DEBUG]: Received correlation id: 358
21:26:27,313 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:27,313 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 358 (3.0095577239990234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=356, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:27,313 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=356, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:27,313 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 356 log start offset 0 and error None.
21:26:27,315 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:27,714 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HIG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:27,716 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:28,37 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:28,39 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:28,323 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HIZ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:28,325 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:28,630 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HJS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:28,633 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HJS,32800.0,100,1800.0,0.1,0.0,0.0,False,0.0,13:21:42' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:28,633 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:28,633 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:28,634 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:28,634 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:28,634 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x19E\x98e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb0\x99\x00\x00\x01\x94\x12\xcf\xb0\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHJS,32800.0,100,1800.0,0.1,0.0,0....')])])}
21:26:28,634 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x19E\x98e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb0\x99\x00\x00\x01\x94\x12\xcf\xb0\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHJS,32800.0,100,1800.0,0.1,0.0,0....')])])
21:26:28,634 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x19E\x98e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb0\x99\x00\x00\x01\x94\x12\xcf\xb0\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHJS,32800.0,100,1800.0,0.1,0.0,0....')])])
21:26:28,635 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 359: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x19E\x98e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb0\x99\x00\x00\x01\x94\x12\xcf\xb0\x99\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHJS,32800.0,100,1800.0,0.1,0.0,0....')])])
21:26:28,635 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:28,638 <kafka.protocol.parser>[DEBUG]: Received correlation id: 359
21:26:28,638 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:28,638 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 359 (2.9947757720947266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=357, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:28,638 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=357, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:28,639 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 357 log start offset 0 and error None.
21:26:28,640 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:29,587 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HKB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:29,670 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HKB,600.0,39000,0.0,0.0,0.0,0.0,False,0.0,14:58:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:29,671 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:29,671 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:29,671 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:29,671 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:29,671 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02^\xa9\xb4T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb4\xa7\x00\x00\x01\x94\x12\xcf\xb4\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHKB,600.0,39000,0.0,0.0,0.0,0.0,F...')])])}
21:26:29,672 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02^\xa9\xb4T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb4\xa7\x00\x00\x01\x94\x12\xcf\xb4\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHKB,600.0,39000,0.0,0.0,0.0,0.0,F...')])])
21:26:29,672 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02^\xa9\xb4T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb4\xa7\x00\x00\x01\x94\x12\xcf\xb4\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHKB,600.0,39000,0.0,0.0,0.0,0.0,F...')])])
21:26:29,672 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:29,672 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 360: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02^\xa9\xb4T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xb4\xa7\x00\x00\x01\x94\x12\xcf\xb4\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHKB,600.0,39000,0.0,0.0,0.0,0.0,F...')])])
21:26:29,675 <kafka.protocol.parser>[DEBUG]: Received correlation id: 360
21:26:29,675 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:29,675 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 360 (2.9637813568115234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=358, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:29,675 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=358, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:29,675 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 358 log start offset 0 and error None.
21:26:29,676 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:29,985 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HKP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:29,987 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:31,364 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HKT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:31,447 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HKT,7800.0,200,0.0,0.0,0.0,0.0,False,0.0,13:17:35' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:31,447 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:31,447 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:31,448 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:31,448 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02E\xaa'\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xbb\x97\x00\x00\x01\x94\x12\xcf\xbb\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHKT,7800.0,200,0.0,0.0,0.0,0.0,Fa...")])])}
21:26:31,448 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02E\xaa'\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xbb\x97\x00\x00\x01\x94\x12\xcf\xbb\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHKT,7800.0,200,0.0,0.0,0.0,0.0,Fa...")])])
21:26:31,448 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:31,448 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02E\xaa'\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xbb\x97\x00\x00\x01\x94\x12\xcf\xbb\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHKT,7800.0,200,0.0,0.0,0.0,0.0,Fa...")])])
21:26:31,449 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 361: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02E\xaa'\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xbb\x97\x00\x00\x01\x94\x12\xcf\xbb\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHKT,7800.0,200,0.0,0.0,0.0,0.0,Fa...")])])
21:26:31,449 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:31,451 <kafka.protocol.parser>[DEBUG]: Received correlation id: 361
21:26:31,451 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:31,451 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 361 (2.0084381103515625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=359, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:31,451 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=359, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:31,451 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 359 log start offset 0 and error None.
21:26:31,453 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:31,957 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:31,959 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:32,811 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:32,814 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HLC,12300.0,100,100.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:32,814 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:32,814 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:32,814 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:32,814 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:32,814 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe9F\x1fN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc0\xee\x00\x00\x01\x94\x12\xcf\xc0\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLC,12300.0,100,100.0,0.0,0.0,0.0...')])])}
21:26:32,814 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe9F\x1fN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc0\xee\x00\x00\x01\x94\x12\xcf\xc0\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLC,12300.0,100,100.0,0.0,0.0,0.0...')])])
21:26:32,815 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe9F\x1fN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc0\xee\x00\x00\x01\x94\x12\xcf\xc0\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLC,12300.0,100,100.0,0.0,0.0,0.0...')])])
21:26:32,814 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:32,815 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 362: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe9F\x1fN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc0\xee\x00\x00\x01\x94\x12\xcf\xc0\xee\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLC,12300.0,100,100.0,0.0,0.0,0.0...')])])
21:26:32,818 <kafka.protocol.parser>[DEBUG]: Received correlation id: 362
21:26:32,818 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:32,818 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 362 (2.736806869506836 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=360, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:32,818 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=360, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:32,818 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 360 log start offset 0 and error None.
21:26:32,820 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:33,228 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:34,250 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HLD,16600.0,100,0.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:34,250 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:34,250 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:34,250 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:34,250 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:34,251 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L\xe3\x19\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc6\x8a\x00\x00\x01\x94\x12\xcf\xc6\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLD,16600.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:26:34,251 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L\xe3\x19\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc6\x8a\x00\x00\x01\x94\x12\xcf\xc6\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLD,16600.0,100,0.0,0.0,0.0,0.0,F...')])])
21:26:34,251 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L\xe3\x19\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc6\x8a\x00\x00\x01\x94\x12\xcf\xc6\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLD,16600.0,100,0.0,0.0,0.0,0.0,F...')])])
21:26:34,251 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:34,251 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 363: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L\xe3\x19\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xc6\x8a\x00\x00\x01\x94\x12\xcf\xc6\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHLD,16600.0,100,0.0,0.0,0.0,0.0,F...')])])
21:26:34,254 <kafka.protocol.parser>[DEBUG]: Received correlation id: 363
21:26:34,254 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:34,254 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 363 (3.0012130737304688 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=361, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:34,254 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=361, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:34,254 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 361 log start offset 0 and error None.
21:26:34,255 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:38,86 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:38,177 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:39,607 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:39,610 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:39,937 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:39,940 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:40,254 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HLY/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:40,256 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:40,806 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:40,808 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HMC,11850.0,100,50.0,0.0,0.0,0.0,False,50.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:40,808 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:40,808 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:40,808 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:40,809 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:40,809 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:40,809 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd8\xf8\xfcY\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe0(\x00\x00\x01\x94\x12\xcf\xe0(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMC,11850.0,100,50.0,0.0,0.0,0.0,...')])])}
21:26:40,809 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd8\xf8\xfcY\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe0(\x00\x00\x01\x94\x12\xcf\xe0(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMC,11850.0,100,50.0,0.0,0.0,0.0,...')])])
21:26:40,809 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd8\xf8\xfcY\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe0(\x00\x00\x01\x94\x12\xcf\xe0(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMC,11850.0,100,50.0,0.0,0.0,0.0,...')])])
21:26:40,809 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 364: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd8\xf8\xfcY\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe0(\x00\x00\x01\x94\x12\xcf\xe0(\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMC,11850.0,100,50.0,0.0,0.0,0.0,...')])])
21:26:40,812 <kafka.protocol.parser>[DEBUG]: Received correlation id: 364
21:26:40,812 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:40,812 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 364 (2.9997825622558594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=362, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:40,812 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=362, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:40,812 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 362 log start offset 0 and error None.
21:26:40,813 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:41,101 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HMS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:41,103 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HMS,35500.0,100,300.0,0.0,0.0,0.0,False,0.0,14:20:32' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:41,103 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:41,103 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:41,103 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:41,103 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:41,103 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x19Cw\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe1O\x00\x00\x01\x94\x12\xcf\xe1O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMS,35500.0,100,300.0,0.0,0.0,0.0...')])])}
21:26:41,104 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x19Cw\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe1O\x00\x00\x01\x94\x12\xcf\xe1O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMS,35500.0,100,300.0,0.0,0.0,0.0...')])])
21:26:41,104 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x19Cw\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe1O\x00\x00\x01\x94\x12\xcf\xe1O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMS,35500.0,100,300.0,0.0,0.0,0.0...')])])
21:26:41,104 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 365: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x19Cw\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe1O\x00\x00\x01\x94\x12\xcf\xe1O\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHMS,35500.0,100,300.0,0.0,0.0,0.0...')])])
21:26:41,104 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:41,106 <kafka.protocol.parser>[DEBUG]: Received correlation id: 365
21:26:41,106 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:41,106 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 365 (1.9993782043457031 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=363, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:41,107 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=363, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:41,107 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 363 log start offset 0 and error None.
21:26:41,108 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:41,570 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HMG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:41,572 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:42,918 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HMH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:42,920 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HMH,14000.0,4300,0.0,0.0,0.0,0.0,False,0.0,13:21:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:42,921 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:42,921 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:42,921 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:42,921 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:42,922 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02c$\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe8i\x00\x00\x01\x94\x12\xcf\xe8i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHMH,14000.0,4300,0.0,0.0,0.0,0.0,...')])])}
21:26:42,922 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02c$\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe8i\x00\x00\x01\x94\x12\xcf\xe8i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHMH,14000.0,4300,0.0,0.0,0.0,0.0,...')])])
21:26:42,922 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02c$\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe8i\x00\x00\x01\x94\x12\xcf\xe8i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHMH,14000.0,4300,0.0,0.0,0.0,0.0,...')])])
21:26:42,921 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:42,922 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 366: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02c$\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xe8i\x00\x00\x01\x94\x12\xcf\xe8i\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHMH,14000.0,4300,0.0,0.0,0.0,0.0,...')])])
21:26:42,924 <kafka.protocol.parser>[DEBUG]: Received correlation id: 366
21:26:42,925 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:42,925 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 366 (2.5086402893066406 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=364, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:42,925 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=364, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:42,925 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 364 log start offset 0 and error None.
21:26:42,926 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:45,380 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BKH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:45,383 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:45,774 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DCH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:45,776 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:46,403 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:46,405 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HAF,17500.0,3800,1600.0,0.1,0.0,0.0,False,200.0,14:57:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:46,405 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:46,405 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:46,405 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:46,405 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:46,405 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:46,405 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b\x8c\xf2\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf6\x05\x00\x00\x01\x94\x12\xcf\xf6\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAF,17500.0,3800,1600.0,0.1,0.0,0...')])])}
21:26:46,406 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b\x8c\xf2\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf6\x05\x00\x00\x01\x94\x12\xcf\xf6\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAF,17500.0,3800,1600.0,0.1,0.0,0...')])])
21:26:46,406 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b\x8c\xf2\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf6\x05\x00\x00\x01\x94\x12\xcf\xf6\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAF,17500.0,3800,1600.0,0.1,0.0,0...')])])
21:26:46,406 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 367: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0b\x8c\xf2\x07\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf6\x05\x00\x00\x01\x94\x12\xcf\xf6\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHAF,17500.0,3800,1600.0,0.1,0.0,0...')])])
21:26:46,408 <kafka.protocol.parser>[DEBUG]: Received correlation id: 367
21:26:46,408 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:46,408 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 367 (2.0067691802978516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=365, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:46,409 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=365, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:46,409 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 365 log start offset 0 and error None.
21:26:46,410 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:47,37 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:47,39 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HNG,6100.0,20000,-100.0,0.0,0.0,0.0,False,0.0,14:59:38' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,39 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,39 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:47,39 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:47,39 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:47,39 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02F\xe1\x94\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf8\x7f\x00\x00\x01\x94\x12\xcf\xf8\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHNG,6100.0,20000,-100.0,0.0,0.0,0...')])])}
21:26:47,39 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02F\xe1\x94\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf8\x7f\x00\x00\x01\x94\x12\xcf\xf8\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHNG,6100.0,20000,-100.0,0.0,0.0,0...')])])
21:26:47,40 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02F\xe1\x94\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf8\x7f\x00\x00\x01\x94\x12\xcf\xf8\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHNG,6100.0,20000,-100.0,0.0,0.0,0...')])])
21:26:47,40 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 368: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02F\xe1\x94\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xf8\x7f\x00\x00\x01\x94\x12\xcf\xf8\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHNG,6100.0,20000,-100.0,0.0,0.0,0...')])])
21:26:47,40 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,42 <kafka.protocol.parser>[DEBUG]: Received correlation id: 368
21:26:47,42 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:47,42 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 368 (2.008199691772461 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=366, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:47,43 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=366, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:47,43 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 366 log start offset 0 and error None.
21:26:47,44 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:47,397 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:47,480 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HNA,24300.0,1000,100.0,0.0,0.0,0.0,False,0.0,11:28:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,481 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,481 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:47,481 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:47,482 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:47,482 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x01)\xf9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfa9\x00\x00\x01\x94\x12\xcf\xfa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNA,24300.0,1000,100.0,0.0,0.0,0....')])])}
21:26:47,483 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x01)\xf9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfa9\x00\x00\x01\x94\x12\xcf\xfa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNA,24300.0,1000,100.0,0.0,0.0,0....')])])
21:26:47,483 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x01)\xf9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfa9\x00\x00\x01\x94\x12\xcf\xfa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNA,24300.0,1000,100.0,0.0,0.0,0....')])])
21:26:47,483 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 369: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x01)\xf9\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfa9\x00\x00\x01\x94\x12\xcf\xfa9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNA,24300.0,1000,100.0,0.0,0.0,0....')])])
21:26:47,485 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,489 <kafka.protocol.parser>[DEBUG]: Received correlation id: 369
21:26:47,489 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:47,490 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 369 (5.976676940917969 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=367, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:47,490 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=367, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:47,491 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 367 log start offset 0 and error None.
21:26:47,494 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:47,800 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:47,804 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HNM,9700.0,800,-900.0,-0.1,0.0,0.0,False,-200.0,14:59:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,804 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,804 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:47,805 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:47,805 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:47,805 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x86W>\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfb|\x00\x00\x01\x94\x12\xcf\xfb|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHNM,9700.0,800,-900.0,-0.1,0.0,0....')])])}
21:26:47,806 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x86W>\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfb|\x00\x00\x01\x94\x12\xcf\xfb|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHNM,9700.0,800,-900.0,-0.1,0.0,0....')])])
21:26:47,806 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x86W>\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfb|\x00\x00\x01\x94\x12\xcf\xfb|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHNM,9700.0,800,-900.0,-0.1,0.0,0....')])])
21:26:47,806 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 370: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x86W>\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xcf\xfb|\x00\x00\x01\x94\x12\xcf\xfb|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHNM,9700.0,800,-900.0,-0.1,0.0,0....')])])
21:26:47,807 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:47,811 <kafka.protocol.parser>[DEBUG]: Received correlation id: 370
21:26:47,811 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:47,811 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 370 (3.735780715942383 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=368, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:47,812 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=368, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:47,812 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 368 log start offset 0 and error None.
21:26:47,814 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:48,232 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DHN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:48,234 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:48,836 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HRT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:48,839 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:49,170 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TSJ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:49,172 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'TSJ,37000.0,1600,4700.0,0.1,0.0,0.0,False,0.0,09:00:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:49,172 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:49,172 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:49,172 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:49,173 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:49,173 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:49,173 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xad\x90\xa4\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x00\xd4\x00\x00\x01\x94\x12\xd0\x00\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lTSJ,37000.0,1600,4700.0,0.1,0.0,0...')])])}
21:26:49,173 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xad\x90\xa4\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x00\xd4\x00\x00\x01\x94\x12\xd0\x00\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lTSJ,37000.0,1600,4700.0,0.1,0.0,0...')])])
21:26:49,173 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xad\x90\xa4\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x00\xd4\x00\x00\x01\x94\x12\xd0\x00\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lTSJ,37000.0,1600,4700.0,0.1,0.0,0...')])])
21:26:49,173 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 371: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xad\x90\xa4\xc2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x00\xd4\x00\x00\x01\x94\x12\xd0\x00\xd4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lTSJ,37000.0,1600,4700.0,0.1,0.0,0...')])])
21:26:49,176 <kafka.protocol.parser>[DEBUG]: Received correlation id: 371
21:26:49,176 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:49,176 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 371 (1.691579818725586 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=369, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:49,176 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=369, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:49,177 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 369 log start offset 0 and error None.
21:26:49,178 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:49,482 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HJC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:49,484 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HJC,5800.0,600,0.0,0.0,0.0,0.0,False,0.0,10:31:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:49,485 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:49,485 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:49,485 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:49,486 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:49,486 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xf7\x1c \xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x02\r\x00\x00\x01\x94\x12\xd0\x02\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHJC,5800.0,600,0.0,0.0,0.0,0.0,Fa...')])])}
21:26:49,486 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:49,486 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xf7\x1c \xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x02\r\x00\x00\x01\x94\x12\xd0\x02\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHJC,5800.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:26:49,486 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xf7\x1c \xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x02\r\x00\x00\x01\x94\x12\xd0\x02\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHJC,5800.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:26:49,486 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 372: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xf7\x1c \xb3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x02\r\x00\x00\x01\x94\x12\xd0\x02\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHJC,5800.0,600,0.0,0.0,0.0,0.0,Fa...')])])
21:26:49,489 <kafka.protocol.parser>[DEBUG]: Received correlation id: 372
21:26:49,489 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:49,489 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 372 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=370, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:49,489 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=370, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:49,489 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 370 log start offset 0 and error None.
21:26:49,491 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:51,10 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HOM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:51,12 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HOM,3700.0,500,100.0,0.0,0.0,0.0,False,0.0,13:10:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:51,12 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:51,12 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:51,12 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:51,13 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:51,13 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x08.\xadi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x08\x04\x00\x00\x01\x94\x12\xd0\x08\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHOM,3700.0,500,100.0,0.0,0.0,0.0,...')])])}
21:26:51,13 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x08.\xadi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x08\x04\x00\x00\x01\x94\x12\xd0\x08\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHOM,3700.0,500,100.0,0.0,0.0,0.0,...')])])
21:26:51,13 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x08.\xadi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x08\x04\x00\x00\x01\x94\x12\xd0\x08\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHOM,3700.0,500,100.0,0.0,0.0,0.0,...')])])
21:26:51,13 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 373: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x08.\xadi\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x08\x04\x00\x00\x01\x94\x12\xd0\x08\x04\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHOM,3700.0,500,100.0,0.0,0.0,0.0,...')])])
21:26:51,14 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:51,15 <kafka.protocol.parser>[DEBUG]: Received correlation id: 373
21:26:51,16 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:51,16 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 373 (3.005504608154297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=371, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:51,16 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=371, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:51,16 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 371 log start offset 0 and error None.
21:26:51,17 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:51,678 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HOT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:51,679 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HOT,19200.0,100,2400.0,0.1,0.0,0.0,False,0.0,13:22:33' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:51,679 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:51,679 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:51,680 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:51,680 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:51,680 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:51,680 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8\t\xfb\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\n\x9f\x00\x00\x01\x94\x12\xd0\n\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHOT,19200.0,100,2400.0,0.1,0.0,0....')])])}
21:26:51,680 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8\t\xfb\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\n\x9f\x00\x00\x01\x94\x12\xd0\n\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHOT,19200.0,100,2400.0,0.1,0.0,0....')])])
21:26:51,680 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8\t\xfb\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\n\x9f\x00\x00\x01\x94\x12\xd0\n\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHOT,19200.0,100,2400.0,0.1,0.0,0....')])])
21:26:51,681 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 374: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8\t\xfb\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\n\x9f\x00\x00\x01\x94\x12\xd0\n\x9f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHOT,19200.0,100,2400.0,0.1,0.0,0....')])])
21:26:51,683 <kafka.protocol.parser>[DEBUG]: Received correlation id: 374
21:26:51,683 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:51,683 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 374 (1.987457275390625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=372, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:51,683 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=372, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:51,683 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 372 log start offset 0 and error None.
21:26:51,685 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:53,417 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:53,419 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:53,802 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HAC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:53,806 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:54,119 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CCP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:54,121 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:54,438 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:54,440 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HPD,22000.0,100,0.0,0.0,0.0,0.0,False,0.0,14:10:39' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:54,440 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:54,440 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:54,440 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:54,440 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:54,441 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xb4\x04\xf1\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x15h\x00\x00\x01\x94\x12\xd0\x15h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHPD,22000.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:26:54,441 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:54,441 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xb4\x04\xf1\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x15h\x00\x00\x01\x94\x12\xd0\x15h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHPD,22000.0,100,0.0,0.0,0.0,0.0,F...')])])
21:26:54,441 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xb4\x04\xf1\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x15h\x00\x00\x01\x94\x12\xd0\x15h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHPD,22000.0,100,0.0,0.0,0.0,0.0,F...')])])
21:26:54,442 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 375: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xb4\x04\xf1\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x15h\x00\x00\x01\x94\x12\xd0\x15h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dHPD,22000.0,100,0.0,0.0,0.0,0.0,F...')])])
21:26:54,444 <kafka.protocol.parser>[DEBUG]: Received correlation id: 375
21:26:54,444 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:54,444 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 375 (1.9969940185546875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=373, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:54,445 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=373, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:54,445 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 373 log start offset 0 and error None.
21:26:54,446 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:56,92 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:56,94 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HPG,26850.0,1673200,-150.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:56,94 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:56,94 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:56,95 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:56,95 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:56,95 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:56,95 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02J\xd8\x18\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x1b\xde\x00\x00\x01\x94\x12\xd0\x1b\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHPG,26850.0,1673200,-150.0,0.0,0...')])])}
21:26:56,95 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02J\xd8\x18\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x1b\xde\x00\x00\x01\x94\x12\xd0\x1b\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHPG,26850.0,1673200,-150.0,0.0,0...')])])
21:26:56,95 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02J\xd8\x18\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x1b\xde\x00\x00\x01\x94\x12\xd0\x1b\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHPG,26850.0,1673200,-150.0,0.0,0...')])])
21:26:56,96 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 376: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02J\xd8\x18\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x1b\xde\x00\x00\x01\x94\x12\xd0\x1b\xde\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vHPG,26850.0,1673200,-150.0,0.0,0...')])])
21:26:56,98 <kafka.protocol.parser>[DEBUG]: Received correlation id: 376
21:26:56,98 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:56,98 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 376 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=374, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:56,99 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=374, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:56,99 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 374 log start offset 0 and error None.
21:26:56,100 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:56,438 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:56,440 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:58,931 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:58,933 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:59,253 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:59,255 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HPP,86000.0,1500,2100.0,0.0,0.0,0.0,False,0.0,09:22:44' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:59,255 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:59,255 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:59,256 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:59,256 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:59,256 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f\x98\xff\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0(7\x00\x00\x01\x94\x12\xd0(7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHPP,86000.0,1500,2100.0,0.0,0.0,0...')])])}
21:26:59,256 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f\x98\xff\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0(7\x00\x00\x01\x94\x12\xd0(7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHPP,86000.0,1500,2100.0,0.0,0.0,0...')])])
21:26:59,256 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:59,256 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f\x98\xff\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0(7\x00\x00\x01\x94\x12\xd0(7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHPP,86000.0,1500,2100.0,0.0,0.0,0...')])])
21:26:59,257 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 377: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f\x98\xff\x05\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0(7\x00\x00\x01\x94\x12\xd0(7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHPP,86000.0,1500,2100.0,0.0,0.0,0...')])])
21:26:59,260 <kafka.protocol.parser>[DEBUG]: Received correlation id: 377
21:26:59,260 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:59,260 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 377 (2.520322799682617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=375, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:59,260 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=375, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:59,260 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 375 log start offset 0 and error None.
21:26:59,262 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:59,563 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DPH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:59,566 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:26:59,930 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:26:59,937 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HPT,20000.0,5300,-100.0,0.0,0.0,0.0,False,500.0,14:28:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:26:59,937 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:26:59,937 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:26:59,937 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:26:59,938 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:26:59,938 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:26:59,938 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02fA!7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0*\xe1\x00\x00\x01\x94\x12\xd0*\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHPT,20000.0,5300,-100.0,0.0,0.0,0...')])])}
21:26:59,938 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02fA!7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0*\xe1\x00\x00\x01\x94\x12\xd0*\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHPT,20000.0,5300,-100.0,0.0,0.0,0...')])])
21:26:59,938 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02fA!7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0*\xe1\x00\x00\x01\x94\x12\xd0*\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHPT,20000.0,5300,-100.0,0.0,0.0,0...')])])
21:26:59,939 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 378: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02fA!7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0*\xe1\x00\x00\x01\x94\x12\xd0*\xe1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHPT,20000.0,5300,-100.0,0.0,0.0,0...')])])
21:26:59,950 <kafka.protocol.parser>[DEBUG]: Received correlation id: 378
21:26:59,950 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:26:59,950 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 378 (10.977983474731445 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=376, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:59,950 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=376, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:26:59,950 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 376 log start offset 0 and error None.
21:26:59,953 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:00,396 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TUG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:00,398 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:00,835 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HPW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:00,838 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:02,569 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HQC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:02,572 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HQC,3270.0,158400,-30.0,0.0,0.0,0.0,True,30.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:02,572 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:02,572 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:02,572 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:02,572 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:02,572 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbd=\x0e\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd05,\x00\x00\x01\x94\x12\xd05,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHQC,3270.0,158400,-30.0,0.0,0.0,0...')])])}
21:27:02,572 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbd=\x0e\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd05,\x00\x00\x01\x94\x12\xd05,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHQC,3270.0,158400,-30.0,0.0,0.0,0...')])])
21:27:02,572 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbd=\x0e\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd05,\x00\x00\x01\x94\x12\xd05,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHQC,3270.0,158400,-30.0,0.0,0.0,0...')])])
21:27:02,572 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:02,572 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 379: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbd=\x0e\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd05,\x00\x00\x01\x94\x12\xd05,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHQC,3270.0,158400,-30.0,0.0,0.0,0...')])])
21:27:02,575 <kafka.protocol.parser>[DEBUG]: Received correlation id: 379
21:27:02,575 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:02,575 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 379 (2.9985904693603516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=377, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:02,575 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=377, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:02,576 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 377 log start offset 0 and error None.
21:27:02,578 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:03,554 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HRB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:03,557 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:04,580 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HRC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:04,583 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HRC,41400.0,100,2500.0,0.1,0.0,0.0,False,-100.0,09:47:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:04,583 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:04,583 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:04,583 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:04,584 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:04,584 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:04,584 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf3f\xb0\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0=\x07\x00\x00\x01\x94\x12\xd0=\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHRC,41400.0,100,2500.0,0.1,0.0,0....')])])}
21:27:04,584 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf3f\xb0\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0=\x07\x00\x00\x01\x94\x12\xd0=\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHRC,41400.0,100,2500.0,0.1,0.0,0....')])])
21:27:04,584 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf3f\xb0\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0=\x07\x00\x00\x01\x94\x12\xd0=\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHRC,41400.0,100,2500.0,0.1,0.0,0....')])])
21:27:04,585 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 380: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf3f\xb0\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0=\x07\x00\x00\x01\x94\x12\xd0=\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHRC,41400.0,100,2500.0,0.1,0.0,0....')])])
21:27:04,588 <kafka.protocol.parser>[DEBUG]: Received correlation id: 380
21:27:04,588 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:04,588 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 380 (2.9723644256591797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=378, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:04,589 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=378, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:04,589 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 378 log start offset 0 and error None.
21:27:04,590 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:05,511 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HSA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:05,513 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:06,64 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HSG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:06,66 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HSG,18800.0,557800,-150.0,0.0,0.0,0.0,True,-50.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:06,66 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:06,66 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:06,67 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:06,67 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:06,67 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:06,67 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd2\xd4\xa2\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0B\xd2\x00\x00\x01\x94\x12\xd0B\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHSG,18800.0,557800,-150.0,0.0,0.0...')])])}
21:27:06,67 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd2\xd4\xa2\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0B\xd2\x00\x00\x01\x94\x12\xd0B\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHSG,18800.0,557800,-150.0,0.0,0.0...')])])
21:27:06,68 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd2\xd4\xa2\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0B\xd2\x00\x00\x01\x94\x12\xd0B\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHSG,18800.0,557800,-150.0,0.0,0.0...')])])
21:27:06,68 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 381: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xd2\xd4\xa2\xa9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0B\xd2\x00\x00\x01\x94\x12\xd0B\xd2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHSG,18800.0,557800,-150.0,0.0,0.0...')])])
21:27:06,71 <kafka.protocol.parser>[DEBUG]: Received correlation id: 381
21:27:06,71 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:06,71 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 381 (2.9952526092529297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=379, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:06,71 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=379, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:06,71 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 379 log start offset 0 and error None.
21:27:06,73 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:06,376 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HSI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:06,378 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:06,677 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HSP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:06,678 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HSP,11500.0,1000,0.0,0.0,0.0,0.0,False,0.0,13:53:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:06,679 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:06,679 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:06,679 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:06,679 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:06,679 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029\xca\x1c\xf8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0E7\x00\x00\x01\x94\x12\xd0E7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHSP,11500.0,1000,0.0,0.0,0.0,0.0,...')])])}
21:27:06,679 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029\xca\x1c\xf8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0E7\x00\x00\x01\x94\x12\xd0E7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHSP,11500.0,1000,0.0,0.0,0.0,0.0,...')])])
21:27:06,680 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029\xca\x1c\xf8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0E7\x00\x00\x01\x94\x12\xd0E7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHSP,11500.0,1000,0.0,0.0,0.0,0.0,...')])])
21:27:06,679 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:06,680 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 382: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x029\xca\x1c\xf8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0E7\x00\x00\x01\x94\x12\xd0E7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHSP,11500.0,1000,0.0,0.0,0.0,0.0,...')])])
21:27:06,682 <kafka.protocol.parser>[DEBUG]: Received correlation id: 382
21:27:06,683 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:06,683 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 382 (3.020048141479492 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=380, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:06,683 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=380, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:06,683 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 380 log start offset 0 and error None.
21:27:06,684 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:07,711 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HT1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:07,713 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HT1,11700.0,35600,-200.0,0.0,0.0,0.0,True,-50.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:07,713 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:07,714 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:07,714 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:07,714 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:07,714 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:07,714 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9\xf6\xf5\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0IA\x00\x00\x01\x94\x12\xd0IA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHT1,11700.0,35600,-200.0,0.0,0.0,...')])])}
21:27:07,714 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9\xf6\xf5\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0IA\x00\x00\x01\x94\x12\xd0IA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHT1,11700.0,35600,-200.0,0.0,0.0,...')])])
21:27:07,715 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9\xf6\xf5\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0IA\x00\x00\x01\x94\x12\xd0IA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHT1,11700.0,35600,-200.0,0.0,0.0,...')])])
21:27:07,715 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 383: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9\xf6\xf5\n\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0IA\x00\x00\x01\x94\x12\xd0IA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHT1,11700.0,35600,-200.0,0.0,0.0,...')])])
21:27:07,717 <kafka.protocol.parser>[DEBUG]: Received correlation id: 383
21:27:07,717 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:07,717 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 383 (1.9998550415039062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=381, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:07,717 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=381, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:07,717 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 381 log start offset 0 and error None.
21:27:07,719 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:08,212 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:08,612 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:09,126 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:09,129 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTG,48050.0,100,-50.0,0.0,0.0,0.0,False,0.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:09,129 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:09,129 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:09,129 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:09,129 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:09,130 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:09,130 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xac\xe7s\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0N\xc9\x00\x00\x01\x94\x12\xd0N\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTG,48050.0,100,-50.0,0.0,0.0,0.0...')])])}
21:27:09,130 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xac\xe7s\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0N\xc9\x00\x00\x01\x94\x12\xd0N\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTG,48050.0,100,-50.0,0.0,0.0,0.0...')])])
21:27:09,130 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xac\xe7s\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0N\xc9\x00\x00\x01\x94\x12\xd0N\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTG,48050.0,100,-50.0,0.0,0.0,0.0...')])])
21:27:09,130 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 384: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xac\xe7s\xd0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0N\xc9\x00\x00\x01\x94\x12\xd0N\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTG,48050.0,100,-50.0,0.0,0.0,0.0...')])])
21:27:09,132 <kafka.protocol.parser>[DEBUG]: Received correlation id: 384
21:27:09,133 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:09,133 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 384 (3.0007362365722656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=382, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:09,133 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=382, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:09,133 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 382 log start offset 0 and error None.
21:27:09,134 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:10,406 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:10,409 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTI,16400.0,200,100.0,0.0,0.0,0.0,False,0.0,14:29:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:10,410 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:10,410 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:10,410 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:10,411 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:10,411 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02B;\x06J\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0S\xca\x00\x00\x01\x94\x12\xd0S\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTI,16400.0,200,100.0,0.0,0.0,0.0...')])])}
21:27:10,412 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:10,412 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02B;\x06J\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0S\xca\x00\x00\x01\x94\x12\xd0S\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTI,16400.0,200,100.0,0.0,0.0,0.0...')])])
21:27:10,412 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02B;\x06J\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0S\xca\x00\x00\x01\x94\x12\xd0S\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTI,16400.0,200,100.0,0.0,0.0,0.0...')])])
21:27:10,413 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 385: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02B;\x06J\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0S\xca\x00\x00\x01\x94\x12\xd0S\xca\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTI,16400.0,200,100.0,0.0,0.0,0.0...')])])
21:27:10,415 <kafka.protocol.parser>[DEBUG]: Received correlation id: 385
21:27:10,415 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:10,415 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 385 (2.708911895751953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=383, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:10,416 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=383, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:10,416 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 383 log start offset 0 and error None.
21:27:10,417 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:10,724 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:10,726 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTN,9920.0,56800,-180.0,0.0,0.0,0.0,True,-80.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:10,726 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:10,727 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:10,727 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:10,727 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:10,727 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:10,727 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\xae\xa2\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0U\x07\x00\x00\x01\x94\x12\xd0U\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTN,9920.0,56800,-180.0,0.0,0.0,0...')])])}
21:27:10,728 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\xae\xa2\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0U\x07\x00\x00\x01\x94\x12\xd0U\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTN,9920.0,56800,-180.0,0.0,0.0,0...')])])
21:27:10,728 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\xae\xa2\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0U\x07\x00\x00\x01\x94\x12\xd0U\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTN,9920.0,56800,-180.0,0.0,0.0,0...')])])
21:27:10,728 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 386: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x9e\xae\xa2\xaa\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0U\x07\x00\x00\x01\x94\x12\xd0U\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTN,9920.0,56800,-180.0,0.0,0.0,0...')])])
21:27:10,731 <kafka.protocol.parser>[DEBUG]: Received correlation id: 386
21:27:10,731 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:10,731 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 386 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=384, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:10,732 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=384, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:10,732 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 384 log start offset 0 and error None.
21:27:10,733 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:11,69 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:11,71 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTL,28600.0,100,-150.0,0.0,0.0,0.0,False,0.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:11,71 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:11,72 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:11,72 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:11,72 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:11,72 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x05iW\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0V`\x00\x00\x01\x94\x12\xd0V`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHTL,28600.0,100,-150.0,0.0,0.0,0....')])])}
21:27:11,72 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x05iW\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0V`\x00\x00\x01\x94\x12\xd0V`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHTL,28600.0,100,-150.0,0.0,0.0,0....')])])
21:27:11,72 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:11,72 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x05iW\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0V`\x00\x00\x01\x94\x12\xd0V`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHTL,28600.0,100,-150.0,0.0,0.0,0....')])])
21:27:11,73 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 387: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x05iW\xe2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0V`\x00\x00\x01\x94\x12\xd0V`\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHTL,28600.0,100,-150.0,0.0,0.0,0....')])])
21:27:11,75 <kafka.protocol.parser>[DEBUG]: Received correlation id: 387
21:27:11,75 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:11,76 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 387 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=385, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:11,76 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=385, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:11,76 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 385 log start offset 0 and error None.
21:27:11,77 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:11,488 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:11,490 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTP,3200.0,140000,300.0,0.1,0.0,0.0,True,200.0,14:59:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:11,490 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:11,490 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:11,491 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:11,491 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:11,492 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r\x89\xceA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0X\x02\x00\x00\x01\x94\x12\xd0X\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTP,3200.0,140000,300.0,0.1,0.0,0...')])])}
21:27:11,491 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:11,492 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r\x89\xceA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0X\x02\x00\x00\x01\x94\x12\xd0X\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTP,3200.0,140000,300.0,0.1,0.0,0...')])])
21:27:11,492 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r\x89\xceA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0X\x02\x00\x00\x01\x94\x12\xd0X\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTP,3200.0,140000,300.0,0.1,0.0,0...')])])
21:27:11,492 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 388: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02r\x89\xceA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0X\x02\x00\x00\x01\x94\x12\xd0X\x02\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHTP,3200.0,140000,300.0,0.1,0.0,0...')])])
21:27:11,494 <kafka.protocol.parser>[DEBUG]: Received correlation id: 388
21:27:11,495 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:11,495 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 388 (3.0968189239501953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=386, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:11,495 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=386, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:11,495 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 386 log start offset 0 and error None.
21:27:11,497 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:12,225 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:12,227 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:15,84 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:15,89 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTT,1700.0,1100,0.0,0.0,0.0,0.0,False,200.0,14:28:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:15,90 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:15,90 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:15,90 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:15,91 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:15,92 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L"\x80\x19\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0f\x12\x00\x00\x01\x94\x12\xd0f\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTT,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])}
21:27:15,92 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L"\x80\x19\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0f\x12\x00\x00\x01\x94\x12\xd0f\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTT,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:27:15,93 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L"\x80\x19\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0f\x12\x00\x00\x01\x94\x12\xd0f\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTT,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:27:15,93 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 389: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02L"\x80\x19\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0f\x12\x00\x00\x01\x94\x12\xd0f\x12\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTT,1700.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:27:15,94 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:15,99 <kafka.protocol.parser>[DEBUG]: Received correlation id: 389
21:27:15,99 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:15,100 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 389 (6.9904327392578125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=387, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:15,100 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=387, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:15,101 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 387 log start offset 0 and error None.
21:27:15,105 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:15,852 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HTV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:15,854 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HTV,9300.0,100,-190.0,0.0,0.0,0.0,False,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:15,854 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:15,854 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:15,855 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:15,855 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:15,855 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02g\x88\x94w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0i\x0e\x00\x00\x01\x94\x12\xd0i\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTV,9300.0,100,-190.0,0.0,0.0,0.0...')])])}
21:27:15,855 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02g\x88\x94w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0i\x0e\x00\x00\x01\x94\x12\xd0i\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTV,9300.0,100,-190.0,0.0,0.0,0.0...')])])
21:27:15,855 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02g\x88\x94w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0i\x0e\x00\x00\x01\x94\x12\xd0i\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTV,9300.0,100,-190.0,0.0,0.0,0.0...')])])
21:27:15,855 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:15,856 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 390: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02g\x88\x94w\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0i\x0e\x00\x00\x01\x94\x12\xd0i\x0e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHTV,9300.0,100,-190.0,0.0,0.0,0.0...')])])
21:27:15,858 <kafka.protocol.parser>[DEBUG]: Received correlation id: 390
21:27:15,858 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:15,859 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 390 (3.008604049682617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=388, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:15,859 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=388, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:15,859 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 388 log start offset 0 and error None.
21:27:15,860 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:16,176 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HU1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:16,903 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HU1,6100.0,100,100.0,0.0,0.0,0.0,False,0.0,10:38:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:16,903 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:16,903 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:16,903 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:16,904 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:16,904 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xea\x1d)g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0m'\x00\x00\x01\x94\x12\xd0m'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHU1,6100.0,100,100.0,0.0,0.0,0.0,...")])])}
21:27:16,904 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xea\x1d)g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0m'\x00\x00\x01\x94\x12\xd0m'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHU1,6100.0,100,100.0,0.0,0.0,0.0,...")])])
21:27:16,904 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xea\x1d)g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0m'\x00\x00\x01\x94\x12\xd0m'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHU1,6100.0,100,100.0,0.0,0.0,0.0,...")])])
21:27:16,904 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:16,904 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 391: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xea\x1d)g\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0m'\x00\x00\x01\x94\x12\xd0m'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fHU1,6100.0,100,100.0,0.0,0.0,0.0,...")])])
21:27:16,907 <kafka.protocol.parser>[DEBUG]: Received correlation id: 391
21:27:16,907 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:16,907 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 391 (2.0017623901367188 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=389, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:16,907 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=389, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:16,907 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 389 log start offset 0 and error None.
21:27:16,909 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:17,229 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HU3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:17,230 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HU3,3600.0,1800,100.0,0.0,0.0,0.0,False,0.0,14:59:56' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:17,231 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:17,231 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:17,231 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:17,231 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:17,232 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\t\x919\x10\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0no\x00\x00\x01\x94\x12\xd0no\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHU3,3600.0,1800,100.0,0.0,0.0,0.0...')])])}
21:27:17,232 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\t\x919\x10\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0no\x00\x00\x01\x94\x12\xd0no\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHU3,3600.0,1800,100.0,0.0,0.0,0.0...')])])
21:27:17,232 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\t\x919\x10\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0no\x00\x00\x01\x94\x12\xd0no\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHU3,3600.0,1800,100.0,0.0,0.0,0.0...')])])
21:27:17,232 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 392: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\t\x919\x10\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0no\x00\x00\x01\x94\x12\xd0no\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHU3,3600.0,1800,100.0,0.0,0.0,0.0...')])])
21:27:17,232 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:17,235 <kafka.protocol.parser>[DEBUG]: Received correlation id: 392
21:27:17,235 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:17,235 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 392 (2.998828887939453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=390, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:17,236 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=390, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:17,236 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 390 log start offset 0 and error None.
21:27:17,237 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:18,533 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HU4/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:18,536 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HU4,13600.0,100,400.0,0.0,0.0,0.0,False,100.0,14:59:17' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:18,536 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:18,536 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:18,536 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:18,536 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:18,536 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:18,537 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xba\xfa\xdcR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0s\x88\x00\x00\x01\x94\x12\xd0s\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHU4,13600.0,100,400.0,0.0,0.0,0.0...')])])}
21:27:18,537 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xba\xfa\xdcR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0s\x88\x00\x00\x01\x94\x12\xd0s\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHU4,13600.0,100,400.0,0.0,0.0,0.0...')])])
21:27:18,537 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xba\xfa\xdcR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0s\x88\x00\x00\x01\x94\x12\xd0s\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHU4,13600.0,100,400.0,0.0,0.0,0.0...')])])
21:27:18,537 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 393: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xba\xfa\xdcR\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0s\x88\x00\x00\x01\x94\x12\xd0s\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHU4,13600.0,100,400.0,0.0,0.0,0.0...')])])
21:27:18,540 <kafka.protocol.parser>[DEBUG]: Received correlation id: 393
21:27:18,540 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:18,540 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 393 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=391, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:18,540 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=391, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:18,540 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 391 log start offset 0 and error None.
21:27:18,541 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:21,232 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HD2/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:21,327 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HD2,18900.0,100,1700.0,0.1,0.0,0.0,False,2000.0,09:53:28' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:21,328 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:21,328 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:21,328 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:21,329 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:21,330 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf6\xc1\xee\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0~p\x00\x00\x01\x94\x12\xd0~p\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHD2,18900.0,100,1700.0,0.1,0.0,0....')])])}
21:27:21,330 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf6\xc1\xee\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0~p\x00\x00\x01\x94\x12\xd0~p\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHD2,18900.0,100,1700.0,0.1,0.0,0....')])])
21:27:21,330 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf6\xc1\xee\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0~p\x00\x00\x01\x94\x12\xd0~p\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHD2,18900.0,100,1700.0,0.1,0.0,0....')])])
21:27:21,331 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 394: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf6\xc1\xee\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0~p\x00\x00\x01\x94\x12\xd0~p\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHD2,18900.0,100,1700.0,0.1,0.0,0....')])])
21:27:21,331 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:21,336 <kafka.protocol.parser>[DEBUG]: Received correlation id: 394
21:27:21,336 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:21,336 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 394 (4.64320182800293 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=392, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:21,336 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=392, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:21,337 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 392 log start offset 0 and error None.
21:27:21,339 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:25,449 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HU6/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:25,580 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HU6,5500.0,700,0.0,0.0,0.0,0.0,False,0.0,13:41:36' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:25,580 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:25,580 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:25,580 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:25,580 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:25,580 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02A\xc9\xb9\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x8f\x0c\x00\x00\x01\x94\x12\xd0\x8f\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHU6,5500.0,700,0.0,0.0,0.0,0.0,Fa...')])])}
21:27:25,580 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:25,580 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02A\xc9\xb9\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x8f\x0c\x00\x00\x01\x94\x12\xd0\x8f\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHU6,5500.0,700,0.0,0.0,0.0,0.0,Fa...')])])
21:27:25,581 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02A\xc9\xb9\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x8f\x0c\x00\x00\x01\x94\x12\xd0\x8f\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHU6,5500.0,700,0.0,0.0,0.0,0.0,Fa...')])])
21:27:25,581 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 395: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02A\xc9\xb9\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x8f\x0c\x00\x00\x01\x94\x12\xd0\x8f\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bHU6,5500.0,700,0.0,0.0,0.0,0.0,Fa...')])])
21:27:25,583 <kafka.protocol.parser>[DEBUG]: Received correlation id: 395
21:27:25,583 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:25,583 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 395 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=393, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:25,584 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=393, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:25,584 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 393 log start offset 0 and error None.
21:27:25,585 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:26,67 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HD8/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:26,69 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HD8,8200.0,500,-100.0,0.0,0.0,0.0,False,0.0,14:37:48' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:26,69 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:26,69 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:26,70 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:26,70 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:26,70 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:26,70 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x17\x90\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x90\xf5\x00\x00\x01\x94\x12\xd0\x90\xf5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD8,8200.0,500,-100.0,0.0,0.0,0.0...')])])}
21:27:26,70 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x17\x90\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x90\xf5\x00\x00\x01\x94\x12\xd0\x90\xf5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD8,8200.0,500,-100.0,0.0,0.0,0.0...')])])
21:27:26,70 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x17\x90\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x90\xf5\x00\x00\x01\x94\x12\xd0\x90\xf5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD8,8200.0,500,-100.0,0.0,0.0,0.0...')])])
21:27:26,70 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 396: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x17\x90\r\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x90\xf5\x00\x00\x01\x94\x12\xd0\x90\xf5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hHD8,8200.0,500,-100.0,0.0,0.0,0.0...')])])
21:27:26,73 <kafka.protocol.parser>[DEBUG]: Received correlation id: 396
21:27:26,73 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:26,73 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 396 (2.0072460174560547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=394, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:26,73 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=394, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:26,73 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 394 log start offset 0 and error None.
21:27:26,74 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:26,529 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HWS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:26,531 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:26,854 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:26,856 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HNI,25400.0,100,1500.0,0.1,0.0,0.0,False,0.0,09:09:21' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:26,856 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:26,856 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:26,856 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:26,857 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:26,857 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb\xd0\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x94\x08\x00\x00\x01\x94\x12\xd0\x94\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNI,25400.0,100,1500.0,0.1,0.0,0....')])])}
21:27:26,857 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb\xd0\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x94\x08\x00\x00\x01\x94\x12\xd0\x94\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNI,25400.0,100,1500.0,0.1,0.0,0....')])])
21:27:26,857 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb\xd0\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x94\x08\x00\x00\x01\x94\x12\xd0\x94\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNI,25400.0,100,1500.0,0.1,0.0,0....')])])
21:27:26,857 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 397: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfb\xd0\xc7\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x94\x08\x00\x00\x01\x94\x12\xd0\x94\x08\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHNI,25400.0,100,1500.0,0.1,0.0,0....')])])
21:27:26,857 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:26,860 <kafka.protocol.parser>[DEBUG]: Received correlation id: 397
21:27:26,860 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:26,860 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 397 (2.017498016357422 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=395, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:26,860 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=395, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:26,860 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 395 log start offset 0 and error None.
21:27:26,861 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:27,191 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HUG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:27,194 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:28,730 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HUT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:28,730 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HUT,16000.0,128000,-100.0,0.0,0.0,0.0,True,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:28,730 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:28,730 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:28,730 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:28,730 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:28,730 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:28,730 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x089\xe6\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x9bZ\x00\x00\x01\x94\x12\xd0\x9bZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHUT,16000.0,128000,-100.0,0.0,0.0...')])])}
21:27:28,730 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x089\xe6\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x9bZ\x00\x00\x01\x94\x12\xd0\x9bZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHUT,16000.0,128000,-100.0,0.0,0.0...')])])
21:27:28,730 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x089\xe6\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x9bZ\x00\x00\x01\x94\x12\xd0\x9bZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHUT,16000.0,128000,-100.0,0.0,0.0...')])])
21:27:28,730 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 398: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x089\xe6\x8a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\x9bZ\x00\x00\x01\x94\x12\xd0\x9bZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nHUT,16000.0,128000,-100.0,0.0,0.0...')])])
21:27:28,749 <kafka.protocol.parser>[DEBUG]: Received correlation id: 398
21:27:28,749 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:28,749 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 398 (18.71180534362793 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=396, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:28,749 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=396, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:28,749 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 396 log start offset 0 and error None.
21:27:28,751 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:30,136 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HNF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:30,139 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:30,509 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HVA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:30,524 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HVA,6400.0,200,100.0,0.0,0.0,0.0,False,-100.0,14:37:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:30,524 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:30,525 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:30,525 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:30,525 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:30,525 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02j\xe50\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa2\\\x00\x00\x01\x94\x12\xd0\xa2\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHVA,6400.0,200,100.0,0.0,0.0,0.0,...')])])}
21:27:30,525 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:30,525 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02j\xe50\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa2\\\x00\x00\x01\x94\x12\xd0\xa2\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHVA,6400.0,200,100.0,0.0,0.0,0.0,...')])])
21:27:30,526 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02j\xe50\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa2\\\x00\x00\x01\x94\x12\xd0\xa2\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHVA,6400.0,200,100.0,0.0,0.0,0.0,...')])])
21:27:30,526 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 399: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02j\xe50\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa2\\\x00\x00\x01\x94\x12\xd0\xa2\\\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lHVA,6400.0,200,100.0,0.0,0.0,0.0,...')])])
21:27:30,535 <kafka.protocol.parser>[DEBUG]: Received correlation id: 399
21:27:30,535 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:30,535 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 399 (9.541749954223633 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=397, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:30,535 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=397, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:30,536 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 397 log start offset 0 and error None.
21:27:30,537 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:30,855 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HVH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:30,863 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HVH,9360.0,35600,-540.0,-0.1,0.0,0.0,True,-40.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:30,864 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:30,864 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:30,865 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:30,866 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:30,867 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xdd\xa8\xe1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa3\xb0\x00\x00\x01\x94\x12\xd0\xa3\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVH,9360.0,35600,-540.0,-0.1,0.0,...')])])}
21:27:30,867 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xdd\xa8\xe1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa3\xb0\x00\x00\x01\x94\x12\xd0\xa3\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVH,9360.0,35600,-540.0,-0.1,0.0,...')])])
21:27:30,868 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:30,869 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xdd\xa8\xe1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa3\xb0\x00\x00\x01\x94\x12\xd0\xa3\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVH,9360.0,35600,-540.0,-0.1,0.0,...')])])
21:27:30,870 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 400: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xdd\xa8\xe1c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa3\xb0\x00\x00\x01\x94\x12\xd0\xa3\xb0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVH,9360.0,35600,-540.0,-0.1,0.0,...')])])
21:27:30,877 <kafka.protocol.parser>[DEBUG]: Received correlation id: 400
21:27:30,878 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:30,879 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 400 (8.855581283569336 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=398, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:30,880 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=398, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:30,880 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 398 log start offset 0 and error None.
21:27:30,886 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:31,216 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HVG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:31,219 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:31,545 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HVT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:31,547 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HVT,114000.0,1100,100.0,0.0,0.0,0.0,False,-900.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:31,547 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:31,547 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:31,547 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:31,548 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:31,548 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1aV\x85@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa6[\x00\x00\x01\x94\x12\xd0\xa6[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHVT,114000.0,1100,100.0,0.0,0.0,0...')])])}
21:27:31,548 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1aV\x85@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa6[\x00\x00\x01\x94\x12\xd0\xa6[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHVT,114000.0,1100,100.0,0.0,0.0,0...')])])
21:27:31,548 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1aV\x85@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa6[\x00\x00\x01\x94\x12\xd0\xa6[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHVT,114000.0,1100,100.0,0.0,0.0,0...')])])
21:27:31,548 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:31,548 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 401: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1aV\x85@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xa6[\x00\x00\x01\x94\x12\xd0\xa6[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rHVT,114000.0,1100,100.0,0.0,0.0,0...')])])
21:27:31,551 <kafka.protocol.parser>[DEBUG]: Received correlation id: 401
21:27:31,551 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:31,551 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 401 (2.008199691772461 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=399, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:31,552 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=399, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:31,552 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 399 log start offset 0 and error None.
21:27:31,554 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:32,869 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HVX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:32,871 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HVX,2700.0,10500,-120.0,0.0,0.0,0.0,False,-10.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:32,871 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:32,871 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:32,871 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:32,871 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:32,871 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02J\xf4d:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xab\x87\x00\x00\x01\x94\x12\xd0\xab\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVX,2700.0,10500,-120.0,0.0,0.0,0...')])])}
21:27:32,872 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02J\xf4d:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xab\x87\x00\x00\x01\x94\x12\xd0\xab\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVX,2700.0,10500,-120.0,0.0,0.0,0...')])])
21:27:32,872 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02J\xf4d:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xab\x87\x00\x00\x01\x94\x12\xd0\xab\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVX,2700.0,10500,-120.0,0.0,0.0,0...')])])
21:27:32,872 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:32,872 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 402: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02J\xf4d:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xab\x87\x00\x00\x01\x94\x12\xd0\xab\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pHVX,2700.0,10500,-120.0,0.0,0.0,0...')])])
21:27:32,875 <kafka.protocol.parser>[DEBUG]: Received correlation id: 402
21:27:32,875 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:32,876 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 402 (2.999544143676758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=400, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:32,876 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=400, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:32,876 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 400 log start offset 0 and error None.
21:27:32,877 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:34,157 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L40/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:34,159 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:35,461 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:35,463 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:36,122 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ICC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:36,124 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ICC,26000.0,100,-1300.0,0.0,0.0,0.0,False,0.0,14:59:40' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:36,124 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:36,124 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:36,124 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:36,125 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:36,125 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02nX\xd9\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xb8<\x00\x00\x01\x94\x12\xd0\xb8<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lICC,26000.0,100,-1300.0,0.0,0.0,0...')])])}
21:27:36,125 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02nX\xd9\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xb8<\x00\x00\x01\x94\x12\xd0\xb8<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lICC,26000.0,100,-1300.0,0.0,0.0,0...')])])
21:27:36,125 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02nX\xd9\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xb8<\x00\x00\x01\x94\x12\xd0\xb8<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lICC,26000.0,100,-1300.0,0.0,0.0,0...')])])
21:27:36,125 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:36,125 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 403: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02nX\xd9\xd4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xb8<\x00\x00\x01\x94\x12\xd0\xb8<\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lICC,26000.0,100,-1300.0,0.0,0.0,0...')])])
21:27:36,128 <kafka.protocol.parser>[DEBUG]: Received correlation id: 403
21:27:36,128 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:36,128 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 403 (2.0117759704589844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=401, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:36,128 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=401, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:36,128 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 401 log start offset 0 and error None.
21:27:36,130 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:37,228 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ILB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:37,230 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ILB,33500.0,200,0.0,0.0,0.0,0.0,False,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:37,230 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:37,230 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:37,230 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:37,231 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:37,231 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xac\x11.h\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xbc\x8e\x00\x00\x01\x94\x12\xd0\xbc\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dILB,33500.0,200,0.0,0.0,0.0,0.0,F...')])])}
21:27:37,231 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xac\x11.h\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xbc\x8e\x00\x00\x01\x94\x12\xd0\xbc\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dILB,33500.0,200,0.0,0.0,0.0,0.0,F...')])])
21:27:37,231 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xac\x11.h\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xbc\x8e\x00\x00\x01\x94\x12\xd0\xbc\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dILB,33500.0,200,0.0,0.0,0.0,0.0,F...')])])
21:27:37,231 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:37,231 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 404: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xac\x11.h\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xbc\x8e\x00\x00\x01\x94\x12\xd0\xbc\x8e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dILB,33500.0,200,0.0,0.0,0.0,0.0,F...')])])
21:27:37,234 <kafka.protocol.parser>[DEBUG]: Received correlation id: 404
21:27:37,234 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:37,234 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 404 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=402, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:37,235 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=402, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:37,236 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 402 log start offset 0 and error None.
21:27:37,238 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:37,949 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ICF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:38,668 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ICF,3500.0,2000,0.0,0.0,0.0,0.0,False,0.0,13:21:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:38,668 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:38,669 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:38,669 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:38,669 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:38,669 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa0\xd5\xf75\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc2,\x00\x00\x01\x94\x12\xd0\xc2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICF,3500.0,2000,0.0,0.0,0.0,0.0,F...')])])}
21:27:38,670 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:38,670 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa0\xd5\xf75\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc2,\x00\x00\x01\x94\x12\xd0\xc2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICF,3500.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:27:38,670 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa0\xd5\xf75\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc2,\x00\x00\x01\x94\x12\xd0\xc2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICF,3500.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:27:38,670 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 405: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa0\xd5\xf75\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc2,\x00\x00\x01\x94\x12\xd0\xc2,\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICF,3500.0,2000,0.0,0.0,0.0,0.0,F...')])])
21:27:38,673 <kafka.protocol.parser>[DEBUG]: Received correlation id: 405
21:27:38,673 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:38,673 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 405 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=403, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:38,673 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=403, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:38,673 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 403 log start offset 0 and error None.
21:27:38,675 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:39,745 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ICG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:39,845 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ICG,7400.0,300,-400.0,-0.1,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:39,845 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:39,845 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:39,845 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:39,846 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:39,846 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02_u\xc8p\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc6\xc5\x00\x00\x01\x94\x12\xd0\xc6\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nICG,7400.0,300,-400.0,-0.1,0.0,0....')])])}
21:27:39,846 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02_u\xc8p\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc6\xc5\x00\x00\x01\x94\x12\xd0\xc6\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nICG,7400.0,300,-400.0,-0.1,0.0,0....')])])
21:27:39,846 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02_u\xc8p\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc6\xc5\x00\x00\x01\x94\x12\xd0\xc6\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nICG,7400.0,300,-400.0,-0.1,0.0,0....')])])
21:27:39,846 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 406: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02_u\xc8p\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc6\xc5\x00\x00\x01\x94\x12\xd0\xc6\xc5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nICG,7400.0,300,-400.0,-0.1,0.0,0....')])])
21:27:39,846 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:39,848 <kafka.protocol.parser>[DEBUG]: Received correlation id: 406
21:27:39,848 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:39,849 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 406 (2.038240432739258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=404, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:39,849 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=404, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:39,849 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 404 log start offset 0 and error None.
21:27:39,850 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:40,175 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ICI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:40,177 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ICI,7000.0,3000,0.0,0.0,0.0,0.0,False,0.0,14:59:20' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:40,177 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:40,177 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:40,177 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:40,177 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:40,178 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:40,178 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02%\x08\xefK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc8\x11\x00\x00\x01\x94\x12\xd0\xc8\x11\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICI,7000.0,3000,0.0,0.0,0.0,0.0,F...')])])}
21:27:40,178 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02%\x08\xefK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc8\x11\x00\x00\x01\x94\x12\xd0\xc8\x11\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICI,7000.0,3000,0.0,0.0,0.0,0.0,F...')])])
21:27:40,178 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02%\x08\xefK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc8\x11\x00\x00\x01\x94\x12\xd0\xc8\x11\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICI,7000.0,3000,0.0,0.0,0.0,0.0,F...')])])
21:27:40,178 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 407: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02%\x08\xefK\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xc8\x11\x00\x00\x01\x94\x12\xd0\xc8\x11\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dICI,7000.0,3000,0.0,0.0,0.0,0.0,F...')])])
21:27:40,180 <kafka.protocol.parser>[DEBUG]: Received correlation id: 407
21:27:40,180 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:40,181 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 407 (1.9679069519042969 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=405, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:40,181 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=405, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:40,181 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 405 log start offset 0 and error None.
21:27:40,182 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:43,781 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CC4/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:43,782 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:44,197 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IDI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:44,199 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IDI,8320.0,59600,-120.0,0.0,0.0,0.0,True,-20.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:44,199 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:44,199 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:44,199 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:44,200 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:44,200 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02|\x9a\x8b\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd7\xc7\x00\x00\x01\x94\x12\xd0\xd7\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nIDI,8320.0,59600,-120.0,0.0,0.0,0...')])])}
21:27:44,200 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:44,200 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02|\x9a\x8b\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd7\xc7\x00\x00\x01\x94\x12\xd0\xd7\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nIDI,8320.0,59600,-120.0,0.0,0.0,0...')])])
21:27:44,200 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02|\x9a\x8b\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd7\xc7\x00\x00\x01\x94\x12\xd0\xd7\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nIDI,8320.0,59600,-120.0,0.0,0.0,0...')])])
21:27:44,200 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 408: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02|\x9a\x8b\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd7\xc7\x00\x00\x01\x94\x12\xd0\xd7\xc7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nIDI,8320.0,59600,-120.0,0.0,0.0,0...')])])
21:27:44,203 <kafka.protocol.parser>[DEBUG]: Received correlation id: 408
21:27:44,203 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:44,203 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 408 (3.2117366790771484 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=406, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:44,204 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=406, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:44,204 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 406 log start offset 0 and error None.
21:27:44,206 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:44,483 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:44,485 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IDC,55900.0,900,-300.0,0.0,0.0,0.0,False,0.0,14:51:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:44,485 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:44,485 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:44,486 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:44,486 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:44,486 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xc13\xac\xf4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd8\xe5\x00\x00\x01\x94\x12\xd0\xd8\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDC,55900.0,900,-300.0,0.0,0.0,0....')])])}
21:27:44,486 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xc13\xac\xf4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd8\xe5\x00\x00\x01\x94\x12\xd0\xd8\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDC,55900.0,900,-300.0,0.0,0.0,0....')])])
21:27:44,486 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xc13\xac\xf4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd8\xe5\x00\x00\x01\x94\x12\xd0\xd8\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDC,55900.0,900,-300.0,0.0,0.0,0....')])])
21:27:44,487 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 409: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xc13\xac\xf4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xd8\xe5\x00\x00\x01\x94\x12\xd0\xd8\xe5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDC,55900.0,900,-300.0,0.0,0.0,0....')])])
21:27:44,487 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:44,489 <kafka.protocol.parser>[DEBUG]: Received correlation id: 409
21:27:44,489 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:44,489 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 409 (2.0041465759277344 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=407, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:44,489 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=407, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:44,489 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 407 log start offset 0 and error None.
21:27:44,491 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:45,236 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:45,238 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:45,924 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IDJ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:45,926 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IDJ,6000.0,7900,0.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:45,926 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:45,926 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:45,927 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:45,927 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:45,927 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8c'\xf0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xde\x86\x00\x00\x01\x94\x12\xd0\xde\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDJ,6000.0,7900,0.0,0.0,0.0,0.0,F...")])])}
21:27:45,927 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8c'\xf0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xde\x86\x00\x00\x01\x94\x12\xd0\xde\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDJ,6000.0,7900,0.0,0.0,0.0,0.0,F...")])])
21:27:45,927 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:45,927 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8c'\xf0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xde\x86\x00\x00\x01\x94\x12\xd0\xde\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDJ,6000.0,7900,0.0,0.0,0.0,0.0,F...")])])
21:27:45,928 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 410: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8c'\xf0\x17\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xde\x86\x00\x00\x01\x94\x12\xd0\xde\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDJ,6000.0,7900,0.0,0.0,0.0,0.0,F...")])])
21:27:45,930 <kafka.protocol.parser>[DEBUG]: Received correlation id: 410
21:27:45,930 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:45,930 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 410 (2.086639404296875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=408, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:45,931 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=408, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:45,931 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 408 log start offset 0 and error None.
21:27:45,932 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:46,261 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IDP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:46,263 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IDP,240000.0,200,-100.0,0.0,0.0,0.0,False,0.0,09:20:48' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:46,263 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:46,264 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:46,264 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:46,264 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:46,264 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xb6M\xedO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xdf\xd8\x00\x00\x01\x94\x12\xd0\xdf\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIDP,240000.0,200,-100.0,0.0,0.0,0...')])])}
21:27:46,264 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xb6M\xedO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xdf\xd8\x00\x00\x01\x94\x12\xd0\xdf\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIDP,240000.0,200,-100.0,0.0,0.0,0...')])])
21:27:46,264 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xb6M\xedO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xdf\xd8\x00\x00\x01\x94\x12\xd0\xdf\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIDP,240000.0,200,-100.0,0.0,0.0,0...')])])
21:27:46,264 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:46,265 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 411: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xb6M\xedO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xdf\xd8\x00\x00\x01\x94\x12\xd0\xdf\xd8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIDP,240000.0,200,-100.0,0.0,0.0,0...')])])
21:27:46,268 <kafka.protocol.parser>[DEBUG]: Received correlation id: 411
21:27:46,268 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:46,268 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 411 (2.713441848754883 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=409, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:46,268 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=409, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:46,268 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 409 log start offset 0 and error None.
21:27:46,270 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:46,684 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IDV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:46,687 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IDV,38100.0,300,-200.0,0.0,0.0,0.0,False,0.0,14:58:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:46,687 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:46,687 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:46,688 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:46,688 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:46,688 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xac\x1d\xa6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe1\x7f\x00\x00\x01\x94\x12\xd0\xe1\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDV,38100.0,300,-200.0,0.0,0.0,0....')])])}
21:27:46,688 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xac\x1d\xa6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe1\x7f\x00\x00\x01\x94\x12\xd0\xe1\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDV,38100.0,300,-200.0,0.0,0.0,0....')])])
21:27:46,688 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xac\x1d\xa6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe1\x7f\x00\x00\x01\x94\x12\xd0\xe1\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDV,38100.0,300,-200.0,0.0,0.0,0....')])])
21:27:46,688 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:46,688 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 412: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xac\x1d\xa6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe1\x7f\x00\x00\x01\x94\x12\xd0\xe1\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIDV,38100.0,300,-200.0,0.0,0.0,0....')])])
21:27:46,691 <kafka.protocol.parser>[DEBUG]: Received correlation id: 412
21:27:46,691 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:46,691 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 412 (1.9688606262207031 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=410, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:46,692 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=410, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:46,692 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 410 log start offset 0 and error None.
21:27:46,693 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:47,374 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IFS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:47,376 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IFS,26000.0,100,200.0,0.0,0.0,0.0,False,0.0,13:08:20' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:47,376 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:47,376 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:47,376 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:47,377 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:47,377 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x1f\x8c\xe0\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe40\x00\x00\x01\x94\x12\xd0\xe40\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hIFS,26000.0,100,200.0,0.0,0.0,0.0...')])])}
21:27:47,377 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x1f\x8c\xe0\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe40\x00\x00\x01\x94\x12\xd0\xe40\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hIFS,26000.0,100,200.0,0.0,0.0,0.0...')])])
21:27:47,377 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x1f\x8c\xe0\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe40\x00\x00\x01\x94\x12\xd0\xe40\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hIFS,26000.0,100,200.0,0.0,0.0,0.0...')])])
21:27:47,377 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:47,377 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 413: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\x1f\x8c\xe0\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xe40\x00\x00\x01\x94\x12\xd0\xe40\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hIFS,26000.0,100,200.0,0.0,0.0,0.0...')])])
21:27:47,380 <kafka.protocol.parser>[DEBUG]: Received correlation id: 413
21:27:47,380 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:47,380 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 413 (1.9943714141845703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=411, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:47,380 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=411, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:47,380 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 411 log start offset 0 and error None.
21:27:47,382 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:47,793 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IHK/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:48,807 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:49,140 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IJC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:49,142 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IJC,13950.0,163300,-150.0,0.0,0.0,0.0,True,-50.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,142 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,142 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:49,142 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:49,143 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:49,143 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02NU\xef\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xeb\x16\x00\x00\x01\x94\x12\xd0\xeb\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rIJC,13950.0,163300,-150.0,0.0,0.0...')])])}
21:27:49,143 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02NU\xef\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xeb\x16\x00\x00\x01\x94\x12\xd0\xeb\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rIJC,13950.0,163300,-150.0,0.0,0.0...')])])
21:27:49,143 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02NU\xef\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xeb\x16\x00\x00\x01\x94\x12\xd0\xeb\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rIJC,13950.0,163300,-150.0,0.0,0.0...')])])
21:27:49,143 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,143 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 414: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02NU\xef\xf7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xeb\x16\x00\x00\x01\x94\x12\xd0\xeb\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rIJC,13950.0,163300,-150.0,0.0,0.0...')])])
21:27:49,146 <kafka.protocol.parser>[DEBUG]: Received correlation id: 414
21:27:49,146 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:49,146 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 414 (2.0008087158203125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=412, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:49,146 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=412, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:49,146 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 412 log start offset 0 and error None.
21:27:49,148 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:49,424 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ILA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:49,426 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ILA,4800.0,100,200.0,0.0,0.0,0.0,False,100.0,14:44:07' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,426 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,426 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:49,426 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:49,426 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:49,426 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,427 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfa=\xf8L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xec2\x00\x00\x01\x94\x12\xd0\xec2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jILA,4800.0,100,200.0,0.0,0.0,0.0,...')])])}
21:27:49,427 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfa=\xf8L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xec2\x00\x00\x01\x94\x12\xd0\xec2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jILA,4800.0,100,200.0,0.0,0.0,0.0,...')])])
21:27:49,427 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfa=\xf8L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xec2\x00\x00\x01\x94\x12\xd0\xec2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jILA,4800.0,100,200.0,0.0,0.0,0.0,...')])])
21:27:49,427 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 415: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xfa=\xf8L\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xec2\x00\x00\x01\x94\x12\xd0\xec2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jILA,4800.0,100,200.0,0.0,0.0,0.0,...')])])
21:27:49,429 <kafka.protocol.parser>[DEBUG]: Received correlation id: 415
21:27:49,429 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:49,429 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 415 (1.9943714141845703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=413, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:49,430 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=413, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:49,430 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 413 log start offset 0 and error None.
21:27:49,431 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:49,725 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ILC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:49,727 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ILC,5800.0,100,-200.0,0.0,0.0,0.0,False,0.0,14:11:17' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,727 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,727 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:49,727 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:49,728 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:49,728 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfaP\xa3\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xed_\x00\x00\x01\x94\x12\xd0\xed_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hILC,5800.0,100,-200.0,0.0,0.0,0.0...')])])}
21:27:49,728 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfaP\xa3\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xed_\x00\x00\x01\x94\x12\xd0\xed_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hILC,5800.0,100,-200.0,0.0,0.0,0.0...')])])
21:27:49,728 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:49,728 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfaP\xa3\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xed_\x00\x00\x01\x94\x12\xd0\xed_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hILC,5800.0,100,-200.0,0.0,0.0,0.0...')])])
21:27:49,728 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 416: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xfaP\xa3\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xed_\x00\x00\x01\x94\x12\xd0\xed_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hILC,5800.0,100,-200.0,0.0,0.0,0.0...')])])
21:27:49,731 <kafka.protocol.parser>[DEBUG]: Received correlation id: 416
21:27:49,731 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:49,731 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 416 (2.963542938232422 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=414, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:49,731 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=414, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:49,731 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 414 log start offset 0 and error None.
21:27:49,733 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:50,158 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IME/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:50,160 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:50,453 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IMP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:50,454 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IMP,47700.0,11100,-750.0,0.0,0.0,0.0,True,0.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:50,455 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:50,455 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:50,455 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:50,455 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:50,455 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:50,455 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8e\x02v\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xf07\x00\x00\x01\x94\x12\xd0\xf07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIMP,47700.0,11100,-750.0,0.0,0.0,...')])])}
21:27:50,456 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8e\x02v\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xf07\x00\x00\x01\x94\x12\xd0\xf07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIMP,47700.0,11100,-750.0,0.0,0.0,...')])])
21:27:50,456 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8e\x02v\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xf07\x00\x00\x01\x94\x12\xd0\xf07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIMP,47700.0,11100,-750.0,0.0,0.0,...')])])
21:27:50,456 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 417: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8e\x02v\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd0\xf07\x00\x00\x01\x94\x12\xd0\xf07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIMP,47700.0,11100,-750.0,0.0,0.0,...')])])
21:27:50,458 <kafka.protocol.parser>[DEBUG]: Received correlation id: 417
21:27:50,458 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:50,458 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 417 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=415, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:50,458 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=415, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:50,458 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 415 log start offset 0 and error None.
21:27:50,460 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:53,913 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IN4/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:53,915 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:54,232 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IBD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:54,234 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:54,506 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/INC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:54,509 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:54,815 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DDG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:55,199 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'DDG,3100.0,31300,100.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:55,200 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:55,200 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:55,200 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:55,200 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:55,200 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\x03\x84C\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x02\xc0\x00\x00\x01\x94\x12\xd1\x02\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDDG,3100.0,31300,100.0,0.0,0.0,0....')])])}
21:27:55,201 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\x03\x84C\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x02\xc0\x00\x00\x01\x94\x12\xd1\x02\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDDG,3100.0,31300,100.0,0.0,0.0,0....')])])
21:27:55,201 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\x03\x84C\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x02\xc0\x00\x00\x01\x94\x12\xd1\x02\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDDG,3100.0,31300,100.0,0.0,0.0,0....')])])
21:27:55,200 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:55,201 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 418: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xb6\x03\x84C\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x02\xc0\x00\x00\x01\x94\x12\xd1\x02\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nDDG,3100.0,31300,100.0,0.0,0.0,0....')])])
21:27:55,204 <kafka.protocol.parser>[DEBUG]: Received correlation id: 418
21:27:55,204 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:55,204 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 418 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=416, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:55,204 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=416, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:55,204 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 416 log start offset 0 and error None.
21:27:55,206 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:55,547 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/INN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:55,549 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'INN,54500.0,1800,-500.0,0.0,0.0,0.0,False,500.0,11:20:25' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:55,549 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:55,549 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:55,549 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:55,550 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:55,550 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf5\xc9Ry\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x04\x1d\x00\x00\x01\x94\x12\xd1\x04\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pINN,54500.0,1800,-500.0,0.0,0.0,0...')])])}
21:27:55,550 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf5\xc9Ry\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x04\x1d\x00\x00\x01\x94\x12\xd1\x04\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pINN,54500.0,1800,-500.0,0.0,0.0,0...')])])
21:27:55,550 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf5\xc9Ry\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x04\x1d\x00\x00\x01\x94\x12\xd1\x04\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pINN,54500.0,1800,-500.0,0.0,0.0,0...')])])
21:27:55,550 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:55,550 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 419: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xf5\xc9Ry\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x04\x1d\x00\x00\x01\x94\x12\xd1\x04\x1d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pINN,54500.0,1800,-500.0,0.0,0.0,0...')])])
21:27:55,554 <kafka.protocol.parser>[DEBUG]: Received correlation id: 419
21:27:55,554 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:55,554 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 419 (2.6454925537109375 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=417, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:55,554 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=417, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:55,554 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 417 log start offset 0 and error None.
21:27:55,556 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:55,878 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IRC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:55,881 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:56,161 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ILS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:56,163 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ILS,12800.0,2800,-900.0,-0.1,0.0,0.0,False,-100.0,14:40:27' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:56,163 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:56,163 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:56,163 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:56,163 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:56,164 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xb7LU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x06\x83\x00\x00\x01\x94\x12\xd1\x06\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tILS,12800.0,2800,-900.0,-0.1,0.0...')])])}
21:27:56,164 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xb7LU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x06\x83\x00\x00\x01\x94\x12\xd1\x06\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tILS,12800.0,2800,-900.0,-0.1,0.0...')])])
21:27:56,164 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:56,164 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xb7LU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x06\x83\x00\x00\x01\x94\x12\xd1\x06\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tILS,12800.0,2800,-900.0,-0.1,0.0...')])])
21:27:56,164 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 420: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x92\xb7LU\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x06\x83\x00\x00\x01\x94\x12\xd1\x06\x83\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tILS,12800.0,2800,-900.0,-0.1,0.0...')])])
21:27:56,167 <kafka.protocol.parser>[DEBUG]: Received correlation id: 420
21:27:56,167 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:56,168 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 420 (3.1290054321289062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=418, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:56,168 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=418, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:56,168 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 418 log start offset 0 and error None.
21:27:56,170 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:27:56,569 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IPA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:27:56,571 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IPA,11800.0,600,-200.0,0.0,0.0,0.0,False,-200.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:27:56,571 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:27:56,572 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:27:56,572 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:27:56,572 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:27:56,572 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02U\xd4]z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x08\x1c\x00\x00\x01\x94\x12\xd1\x08\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pIPA,11800.0,600,-200.0,0.0,0.0,0....')])])}
21:27:56,572 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:27:56,572 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02U\xd4]z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x08\x1c\x00\x00\x01\x94\x12\xd1\x08\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pIPA,11800.0,600,-200.0,0.0,0.0,0....')])])
21:27:56,573 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02U\xd4]z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x08\x1c\x00\x00\x01\x94\x12\xd1\x08\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pIPA,11800.0,600,-200.0,0.0,0.0,0....')])])
21:27:56,573 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 421: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02U\xd4]z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x08\x1c\x00\x00\x01\x94\x12\xd1\x08\x1c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pIPA,11800.0,600,-200.0,0.0,0.0,0....')])])
21:27:56,575 <kafka.protocol.parser>[DEBUG]: Received correlation id: 421
21:27:56,575 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:27:56,576 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 421 (3.008604049682617 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=419, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:56,576 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=419, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:27:56,576 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 419 log start offset 0 and error None.
21:27:56,577 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:00,146 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ISG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:00,148 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:00,451 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IST/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:00,453 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IST,36000.0,100,-100.0,0.0,0.0,0.0,False,0.0,14:22:41' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:00,453 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:00,454 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:00,454 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:00,454 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:00,454 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x92\x0f\x1e\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x17F\x00\x00\x01\x94\x12\xd1\x17F\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIST,36000.0,100,-100.0,0.0,0.0,0....')])])}
21:28:00,454 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:00,454 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x92\x0f\x1e\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x17F\x00\x00\x01\x94\x12\xd1\x17F\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIST,36000.0,100,-100.0,0.0,0.0,0....')])])
21:28:00,455 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x92\x0f\x1e\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x17F\x00\x00\x01\x94\x12\xd1\x17F\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIST,36000.0,100,-100.0,0.0,0.0,0....')])])
21:28:00,455 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 422: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x92\x0f\x1e\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x17F\x00\x00\x01\x94\x12\xd1\x17F\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jIST,36000.0,100,-100.0,0.0,0.0,0....')])])
21:28:00,457 <kafka.protocol.parser>[DEBUG]: Received correlation id: 422
21:28:00,457 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:00,457 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 422 (1.9881725311279297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=420, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:00,458 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=420, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:00,458 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 420 log start offset 0 and error None.
21:28:00,459 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:01,147 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ITA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:01,149 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:01,475 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ITS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:01,477 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ITS,4200.0,200,0.0,0.0,0.0,0.0,False,0.0,14:48:51' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:01,478 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:01,478 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:01,478 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:01,478 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:01,478 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:01,478 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x08\x96d\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x1bF\x00\x00\x01\x94\x12\xd1\x1bF\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bITS,4200.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:28:01,479 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x08\x96d\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x1bF\x00\x00\x01\x94\x12\xd1\x1bF\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bITS,4200.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:28:01,479 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x08\x96d\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x1bF\x00\x00\x01\x94\x12\xd1\x1bF\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bITS,4200.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:28:01,479 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 423: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x08\x96d\xa3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x1bF\x00\x00\x01\x94\x12\xd1\x1bF\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bITS,4200.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:28:01,481 <kafka.protocol.parser>[DEBUG]: Received correlation id: 423
21:28:01,481 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:01,481 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 423 (2.039670944213867 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=421, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:01,481 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=421, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:01,482 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 421 log start offset 0 and error None.
21:28:01,483 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:02,814 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ITC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:02,816 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ITC,11150.0,14700,-300.0,0.0,0.0,0.0,False,50.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:02,816 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:02,816 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:02,817 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:02,817 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:02,817 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b,\xb1\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1 \x80\x00\x00\x01\x94\x12\xd1 \x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pITC,11150.0,14700,-300.0,0.0,0.0,...')])])}
21:28:02,817 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b,\xb1\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1 \x80\x00\x00\x01\x94\x12\xd1 \x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pITC,11150.0,14700,-300.0,0.0,0.0,...')])])
21:28:02,817 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:02,817 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b,\xb1\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1 \x80\x00\x00\x01\x94\x12\xd1 \x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pITC,11150.0,14700,-300.0,0.0,0.0,...')])])
21:28:02,818 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 424: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x1b,\xb1\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1 \x80\x00\x00\x01\x94\x12\xd1 \x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pITC,11150.0,14700,-300.0,0.0,0.0,...')])])
21:28:02,820 <kafka.protocol.parser>[DEBUG]: Received correlation id: 424
21:28:02,820 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:02,820 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 424 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=422, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:02,821 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=422, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:02,821 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 422 log start offset 0 and error None.
21:28:02,822 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:03,127 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ITD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:03,129 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ITD,13000.0,3200,-200.0,0.0,0.0,0.0,False,-200.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:03,129 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:03,129 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:03,129 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:03,130 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:03,130 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xffuo1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1!\xb9\x00\x00\x01\x94\x12\xd1!\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITD,13000.0,3200,-200.0,0.0,0.0,0...')])])}
21:28:03,130 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xffuo1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1!\xb9\x00\x00\x01\x94\x12\xd1!\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITD,13000.0,3200,-200.0,0.0,0.0,0...')])])
21:28:03,130 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:03,130 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xffuo1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1!\xb9\x00\x00\x01\x94\x12\xd1!\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITD,13000.0,3200,-200.0,0.0,0.0,0...')])])
21:28:03,130 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 425: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xffuo1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1!\xb9\x00\x00\x01\x94\x12\xd1!\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITD,13000.0,3200,-200.0,0.0,0.0,0...')])])
21:28:03,134 <kafka.protocol.parser>[DEBUG]: Received correlation id: 425
21:28:03,134 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:03,134 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 425 (2.6226043701171875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=423, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:03,134 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=423, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:03,135 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 423 log start offset 0 and error None.
21:28:03,136 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:03,460 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ITQ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:03,462 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ITQ,2600.0,37600,-100.0,0.0,0.0,0.0,False,-100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:03,462 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:03,463 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:03,463 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:03,463 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:03,463 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:03,464 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1eH[\xac\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1#\x07\x00\x00\x01\x94\x12\xd1#\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITQ,2600.0,37600,-100.0,0.0,0.0,0...')])])}
21:28:03,464 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1eH[\xac\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1#\x07\x00\x00\x01\x94\x12\xd1#\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITQ,2600.0,37600,-100.0,0.0,0.0,0...')])])
21:28:03,464 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1eH[\xac\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1#\x07\x00\x00\x01\x94\x12\xd1#\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITQ,2600.0,37600,-100.0,0.0,0.0,0...')])])
21:28:03,464 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 426: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1eH[\xac\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1#\x07\x00\x00\x01\x94\x12\xd1#\x07\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rITQ,2600.0,37600,-100.0,0.0,0.0,0...')])])
21:28:03,467 <kafka.protocol.parser>[DEBUG]: Received correlation id: 426
21:28:03,468 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:03,469 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 426 (3.991365432739258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=424, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:03,469 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=424, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:03,469 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 424 log start offset 0 and error None.
21:28:03,470 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:04,871 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/IVS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:04,874 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'IVS,10400.0,1000,-100.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:04,874 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:04,874 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:04,874 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:04,875 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:04,875 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xae\xadL\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1(\x8a\x00\x00\x01\x94\x12\xd1(\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIVS,10400.0,1000,-100.0,0.0,0.0,0...')])])}
21:28:04,875 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:04,875 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xae\xadL\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1(\x8a\x00\x00\x01\x94\x12\xd1(\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIVS,10400.0,1000,-100.0,0.0,0.0,0...')])])
21:28:04,875 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xae\xadL\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1(\x8a\x00\x00\x01\x94\x12\xd1(\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIVS,10400.0,1000,-100.0,0.0,0.0,0...')])])
21:28:04,876 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 427: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xae\xadL\x06\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1(\x8a\x00\x00\x01\x94\x12\xd1(\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lIVS,10400.0,1000,-100.0,0.0,0.0,0...')])])
21:28:04,878 <kafka.protocol.parser>[DEBUG]: Received correlation id: 427
21:28:04,878 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:04,878 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 427 (1.9996166229248047 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=425, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:04,878 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=425, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:04,878 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 425 log start offset 0 and error None.
21:28:04,880 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:05,575 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/JVC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:05,577 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'JVC,3800.0,35900,-20.0,0.0,0.0,0.0,False,30.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:05,577 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:05,577 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:05,578 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:05,578 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:05,578 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f,Y<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1+I\x00\x00\x01\x94\x12\xd1+I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lJVC,3800.0,35900,-20.0,0.0,0.0,0....')])])}
21:28:05,578 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f,Y<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1+I\x00\x00\x01\x94\x12\xd1+I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lJVC,3800.0,35900,-20.0,0.0,0.0,0....')])])
21:28:05,578 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f,Y<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1+I\x00\x00\x01\x94\x12\xd1+I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lJVC,3800.0,35900,-20.0,0.0,0.0,0....')])])
21:28:05,578 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:05,578 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 428: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8f,Y<\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1+I\x00\x00\x01\x94\x12\xd1+I\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lJVC,3800.0,35900,-20.0,0.0,0.0,0....')])])
21:28:05,581 <kafka.protocol.parser>[DEBUG]: Received correlation id: 428
21:28:05,581 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:05,581 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 428 (1.997232437133789 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=426, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:05,581 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=426, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:05,581 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 426 log start offset 0 and error None.
21:28:05,583 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:06,907 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KAC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:06,909 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:08,284 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:08,287 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KBC,27650.0,303300,100.0,0.0,0.0,0.0,True,50.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:08,287 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:08,287 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:08,287 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:08,287 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:08,288 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:08,288 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x19\x11[#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd15\xdf\x00\x00\x01\x94\x12\xd15\xdf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nKBC,27650.0,303300,100.0,0.0,0.0,...')])])}
21:28:08,288 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x19\x11[#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd15\xdf\x00\x00\x01\x94\x12\xd15\xdf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nKBC,27650.0,303300,100.0,0.0,0.0,...')])])
21:28:08,288 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x19\x11[#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd15\xdf\x00\x00\x01\x94\x12\xd15\xdf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nKBC,27650.0,303300,100.0,0.0,0.0,...')])])
21:28:08,288 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 429: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x19\x11[#\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd15\xdf\x00\x00\x01\x94\x12\xd15\xdf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nKBC,27650.0,303300,100.0,0.0,0.0,...')])])
21:28:08,291 <kafka.protocol.parser>[DEBUG]: Received correlation id: 429
21:28:08,291 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:08,291 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 429 (2.994537353515625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=427, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:08,291 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=427, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:08,291 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 427 log start offset 0 and error None.
21:28:08,292 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:08,587 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KCE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:08,589 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:08,898 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:08,900 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KDC,58800.0,49000,-100.0,0.0,0.0,0.0,True,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:08,901 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:08,901 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:08,902 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:08,902 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:08,902 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xeb\xbf\x9de\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd18E\x00\x00\x01\x94\x12\xd18E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKDC,58800.0,49000,-100.0,0.0,0.0,...')])])}
21:28:08,903 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xeb\xbf\x9de\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd18E\x00\x00\x01\x94\x12\xd18E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKDC,58800.0,49000,-100.0,0.0,0.0,...')])])
21:28:08,903 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xeb\xbf\x9de\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd18E\x00\x00\x01\x94\x12\xd18E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKDC,58800.0,49000,-100.0,0.0,0.0,...')])])
21:28:08,903 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 430: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xeb\xbf\x9de\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd18E\x00\x00\x01\x94\x12\xd18E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKDC,58800.0,49000,-100.0,0.0,0.0,...')])])
21:28:08,903 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:08,905 <kafka.protocol.parser>[DEBUG]: Received correlation id: 430
21:28:08,905 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:08,905 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 430 (1.993417739868164 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=428, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:08,906 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=428, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:08,906 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 428 log start offset 0 and error None.
21:28:08,907 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:09,248 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KDH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:09,251 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KDH,35800.0,726600,-50.0,0.0,0.0,0.0,True,-100.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:09,251 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:09,251 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:09,251 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:09,252 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:09,252 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:09,252 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x026\xe6sA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd19\xa3\x00\x00\x01\x94\x12\xd19\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKDH,35800.0,726600,-50.0,0.0,0.0,...')])])}
21:28:09,252 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x026\xe6sA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd19\xa3\x00\x00\x01\x94\x12\xd19\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKDH,35800.0,726600,-50.0,0.0,0.0,...')])])
21:28:09,253 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x026\xe6sA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd19\xa3\x00\x00\x01\x94\x12\xd19\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKDH,35800.0,726600,-50.0,0.0,0.0,...')])])
21:28:09,253 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 431: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x026\xe6sA\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd19\xa3\x00\x00\x01\x94\x12\xd19\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKDH,35800.0,726600,-50.0,0.0,0.0,...')])])
21:28:09,255 <kafka.protocol.parser>[DEBUG]: Received correlation id: 431
21:28:09,255 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:09,256 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 431 (1.9993782043457031 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=429, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:09,256 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=429, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:09,256 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 429 log start offset 0 and error None.
21:28:09,257 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:09,584 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KDM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:09,586 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KDM,15800.0,1300,0.0,0.0,0.0,0.0,False,0.0,14:45:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:09,587 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:09,587 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:09,587 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:09,587 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:09,587 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb2\x11\xac.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1:\xf3\x00\x00\x01\x94\x12\xd1:\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKDM,15800.0,1300,0.0,0.0,0.0,0.0,...')])])}
21:28:09,588 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:09,588 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb2\x11\xac.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1:\xf3\x00\x00\x01\x94\x12\xd1:\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKDM,15800.0,1300,0.0,0.0,0.0,0.0,...')])])
21:28:09,588 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb2\x11\xac.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1:\xf3\x00\x00\x01\x94\x12\xd1:\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKDM,15800.0,1300,0.0,0.0,0.0,0.0,...')])])
21:28:09,588 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 432: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xb2\x11\xac.\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1:\xf3\x00\x00\x01\x94\x12\xd1:\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKDM,15800.0,1300,0.0,0.0,0.0,0.0,...')])])
21:28:09,590 <kafka.protocol.parser>[DEBUG]: Received correlation id: 432
21:28:09,591 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:09,591 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 432 (2.999544143676758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=430, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:09,591 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=430, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:09,591 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 430 log start offset 0 and error None.
21:28:09,593 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:09,878 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KTC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:09,880 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:10,201 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KHA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:10,204 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:10,926 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KHG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:10,928 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KHG,5690.0,367800,10.0,0.0,0.0,0.0,True,-10.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:10,928 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:10,928 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:10,928 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:10,928 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:10,928 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02|`\xe0m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1@0\x00\x00\x01\x94\x12\xd1@0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKHG,5690.0,367800,10.0,0.0,0.0,0....')])])}
21:28:10,929 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02|`\xe0m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1@0\x00\x00\x01\x94\x12\xd1@0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKHG,5690.0,367800,10.0,0.0,0.0,0....')])])
21:28:10,929 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02|`\xe0m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1@0\x00\x00\x01\x94\x12\xd1@0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKHG,5690.0,367800,10.0,0.0,0.0,0....')])])
21:28:10,929 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:10,929 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 433: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02|`\xe0m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1@0\x00\x00\x01\x94\x12\xd1@0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lKHG,5690.0,367800,10.0,0.0,0.0,0....')])])
21:28:10,932 <kafka.protocol.parser>[DEBUG]: Received correlation id: 433
21:28:10,932 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:10,932 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 433 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=431, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:10,932 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=431, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:10,932 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 431 log start offset 0 and error None.
21:28:10,933 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:11,249 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KHW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:11,251 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KHW,28000.0,100,500.0,0.0,0.0,0.0,False,0.0,11:15:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:11,251 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:11,252 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:11,252 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:11,252 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:11,252 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x8a\x14z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1At\x00\x00\x01\x94\x12\xd1At\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hKHW,28000.0,100,500.0,0.0,0.0,0.0...')])])}
21:28:11,252 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x8a\x14z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1At\x00\x00\x01\x94\x12\xd1At\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hKHW,28000.0,100,500.0,0.0,0.0,0.0...')])])
21:28:11,252 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x8a\x14z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1At\x00\x00\x01\x94\x12\xd1At\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hKHW,28000.0,100,500.0,0.0,0.0,0.0...')])])
21:28:11,252 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:11,253 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 434: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02n\x8a\x14z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1At\x00\x00\x01\x94\x12\xd1At\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hKHW,28000.0,100,500.0,0.0,0.0,0.0...')])])
21:28:11,255 <kafka.protocol.parser>[DEBUG]: Received correlation id: 434
21:28:11,255 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:11,255 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 434 (2.631664276123047 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=432, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:11,255 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=432, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:11,255 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 432 log start offset 0 and error None.
21:28:11,257 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:11,568 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KHL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:11,570 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:11,893 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KHP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:11,895 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KHP,15400.0,109400,200.0,0.0,0.0,0.0,True,-100.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:11,895 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:11,896 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:11,896 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:11,896 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:11,896 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02y\x08\xa7P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1C\xf8\x00\x00\x01\x94\x12\xd1C\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKHP,15400.0,109400,200.0,0.0,0.0,...')])])}
21:28:11,896 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02y\x08\xa7P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1C\xf8\x00\x00\x01\x94\x12\xd1C\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKHP,15400.0,109400,200.0,0.0,0.0,...')])])
21:28:11,896 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02y\x08\xa7P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1C\xf8\x00\x00\x01\x94\x12\xd1C\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKHP,15400.0,109400,200.0,0.0,0.0,...')])])
21:28:11,897 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 435: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02y\x08\xa7P\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1C\xf8\x00\x00\x01\x94\x12\xd1C\xf8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKHP,15400.0,109400,200.0,0.0,0.0,...')])])
21:28:11,897 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:11,900 <kafka.protocol.parser>[DEBUG]: Received correlation id: 435
21:28:11,900 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:11,900 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 435 (2.5260448455810547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=433, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:11,900 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=433, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:11,900 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 433 log start offset 0 and error None.
21:28:11,902 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:13,551 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KGM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:13,553 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KGM,7100.0,200,100.0,0.0,0.0,0.0,False,0.0,13:19:28' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:13,554 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:13,554 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:13,554 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:13,554 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:13,554 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02P\xe2\xe5y\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1Jr\x00\x00\x01\x94\x12\xd1Jr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKGM,7100.0,200,100.0,0.0,0.0,0.0,...')])])}
21:28:13,554 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02P\xe2\xe5y\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1Jr\x00\x00\x01\x94\x12\xd1Jr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKGM,7100.0,200,100.0,0.0,0.0,0.0,...')])])
21:28:13,555 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02P\xe2\xe5y\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1Jr\x00\x00\x01\x94\x12\xd1Jr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKGM,7100.0,200,100.0,0.0,0.0,0.0,...')])])
21:28:13,554 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:13,555 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 436: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02P\xe2\xe5y\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1Jr\x00\x00\x01\x94\x12\xd1Jr\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKGM,7100.0,200,100.0,0.0,0.0,0.0,...')])])
21:28:13,557 <kafka.protocol.parser>[DEBUG]: Received correlation id: 436
21:28:13,557 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:13,557 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 436 (1.9958019256591797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=434, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:13,558 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=434, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:13,558 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 434 log start offset 0 and error None.
21:28:13,559 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:13,875 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KHS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:13,877 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KHS,13800.0,1000,0.0,0.0,0.0,0.0,False,100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:13,877 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:13,877 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:13,877 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:13,878 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:13,878 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02p+\x00\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1K\xb5\x00\x00\x01\x94\x12\xd1K\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHS,13800.0,1000,0.0,0.0,0.0,0.0,...')])])}
21:28:13,878 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02p+\x00\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1K\xb5\x00\x00\x01\x94\x12\xd1K\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHS,13800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:28:13,878 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:13,878 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02p+\x00\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1K\xb5\x00\x00\x01\x94\x12\xd1K\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHS,13800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:28:13,878 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 437: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02p+\x00\xa0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1K\xb5\x00\x00\x01\x94\x12\xd1K\xb5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHS,13800.0,1000,0.0,0.0,0.0,0.0,...')])])
21:28:13,881 <kafka.protocol.parser>[DEBUG]: Received correlation id: 437
21:28:13,881 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:13,881 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 437 (1.9626617431640625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=435, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:13,881 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=435, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:13,881 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 435 log start offset 0 and error None.
21:28:13,882 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:14,641 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KKC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:14,643 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:14,931 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KLB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:14,933 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KLB,11500.0,5000,0.0,0.0,0.0,0.0,False,0.0,14:57:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:14,933 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:14,933 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:14,934 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:14,934 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:14,934 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:14,934 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x0f\xe2\xbf\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1O\xd5\x00\x00\x01\x94\x12\xd1O\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKLB,11500.0,5000,0.0,0.0,0.0,0.0,...')])])}
21:28:14,935 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x0f\xe2\xbf\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1O\xd5\x00\x00\x01\x94\x12\xd1O\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKLB,11500.0,5000,0.0,0.0,0.0,0.0,...')])])
21:28:14,935 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x0f\xe2\xbf\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1O\xd5\x00\x00\x01\x94\x12\xd1O\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKLB,11500.0,5000,0.0,0.0,0.0,0.0,...')])])
21:28:14,935 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 438: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x0f\xe2\xbf\x88\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1O\xd5\x00\x00\x01\x94\x12\xd1O\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKLB,11500.0,5000,0.0,0.0,0.0,0.0,...')])])
21:28:14,937 <kafka.protocol.parser>[DEBUG]: Received correlation id: 438
21:28:14,937 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:14,938 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 438 (2.0051002502441406 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=436, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:14,938 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=436, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:14,938 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 436 log start offset 0 and error None.
21:28:14,939 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:15,611 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KLF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:15,613 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:16,964 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KLM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:16,966 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:18,390 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/GKM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:18,392 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'GKM,5200.0,30100,-100.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:18,393 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:18,393 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:18,393 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:18,393 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:18,393 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:18,393 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x021Y\r\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1]Y\x00\x00\x01\x94\x12\xd1]Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGKM,5200.0,30100,-100.0,0.0,0.0,0...')])])}
21:28:18,393 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x021Y\r\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1]Y\x00\x00\x01\x94\x12\xd1]Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGKM,5200.0,30100,-100.0,0.0,0.0,0...')])])
21:28:18,394 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x021Y\r\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1]Y\x00\x00\x01\x94\x12\xd1]Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGKM,5200.0,30100,-100.0,0.0,0.0,0...')])])
21:28:18,394 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 439: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x021Y\r\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1]Y\x00\x00\x01\x94\x12\xd1]Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rGKM,5200.0,30100,-100.0,0.0,0.0,0...')])])
21:28:18,396 <kafka.protocol.parser>[DEBUG]: Received correlation id: 439
21:28:18,396 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:18,396 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 439 (2.4225711822509766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=437, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:18,396 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=437, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:18,396 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 437 log start offset 0 and error None.
21:28:18,397 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:18,959 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KMR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:18,961 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KMR,3250.0,1000,10.0,0.0,0.0,0.0,False,0.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:18,961 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:18,961 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:18,961 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:18,962 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:18,962 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:18,962 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x91\xe0\xc6>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1_\x91\x00\x00\x01\x94\x12\xd1_\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKMR,3250.0,1000,10.0,0.0,0.0,0.0,...')])])}
21:28:18,962 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x91\xe0\xc6>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1_\x91\x00\x00\x01\x94\x12\xd1_\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKMR,3250.0,1000,10.0,0.0,0.0,0.0,...')])])
21:28:18,963 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x91\xe0\xc6>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1_\x91\x00\x00\x01\x94\x12\xd1_\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKMR,3250.0,1000,10.0,0.0,0.0,0.0,...')])])
21:28:18,963 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 440: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x91\xe0\xc6>\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1_\x91\x00\x00\x01\x94\x12\xd1_\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKMR,3250.0,1000,10.0,0.0,0.0,0.0,...')])])
21:28:18,965 <kafka.protocol.parser>[DEBUG]: Received correlation id: 440
21:28:18,965 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:18,965 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 440 (1.5909671783447266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=438, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:18,965 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=438, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:18,966 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 438 log start offset 0 and error None.
21:28:18,967 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:19,293 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KMT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:19,295 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:19,613 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KOS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:19,615 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KOS,38350.0,2100,0.0,0.0,0.0,0.0,False,0.0,13:45:41' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:19,615 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:19,615 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:19,616 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:19,616 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:19,616 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xce\x80\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1b\x1f\x00\x00\x01\x94\x12\xd1b\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKOS,38350.0,2100,0.0,0.0,0.0,0.0,...')])])}
21:28:19,616 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:19,616 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xce\x80\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1b\x1f\x00\x00\x01\x94\x12\xd1b\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKOS,38350.0,2100,0.0,0.0,0.0,0.0,...')])])
21:28:19,617 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xce\x80\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1b\x1f\x00\x00\x01\x94\x12\xd1b\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKOS,38350.0,2100,0.0,0.0,0.0,0.0,...')])])
21:28:19,617 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 441: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xce\x80\x00"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1b\x1f\x00\x00\x01\x94\x12\xd1b\x1f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKOS,38350.0,2100,0.0,0.0,0.0,0.0,...')])])
21:28:19,620 <kafka.protocol.parser>[DEBUG]: Received correlation id: 441
21:28:19,620 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:19,620 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 441 (2.9938220977783203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=439, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:19,620 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=439, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:19,620 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 439 log start offset 0 and error None.
21:28:19,622 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:19,932 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KPF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:19,935 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KPF,1640.0,1100,0.0,0.0,0.0,0.0,False,10.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:19,935 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:19,935 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:19,936 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:19,936 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:19,936 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:19,936 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd9\xe3z0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1c_\x00\x00\x01\x94\x12\xd1c_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKPF,1640.0,1100,0.0,0.0,0.0,0.0,F...')])])}
21:28:19,936 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd9\xe3z0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1c_\x00\x00\x01\x94\x12\xd1c_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKPF,1640.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:28:19,936 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd9\xe3z0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1c_\x00\x00\x01\x94\x12\xd1c_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKPF,1640.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:28:19,937 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 442: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xd9\xe3z0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1c_\x00\x00\x01\x94\x12\xd1c_\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fKPF,1640.0,1100,0.0,0.0,0.0,0.0,F...')])])
21:28:19,939 <kafka.protocol.parser>[DEBUG]: Received correlation id: 442
21:28:19,939 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:19,939 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 442 (2.000093460083008 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=440, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:19,939 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=440, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:19,939 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 440 log start offset 0 and error None.
21:28:19,940 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:20,276 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KSB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:20,277 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KSB,18700.0,90500,-250.0,0.0,0.0,0.0,True,-150.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:20,278 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:20,278 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:20,278 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:20,278 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:20,279 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:20,279 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb0\xab_q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1d\xb6\x00\x00\x01\x94\x12\xd1d\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKSB,18700.0,90500,-250.0,0.0,0.0,...')])])}
21:28:20,279 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb0\xab_q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1d\xb6\x00\x00\x01\x94\x12\xd1d\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKSB,18700.0,90500,-250.0,0.0,0.0,...')])])
21:28:20,279 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb0\xab_q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1d\xb6\x00\x00\x01\x94\x12\xd1d\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKSB,18700.0,90500,-250.0,0.0,0.0,...')])])
21:28:20,279 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 443: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xb0\xab_q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1d\xb6\x00\x00\x01\x94\x12\xd1d\xb6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rKSB,18700.0,90500,-250.0,0.0,0.0,...')])])
21:28:20,281 <kafka.protocol.parser>[DEBUG]: Received correlation id: 443
21:28:20,282 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:20,282 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 443 (2.9997825622558594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=441, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:20,282 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=441, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:20,282 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 441 log start offset 0 and error None.
21:28:20,283 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:22,164 <kafka.client>[DEBUG]: Sending metadata request MetadataRequest_v1(topics=['realtimeStockData']) to node 1
21:28:22,164 <kafka.protocol.parser>[DEBUG]: Sending request MetadataRequest_v1(topics=['realtimeStockData'])
21:28:22,164 <kafka.conn>[DEBUG]: <BrokerConnection node_id=1 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Request 2: MetadataRequest_v1(topics=['realtimeStockData'])
21:28:22,166 <kafka.protocol.parser>[DEBUG]: Received correlation id: 2
21:28:22,166 <kafka.protocol.parser>[DEBUG]: Processing response MetadataResponse_v1
21:28:22,166 <kafka.conn>[DEBUG]: <BrokerConnection node_id=1 host=localhost:19092 <connected> [IPv6 ('::1', 19092, 0, 0)]> Response 2 (1.9989013671875 ms): MetadataResponse_v1(brokers=[(node_id=2, host='localhost', port=29092, rack=None), (node_id=3, host='localhost', port=39092, rack=None), (node_id=1, host='localhost', port=19092, rack=None)], controller_id=1, topics=[(error_code=0, topic='realtimeStockData', is_internal=False, partitions=[(error_code=0, partition=0, leader=2, replicas=[2], isr=[2])])])
21:28:22,166 <kafka.cluster>[DEBUG]: Updated cluster metadata to ClusterMetadata(brokers: 3, topics: 1, groups: 0)
21:28:25,397 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KSD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:25,539 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KSD,4700.0,1000,-200.0,0.0,0.0,0.0,False,0.0,09:35:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:25,539 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:25,539 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:25,539 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:25,539 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:25,540 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf8\xb5\x93\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1yC\x00\x00\x01\x94\x12\xd1yC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSD,4700.0,1000,-200.0,0.0,0.0,0....')])])}
21:28:25,540 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf8\xb5\x93\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1yC\x00\x00\x01\x94\x12\xd1yC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSD,4700.0,1000,-200.0,0.0,0.0,0....')])])
21:28:25,540 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf8\xb5\x93\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1yC\x00\x00\x01\x94\x12\xd1yC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSD,4700.0,1000,-200.0,0.0,0.0,0....')])])
21:28:25,540 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:25,540 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 444: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xf8\xb5\x93\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1yC\x00\x00\x01\x94\x12\xd1yC\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSD,4700.0,1000,-200.0,0.0,0.0,0....')])])
21:28:25,542 <kafka.protocol.parser>[DEBUG]: Received correlation id: 444
21:28:25,543 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:25,543 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 444 (3.0066967010498047 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=442, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:25,543 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=442, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:25,543 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 442 log start offset 0 and error None.
21:28:25,544 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:25,874 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KSH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:25,876 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:26,215 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KHD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:26,217 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KHD,12800.0,200,1600.0,0.1,0.0,0.0,False,0.0,14:02:27' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:26,218 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:26,218 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:26,218 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:26,219 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:26,219 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:26,219 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02CFO\xb5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1{\xea\x00\x00\x01\x94\x12\xd1{\xea\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHD,12800.0,200,1600.0,0.1,0.0,0....')])])}
21:28:26,219 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02CFO\xb5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1{\xea\x00\x00\x01\x94\x12\xd1{\xea\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHD,12800.0,200,1600.0,0.1,0.0,0....')])])
21:28:26,219 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02CFO\xb5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1{\xea\x00\x00\x01\x94\x12\xd1{\xea\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHD,12800.0,200,1600.0,0.1,0.0,0....')])])
21:28:26,219 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 445: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02CFO\xb5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1{\xea\x00\x00\x01\x94\x12\xd1{\xea\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKHD,12800.0,200,1600.0,0.1,0.0,0....')])])
21:28:26,222 <kafka.protocol.parser>[DEBUG]: Received correlation id: 445
21:28:26,222 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:26,222 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 445 (2.0012855529785156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=443, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:26,222 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=443, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:26,222 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 443 log start offset 0 and error None.
21:28:26,223 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:26,551 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KSK/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:26,553 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:26,910 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LMC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:28,363 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LMC,9800.0,100,-200.0,0.0,0.0,0.0,False,0.0,10:32:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:28,363 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:28,363 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:28,363 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:28,364 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:28,364 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:28,364 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02I\xc0\xa6q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x84K\x00\x00\x01\x94\x12\xd1\x84K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLMC,9800.0,100,-200.0,0.0,0.0,0.0...')])])}
21:28:28,364 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02I\xc0\xa6q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x84K\x00\x00\x01\x94\x12\xd1\x84K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLMC,9800.0,100,-200.0,0.0,0.0,0.0...')])])
21:28:28,364 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02I\xc0\xa6q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x84K\x00\x00\x01\x94\x12\xd1\x84K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLMC,9800.0,100,-200.0,0.0,0.0,0.0...')])])
21:28:28,365 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 446: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02I\xc0\xa6q\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x84K\x00\x00\x01\x94\x12\xd1\x84K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLMC,9800.0,100,-200.0,0.0,0.0,0.0...')])])
21:28:28,368 <kafka.protocol.parser>[DEBUG]: Received correlation id: 446
21:28:28,368 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:28,369 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 446 (4.002094268798828 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=444, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:28,369 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=444, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:28,369 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 444 log start offset 0 and error None.
21:28:28,370 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:28,678 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KSQ/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:28,679 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KSQ,3000.0,800,-200.0,-0.1,0.0,0.0,False,0.0,14:45:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:28,680 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:28,680 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:28,680 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:28,680 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:28,680 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:28,681 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa2\x05Y\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x85\x88\x00\x00\x01\x94\x12\xd1\x85\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSQ,3000.0,800,-200.0,-0.1,0.0,0....')])])}
21:28:28,682 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa2\x05Y\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x85\x88\x00\x00\x01\x94\x12\xd1\x85\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSQ,3000.0,800,-200.0,-0.1,0.0,0....')])])
21:28:28,682 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa2\x05Y\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x85\x88\x00\x00\x01\x94\x12\xd1\x85\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSQ,3000.0,800,-200.0,-0.1,0.0,0....')])])
21:28:28,682 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 447: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa2\x05Y\x04\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x85\x88\x00\x00\x01\x94\x12\xd1\x85\x88\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jKSQ,3000.0,800,-200.0,-0.1,0.0,0....')])])
21:28:28,684 <kafka.protocol.parser>[DEBUG]: Received correlation id: 447
21:28:28,684 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:28,684 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 447 (2.000093460083008 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=445, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:28,684 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=445, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:28,685 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 445 log start offset 0 and error None.
21:28:28,686 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:28,988 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KSS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:28,991 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:29,315 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KST/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:29,317 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:29,639 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KSV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:29,642 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KSV,132000.0,1800,1700.0,0.0,0.0,0.0,True,-2000.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:29,642 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:29,643 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:29,643 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:29,643 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:29,643 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x16\xa9\x94}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x89K\x00\x00\x01\x94\x12\xd1\x89K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tKSV,132000.0,1800,1700.0,0.0,0.0...')])])}
21:28:29,643 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:29,644 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x16\xa9\x94}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x89K\x00\x00\x01\x94\x12\xd1\x89K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tKSV,132000.0,1800,1700.0,0.0,0.0...')])])
21:28:29,644 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x16\xa9\x94}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x89K\x00\x00\x01\x94\x12\xd1\x89K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tKSV,132000.0,1800,1700.0,0.0,0.0...')])])
21:28:29,644 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 448: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\x16\xa9\x94}\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x89K\x00\x00\x01\x94\x12\xd1\x89K\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tKSV,132000.0,1800,1700.0,0.0,0.0...')])])
21:28:29,648 <kafka.protocol.parser>[DEBUG]: Received correlation id: 448
21:28:29,648 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:29,648 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 448 (3.3414363861083984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=446, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:29,648 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=446, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:29,648 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 446 log start offset 0 and error None.
21:28:29,650 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:30,594 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KTL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:30,596 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KTL,17000.0,1500,-1800.0,-0.1,0.0,0.0,False,0.0,14:33:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:30,596 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:30,597 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:30,597 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:30,597 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:30,597 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:30,597 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x99\xf9\x0fO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8d\x05\x00\x00\x01\x94\x12\xd1\x8d\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTL,17000.0,1500,-1800.0,-0.1,0.0...')])])}
21:28:30,597 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x99\xf9\x0fO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8d\x05\x00\x00\x01\x94\x12\xd1\x8d\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTL,17000.0,1500,-1800.0,-0.1,0.0...')])])
21:28:30,598 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x99\xf9\x0fO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8d\x05\x00\x00\x01\x94\x12\xd1\x8d\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTL,17000.0,1500,-1800.0,-0.1,0.0...')])])
21:28:30,598 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 449: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x99\xf9\x0fO\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8d\x05\x00\x00\x01\x94\x12\xd1\x8d\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTL,17000.0,1500,-1800.0,-0.1,0.0...')])])
21:28:30,601 <kafka.protocol.parser>[DEBUG]: Received correlation id: 449
21:28:30,601 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:30,602 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 449 (3.515005111694336 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=447, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:30,602 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=447, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:30,602 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 447 log start offset 0 and error None.
21:28:30,604 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:30,907 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KTS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:30,912 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KTS,42000.0,100,-200.0,0.0,0.0,0.0,False,1000.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:30,913 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:30,913 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:30,913 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:30,913 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:30,913 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:30,913 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02D\xb9PW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8eA\x00\x00\x01\x94\x12\xd1\x8eA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTS,42000.0,100,-200.0,0.0,0.0,0....')])])}
21:28:30,913 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02D\xb9PW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8eA\x00\x00\x01\x94\x12\xd1\x8eA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTS,42000.0,100,-200.0,0.0,0.0,0....')])])
21:28:30,913 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02D\xb9PW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8eA\x00\x00\x01\x94\x12\xd1\x8eA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTS,42000.0,100,-200.0,0.0,0.0,0....')])])
21:28:30,914 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 450: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02D\xb9PW\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x8eA\x00\x00\x01\x94\x12\xd1\x8eA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pKTS,42000.0,100,-200.0,0.0,0.0,0....')])])
21:28:30,918 <kafka.protocol.parser>[DEBUG]: Received correlation id: 450
21:28:30,918 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:30,918 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 450 (3.5924911499023438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=448, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:30,918 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=448, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:30,918 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 448 log start offset 0 and error None.
21:28:30,920 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:31,258 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KTT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:31,261 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:31,998 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KTU/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:32,0 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:33,761 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/KVC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:33,763 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'KVC,1300.0,8000,0.0,0.0,0.0,0.0,False,0.0,14:56:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:33,763 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:33,763 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:33,764 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:33,764 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:33,764 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xceU\xe9k\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x99c\x00\x00\x01\x94\x12\xd1\x99c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dKVC,1300.0,8000,0.0,0.0,0.0,0.0,F...')])])}
21:28:33,764 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xceU\xe9k\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x99c\x00\x00\x01\x94\x12\xd1\x99c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dKVC,1300.0,8000,0.0,0.0,0.0,0.0,F...')])])
21:28:33,764 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:33,764 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xceU\xe9k\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x99c\x00\x00\x01\x94\x12\xd1\x99c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dKVC,1300.0,8000,0.0,0.0,0.0,0.0,F...')])])
21:28:33,765 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 451: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xceU\xe9k\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x99c\x00\x00\x01\x94\x12\xd1\x99c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dKVC,1300.0,8000,0.0,0.0,0.0,0.0,F...')])])
21:28:33,811 <kafka.protocol.parser>[DEBUG]: Received correlation id: 451
21:28:33,811 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:33,812 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 451 (46.60820960998535 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=449, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:33,812 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=449, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:33,812 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 449 log start offset 0 and error None.
21:28:33,813 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:34,527 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L10/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:34,530 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:34,855 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L14/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:34,858 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L14,38400.0,12100,-400.0,0.0,0.0,0.0,True,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:34,858 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:34,858 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:34,859 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:34,859 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfa\x83\x943\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x9d\xaa\x00\x00\x01\x94\x12\xd1\x9d\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lL14,38400.0,12100,-400.0,0.0,0.0,...')])])}
21:28:34,859 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfa\x83\x943\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x9d\xaa\x00\x00\x01\x94\x12\xd1\x9d\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lL14,38400.0,12100,-400.0,0.0,0.0,...')])])
21:28:34,860 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfa\x83\x943\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x9d\xaa\x00\x00\x01\x94\x12\xd1\x9d\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lL14,38400.0,12100,-400.0,0.0,0.0,...')])])
21:28:34,860 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 452: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfa\x83\x943\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\x9d\xaa\x00\x00\x01\x94\x12\xd1\x9d\xaa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lL14,38400.0,12100,-400.0,0.0,0.0,...')])])
21:28:34,860 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:34,860 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:34,863 <kafka.protocol.parser>[DEBUG]: Received correlation id: 452
21:28:34,863 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:34,863 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 452 (3.0031204223632812 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=450, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:34,863 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=450, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:34,863 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 450 log start offset 0 and error None.
21:28:34,865 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:35,902 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L18/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:35,904 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L18,40000.0,1000,-500.0,0.0,0.0,0.0,False,200.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:35,904 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:35,904 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:35,904 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:35,905 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:35,905 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:35,905 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02G\xac;m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa1\xc0\x00\x00\x01\x94\x12\xd1\xa1\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pL18,40000.0,1000,-500.0,0.0,0.0,0...')])])}
21:28:35,905 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02G\xac;m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa1\xc0\x00\x00\x01\x94\x12\xd1\xa1\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pL18,40000.0,1000,-500.0,0.0,0.0,0...')])])
21:28:35,905 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02G\xac;m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa1\xc0\x00\x00\x01\x94\x12\xd1\xa1\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pL18,40000.0,1000,-500.0,0.0,0.0,0...')])])
21:28:35,905 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 453: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02G\xac;m\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa1\xc0\x00\x00\x01\x94\x12\xd1\xa1\xc0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pL18,40000.0,1000,-500.0,0.0,0.0,0...')])])
21:28:35,907 <kafka.protocol.parser>[DEBUG]: Received correlation id: 453
21:28:35,908 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:35,908 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 453 (2.99835205078125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=451, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:35,908 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=451, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:35,908 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 451 log start offset 0 and error None.
21:28:35,909 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:36,339 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L35/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:36,342 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:37,352 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L43/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:37,355 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L43,3100.0,100,0.0,0.0,0.0,0.0,False,100.0,14:00:55' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:37,355 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:37,355 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:37,355 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:37,355 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:37,356 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:37,356 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Ba\x0f9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa7k\x00\x00\x01\x94\x12\xd1\xa7k\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL43,3100.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:28:37,356 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Ba\x0f9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa7k\x00\x00\x01\x94\x12\xd1\xa7k\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL43,3100.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:28:37,356 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Ba\x0f9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa7k\x00\x00\x01\x94\x12\xd1\xa7k\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL43,3100.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:28:37,356 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 454: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Ba\x0f9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa7k\x00\x00\x01\x94\x12\xd1\xa7k\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL43,3100.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:28:37,359 <kafka.protocol.parser>[DEBUG]: Received correlation id: 454
21:28:37,360 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:37,360 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 454 (3.9997100830078125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=452, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:37,360 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=452, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:37,360 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 452 log start offset 0 and error None.
21:28:37,362 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:37,647 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L44/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:37,649 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L44,500.0,1000,0.0,0.0,0.0,0.0,False,0.0,13:00:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:37,649 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:37,649 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:37,650 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:37,650 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02}\xd1\xdfu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa8\x91\x00\x00\x01\x94\x12\xd1\xa8\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL44,500.0,1000,0.0,0.0,0.0,0.0,Fa...')])])}
21:28:37,650 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02}\xd1\xdfu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa8\x91\x00\x00\x01\x94\x12\xd1\xa8\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL44,500.0,1000,0.0,0.0,0.0,0.0,Fa...')])])
21:28:37,650 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02}\xd1\xdfu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa8\x91\x00\x00\x01\x94\x12\xd1\xa8\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL44,500.0,1000,0.0,0.0,0.0,0.0,Fa...')])])
21:28:37,651 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 455: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02}\xd1\xdfu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xa8\x91\x00\x00\x01\x94\x12\xd1\xa8\x91\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL44,500.0,1000,0.0,0.0,0.0,0.0,Fa...')])])
21:28:37,652 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:37,652 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:37,654 <kafka.protocol.parser>[DEBUG]: Received correlation id: 455
21:28:37,654 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:37,654 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 455 (2.9981136322021484 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=453, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:37,654 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=453, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:37,655 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 453 log start offset 0 and error None.
21:28:37,656 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:39,60 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L45/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:39,61 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L45,3500.0,500,0.0,0.0,0.0,0.0,False,0.0,14:46:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:39,62 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:39,62 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:39,62 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:39,62 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:39,62 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xab\xac\x92\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xae\x16\x00\x00\x01\x94\x12\xd1\xae\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL45,3500.0,500,0.0,0.0,0.0,0.0,Fa...')])])}
21:28:39,62 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xab\xac\x92\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xae\x16\x00\x00\x01\x94\x12\xd1\xae\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL45,3500.0,500,0.0,0.0,0.0,0.0,Fa...')])])
21:28:39,62 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xab\xac\x92\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xae\x16\x00\x00\x01\x94\x12\xd1\xae\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL45,3500.0,500,0.0,0.0,0.0,0.0,Fa...')])])
21:28:39,63 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:39,63 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 456: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xab\xac\x92\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xae\x16\x00\x00\x01\x94\x12\xd1\xae\x16\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL45,3500.0,500,0.0,0.0,0.0,0.0,Fa...')])])
21:28:39,65 <kafka.protocol.parser>[DEBUG]: Received correlation id: 456
21:28:39,65 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:39,65 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 456 (2.003908157348633 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=454, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:39,66 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=454, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:39,66 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 454 log start offset 0 and error None.
21:28:39,67 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:39,514 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L61/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:39,516 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L61,1300.0,500,0.0,0.0,0.0,0.0,False,0.0,14:58:24' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:39,516 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:39,516 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:39,516 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:39,516 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:39,517 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xea4K(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xaf\xdc\x00\x00\x01\x94\x12\xd1\xaf\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL61,1300.0,500,0.0,0.0,0.0,0.0,Fa...')])])}
21:28:39,516 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:39,517 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xea4K(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xaf\xdc\x00\x00\x01\x94\x12\xd1\xaf\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL61,1300.0,500,0.0,0.0,0.0,0.0,Fa...')])])
21:28:39,517 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xea4K(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xaf\xdc\x00\x00\x01\x94\x12\xd1\xaf\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL61,1300.0,500,0.0,0.0,0.0,0.0,Fa...')])])
21:28:39,517 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 457: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xea4K(\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xaf\xdc\x00\x00\x01\x94\x12\xd1\xaf\xdc\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bL61,1300.0,500,0.0,0.0,0.0,0.0,Fa...')])])
21:28:39,520 <kafka.protocol.parser>[DEBUG]: Received correlation id: 457
21:28:39,520 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:39,520 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 457 (3.001689910888672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=455, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:39,520 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=455, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:39,520 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 455 log start offset 0 and error None.
21:28:39,521 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:41,928 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L62/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:41,930 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L62,3700.0,900,100.0,0.0,0.0,0.0,False,0.0,14:24:35' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:41,930 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:41,930 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:41,930 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:41,931 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:41,931 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa6$\xcct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xb9J\x00\x00\x01\x94\x12\xd1\xb9J\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL62,3700.0,900,100.0,0.0,0.0,0.0,...')])])}
21:28:41,931 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa6$\xcct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xb9J\x00\x00\x01\x94\x12\xd1\xb9J\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL62,3700.0,900,100.0,0.0,0.0,0.0,...')])])
21:28:41,931 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa6$\xcct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xb9J\x00\x00\x01\x94\x12\xd1\xb9J\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL62,3700.0,900,100.0,0.0,0.0,0.0,...')])])
21:28:41,931 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 458: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa6$\xcct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xb9J\x00\x00\x01\x94\x12\xd1\xb9J\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL62,3700.0,900,100.0,0.0,0.0,0.0,...')])])
21:28:41,931 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:41,934 <kafka.protocol.parser>[DEBUG]: Received correlation id: 458
21:28:41,934 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:41,934 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 458 (2.9990673065185547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=456, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:41,934 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=456, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:41,934 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 456 log start offset 0 and error None.
21:28:41,935 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:45,603 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L63/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:45,606 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:48,445 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LAF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:48,535 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LAF,18200.0,100,50.0,0.0,0.0,0.0,False,0.0,14:09:56' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:48,535 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:48,535 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:48,535 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:48,535 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:48,536 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:48,536 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xdem\xe9\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xd3\x17\x00\x00\x01\x94\x12\xd1\xd3\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLAF,18200.0,100,50.0,0.0,0.0,0.0,...')])])}
21:28:48,536 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xdem\xe9\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xd3\x17\x00\x00\x01\x94\x12\xd1\xd3\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLAF,18200.0,100,50.0,0.0,0.0,0.0,...')])])
21:28:48,536 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xdem\xe9\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xd3\x17\x00\x00\x01\x94\x12\xd1\xd3\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLAF,18200.0,100,50.0,0.0,0.0,0.0,...')])])
21:28:48,536 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 459: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xdem\xe9\x14\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xd3\x17\x00\x00\x01\x94\x12\xd1\xd3\x17\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLAF,18200.0,100,50.0,0.0,0.0,0.0,...')])])
21:28:48,539 <kafka.protocol.parser>[DEBUG]: Received correlation id: 459
21:28:48,539 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:48,539 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 459 (2.9768943786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=457, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:48,539 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=457, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:48,539 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 457 log start offset 0 and error None.
21:28:48,541 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:48,844 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LMI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:48,847 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:51,310 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/DKC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:51,312 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:52,966 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LSG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:53,379 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LSG,10200.0,100,0.0,0.0,0.0,0.0,False,100.0,14:54:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:53,379 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:53,379 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:53,379 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:53,379 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:53,379 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc2\x83\xbd\x11\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe6\x03\x00\x00\x01\x94\x12\xd1\xe6\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLSG,10200.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:28:53,380 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc2\x83\xbd\x11\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe6\x03\x00\x00\x01\x94\x12\xd1\xe6\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLSG,10200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:28:53,380 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:53,380 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc2\x83\xbd\x11\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe6\x03\x00\x00\x01\x94\x12\xd1\xe6\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLSG,10200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:28:53,380 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 460: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xc2\x83\xbd\x11\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe6\x03\x00\x00\x01\x94\x12\xd1\xe6\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLSG,10200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:28:53,383 <kafka.protocol.parser>[DEBUG]: Received correlation id: 460
21:28:53,383 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:53,383 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 460 (2.959728240966797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=458, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:53,383 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=458, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:53,383 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 458 log start offset 0 and error None.
21:28:53,385 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:53,701 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:53,703 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LAS,21800.0,48600,-300.0,0.0,0.0,0.0,True,-100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:53,703 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:53,703 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:53,703 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:53,704 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:53,704 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02[\xfc\xf3\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe7G\x00\x00\x01\x94\x12\xd1\xe7G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLAS,21800.0,48600,-300.0,0.0,0.0,...')])])}
21:28:53,704 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02[\xfc\xf3\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe7G\x00\x00\x01\x94\x12\xd1\xe7G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLAS,21800.0,48600,-300.0,0.0,0.0,...')])])
21:28:53,704 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02[\xfc\xf3\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe7G\x00\x00\x01\x94\x12\xd1\xe7G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLAS,21800.0,48600,-300.0,0.0,0.0,...')])])
21:28:53,704 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:53,705 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 461: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02[\xfc\xf3\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xe7G\x00\x00\x01\x94\x12\xd1\xe7G\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLAS,21800.0,48600,-300.0,0.0,0.0,...')])])
21:28:53,706 <kafka.protocol.parser>[DEBUG]: Received correlation id: 461
21:28:53,707 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:53,707 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 461 (2.6025772094726562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=459, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:53,707 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=459, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:53,707 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 459 log start offset 0 and error None.
21:28:53,709 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:55,209 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LAW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:55,211 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:55,508 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:55,509 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:55,825 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LBE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:56,233 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:58,532 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LBM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:58,535 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LBM,28300.0,1700,-250.0,0.0,0.0,0.0,False,0.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:58,535 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:58,535 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:58,535 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:58,535 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:58,536 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfcHA\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xfa'\x00\x00\x01\x94\x12\xd1\xfa'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLBM,28300.0,1700,-250.0,0.0,0.0,0...")])])}
21:28:58,536 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfcHA\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xfa'\x00\x00\x01\x94\x12\xd1\xfa'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLBM,28300.0,1700,-250.0,0.0,0.0,0...")])])
21:28:58,536 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfcHA\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xfa'\x00\x00\x01\x94\x12\xd1\xfa'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLBM,28300.0,1700,-250.0,0.0,0.0,0...")])])
21:28:58,536 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:58,536 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 462: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xfcHA\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xfa'\x00\x00\x01\x94\x12\xd1\xfa'\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLBM,28300.0,1700,-250.0,0.0,0.0,0...")])])
21:28:58,539 <kafka.protocol.parser>[DEBUG]: Received correlation id: 462
21:28:58,539 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:58,539 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 462 (2.999544143676758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=460, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:58,539 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=460, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:58,539 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 460 log start offset 0 and error None.
21:28:58,540 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:28:59,816 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LCC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:28:59,819 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LCC,1600.0,100,200.0,0.1,0.0,0.0,False,400.0,13:16:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:28:59,819 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:28:59,819 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:28:59,819 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:28:59,820 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:28:59,820 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xe4\xf1\xdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xff+\x00\x00\x01\x94\x12\xd1\xff+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLCC,1600.0,100,200.0,0.1,0.0,0.0,...')])])}
21:28:59,820 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xe4\xf1\xdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xff+\x00\x00\x01\x94\x12\xd1\xff+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLCC,1600.0,100,200.0,0.1,0.0,0.0,...')])])
21:28:59,820 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xe4\xf1\xdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xff+\x00\x00\x01\x94\x12\xd1\xff+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLCC,1600.0,100,200.0,0.1,0.0,0.0,...')])])
21:28:59,820 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:28:59,820 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 463: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x8e\xe4\xf1\xdb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd1\xff+\x00\x00\x01\x94\x12\xd1\xff+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLCC,1600.0,100,200.0,0.1,0.0,0.0,...')])])
21:28:59,823 <kafka.protocol.parser>[DEBUG]: Received correlation id: 463
21:28:59,823 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:28:59,823 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 463 (1.9931793212890625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=461, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:59,823 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=461, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:28:59,823 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 461 log start offset 0 and error None.
21:28:59,825 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:00,571 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LCD/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:00,573 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:01,285 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LCG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:01,287 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LCG,10300.0,134300,-150.0,0.0,0.0,0.0,True,-50.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:01,287 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:01,287 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:01,287 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:01,287 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:01,288 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:01,288 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\xfa\x8a\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x04\xe7\x00\x00\x01\x94\x12\xd2\x04\xe7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLCG,10300.0,134300,-150.0,0.0,0.0...')])])}
21:29:01,288 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\xfa\x8a\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x04\xe7\x00\x00\x01\x94\x12\xd2\x04\xe7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLCG,10300.0,134300,-150.0,0.0,0.0...')])])
21:29:01,288 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\xfa\x8a\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x04\xe7\x00\x00\x01\x94\x12\xd2\x04\xe7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLCG,10300.0,134300,-150.0,0.0,0.0...')])])
21:29:01,288 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 464: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02e\xfa\x8a\x9a\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x04\xe7\x00\x00\x01\x94\x12\xd2\x04\xe7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLCG,10300.0,134300,-150.0,0.0,0.0...')])])
21:29:01,290 <kafka.protocol.parser>[DEBUG]: Received correlation id: 464
21:29:01,290 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:01,290 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 464 (2.711057662963867 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=462, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:01,290 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=462, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:01,290 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 462 log start offset 0 and error None.
21:29:01,292 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:01,588 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LQN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:01,591 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:02,695 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:02,698 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LCM,1100.0,1500,100.0,0.1,0.0,0.0,False,0.0,14:55:16' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:02,699 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:02,699 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:02,699 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:02,699 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:02,699 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd7&k2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\nk\x00\x00\x01\x94\x12\xd2\nk\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLCM,1100.0,1500,100.0,0.1,0.0,0.0...')])])}
21:29:02,700 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:02,700 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd7&k2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\nk\x00\x00\x01\x94\x12\xd2\nk\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLCM,1100.0,1500,100.0,0.1,0.0,0.0...')])])
21:29:02,700 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd7&k2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\nk\x00\x00\x01\x94\x12\xd2\nk\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLCM,1100.0,1500,100.0,0.1,0.0,0.0...')])])
21:29:02,700 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 465: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xd7&k2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\nk\x00\x00\x01\x94\x12\xd2\nk\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLCM,1100.0,1500,100.0,0.1,0.0,0.0...')])])
21:29:02,704 <kafka.protocol.parser>[DEBUG]: Received correlation id: 465
21:29:02,704 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:02,705 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 465 (5.00035285949707 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=463, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:02,705 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=463, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:02,705 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 463 log start offset 0 and error None.
21:29:02,708 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:03,5 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LCS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:03,8 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:04,428 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LCW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:04,431 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:04,736 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LWS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:04,738 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:05,105 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LDG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:05,107 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LDG,1890.0,87100,-40.0,0.0,0.0,0.0,False,-20.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:05,107 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:05,107 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:05,107 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:05,108 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:05,108 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~\xcf\x97E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x13\xd3\x00\x00\x01\x94\x12\xd2\x13\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLDG,1890.0,87100,-40.0,0.0,0.0,0....')])])}
21:29:05,108 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:05,109 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~\xcf\x97E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x13\xd3\x00\x00\x01\x94\x12\xd2\x13\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLDG,1890.0,87100,-40.0,0.0,0.0,0....')])])
21:29:05,109 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~\xcf\x97E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x13\xd3\x00\x00\x01\x94\x12\xd2\x13\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLDG,1890.0,87100,-40.0,0.0,0.0,0....')])])
21:29:05,109 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 466: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02~\xcf\x97E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x13\xd3\x00\x00\x01\x94\x12\xd2\x13\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLDG,1890.0,87100,-40.0,0.0,0.0,0....')])])
21:29:05,111 <kafka.protocol.parser>[DEBUG]: Received correlation id: 466
21:29:05,111 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:05,111 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 466 (1.9986629486083984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=464, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:05,112 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=464, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:05,112 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 464 log start offset 0 and error None.
21:29:05,113 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:06,105 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LDP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:06,109 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LDP,10000.0,3400,-100.0,0.0,0.0,0.0,False,0.0,13:14:11' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:06,109 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:06,109 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:06,110 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:06,110 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:06,110 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe0\xec\x87\xe5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x17\xbd\x00\x00\x01\x94\x12\xd2\x17\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLDP,10000.0,3400,-100.0,0.0,0.0,0...')])])}
21:29:06,111 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:06,111 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe0\xec\x87\xe5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x17\xbd\x00\x00\x01\x94\x12\xd2\x17\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLDP,10000.0,3400,-100.0,0.0,0.0,0...')])])
21:29:06,111 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe0\xec\x87\xe5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x17\xbd\x00\x00\x01\x94\x12\xd2\x17\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLDP,10000.0,3400,-100.0,0.0,0.0,0...')])])
21:29:06,111 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 467: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xe0\xec\x87\xe5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x17\xbd\x00\x00\x01\x94\x12\xd2\x17\xbd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLDP,10000.0,3400,-100.0,0.0,0.0,0...')])])
21:29:06,130 <kafka.protocol.parser>[DEBUG]: Received correlation id: 467
21:29:06,130 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:06,130 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 467 (19.133329391479492 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=465, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:06,130 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=465, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:06,130 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 465 log start offset 0 and error None.
21:29:06,132 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:06,497 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LDW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:06,500 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:07,210 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LGM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:07,212 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LGM,13000.0,13000,1600.0,0.1,0.0,0.0,False,-100.0,14:12:20' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:07,213 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:07,213 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:07,213 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:07,213 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:07,213 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02|\xd2\x8eN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1c\r\x00\x00\x01\x94\x12\xd2\x1c\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tLGM,13000.0,13000,1600.0,0.1,0.0...')])])}
21:29:07,213 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02|\xd2\x8eN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1c\r\x00\x00\x01\x94\x12\xd2\x1c\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tLGM,13000.0,13000,1600.0,0.1,0.0...')])])
21:29:07,214 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02|\xd2\x8eN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1c\r\x00\x00\x01\x94\x12\xd2\x1c\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tLGM,13000.0,13000,1600.0,0.1,0.0...')])])
21:29:07,213 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:07,214 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 468: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02|\xd2\x8eN\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1c\r\x00\x00\x01\x94\x12\xd2\x1c\r\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tLGM,13000.0,13000,1600.0,0.1,0.0...')])])
21:29:07,218 <kafka.protocol.parser>[DEBUG]: Received correlation id: 468
21:29:07,218 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:07,218 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 468 (3.9620399475097656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=466, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:07,218 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=466, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:07,218 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 466 log start offset 0 and error None.
21:29:07,220 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:07,550 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LGC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:07,552 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:07,885 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LGL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:07,886 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LGL,2630.0,300,0.0,0.0,0.0,0.0,False,10.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:07,887 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:07,887 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:07,887 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:07,887 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:07,887 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:07,887 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x028\xbc\x18\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1e\xaf\x00\x00\x01\x94\x12\xd2\x1e\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dLGL,2630.0,300,0.0,0.0,0.0,0.0,Fa...')])])}
21:29:07,888 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x028\xbc\x18\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1e\xaf\x00\x00\x01\x94\x12\xd2\x1e\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dLGL,2630.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:29:07,888 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x028\xbc\x18\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1e\xaf\x00\x00\x01\x94\x12\xd2\x1e\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dLGL,2630.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:29:07,888 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 469: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x028\xbc\x18\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x1e\xaf\x00\x00\x01\x94\x12\xd2\x1e\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dLGL,2630.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:29:07,890 <kafka.protocol.parser>[DEBUG]: Received correlation id: 469
21:29:07,890 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:07,890 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 469 (1.9986629486083984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=467, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:07,890 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=467, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:07,891 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 467 log start offset 0 and error None.
21:29:07,892 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:09,401 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:09,403 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LHC,71400.0,2000,0.0,0.0,0.0,0.0,False,900.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:09,403 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:09,404 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:09,404 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:09,404 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:09,404 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xfe-\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2$\x9c\x00\x00\x01\x94\x12\xd2$\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLHC,71400.0,2000,0.0,0.0,0.0,0.0,...')])])}
21:29:09,404 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xfe-\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2$\x9c\x00\x00\x01\x94\x12\xd2$\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLHC,71400.0,2000,0.0,0.0,0.0,0.0,...')])])
21:29:09,404 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xfe-\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2$\x9c\x00\x00\x01\x94\x12\xd2$\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLHC,71400.0,2000,0.0,0.0,0.0,0.0,...')])])
21:29:09,404 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:09,405 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 470: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe4\xfe-\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2$\x9c\x00\x00\x01\x94\x12\xd2$\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLHC,71400.0,2000,0.0,0.0,0.0,0.0,...')])])
21:29:09,407 <kafka.protocol.parser>[DEBUG]: Received correlation id: 470
21:29:09,407 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:09,407 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 470 (2.0105838775634766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=468, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:09,407 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=468, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:09,408 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 468 log start offset 0 and error None.
21:29:09,409 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:10,105 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LHG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:10,107 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LHG,36050.0,40700,-450.0,0.0,0.0,0.0,True,-350.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:10,107 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:10,107 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:10,107 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:10,107 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:10,107 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Q\xc8\xea\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2'[\x00\x00\x01\x94\x12\xd2'[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLHG,36050.0,40700,-450.0,0.0,0.0,...")])])}
21:29:10,108 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Q\xc8\xea\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2'[\x00\x00\x01\x94\x12\xd2'[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLHG,36050.0,40700,-450.0,0.0,0.0,...")])])
21:29:10,108 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:10,108 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Q\xc8\xea\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2'[\x00\x00\x01\x94\x12\xd2'[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLHG,36050.0,40700,-450.0,0.0,0.0,...")])])
21:29:10,108 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 471: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Q\xc8\xea\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2'[\x00\x00\x01\x94\x12\xd2'[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rLHG,36050.0,40700,-450.0,0.0,0.0,...")])])
21:29:10,112 <kafka.protocol.parser>[DEBUG]: Received correlation id: 471
21:29:10,112 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:10,112 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 471 (3.0786991119384766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=469, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:10,112 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=469, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:10,112 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 469 log start offset 0 and error None.
21:29:10,113 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:10,692 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LIC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:10,694 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LIC,34200.0,500,-200.0,0.0,0.0,0.0,False,0.0,13:49:12' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:10,695 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:10,695 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:10,695 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:10,695 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:10,695 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:10,695 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>ip\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2)\xa7\x00\x00\x01\x94\x12\xd2)\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIC,34200.0,500,-200.0,0.0,0.0,0....')])])}
21:29:10,696 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>ip\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2)\xa7\x00\x00\x01\x94\x12\xd2)\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIC,34200.0,500,-200.0,0.0,0.0,0....')])])
21:29:10,696 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>ip\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2)\xa7\x00\x00\x01\x94\x12\xd2)\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIC,34200.0,500,-200.0,0.0,0.0,0....')])])
21:29:10,696 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 472: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02>ip\x13\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2)\xa7\x00\x00\x01\x94\x12\xd2)\xa7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIC,34200.0,500,-200.0,0.0,0.0,0....')])])
21:29:10,698 <kafka.protocol.parser>[DEBUG]: Received correlation id: 472
21:29:10,698 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:10,698 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 472 (1.9931793212890625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=470, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:10,698 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=470, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:10,698 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 470 log start offset 0 and error None.
21:29:10,700 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:11,50 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/L12/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:11,52 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'L12,4400.0,100,0.0,0.0,0.0,0.0,False,300.0,14:56:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:11,52 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:11,52 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:11,53 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:11,53 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:11,53 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Vf\xb1F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2+\x0c\x00\x00\x01\x94\x12\xd2+\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL12,4400.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:29:11,53 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:11,53 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Vf\xb1F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2+\x0c\x00\x00\x01\x94\x12\xd2+\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL12,4400.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:11,54 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Vf\xb1F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2+\x0c\x00\x00\x01\x94\x12\xd2+\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL12,4400.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:11,54 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 473: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Vf\xb1F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2+\x0c\x00\x00\x01\x94\x12\xd2+\x0c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fL12,4400.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:11,56 <kafka.protocol.parser>[DEBUG]: Received correlation id: 473
21:29:11,56 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:11,56 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 473 (2.0012855529785156 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=471, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:11,56 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=471, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:11,56 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 471 log start offset 0 and error None.
21:29:11,59 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:11,382 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LG9/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:11,384 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LG9,7000.0,100,-300.0,0.0,0.0,0.0,False,0.0,13:30:17' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:11,384 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:11,385 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:11,385 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:11,385 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:11,386 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:11,386 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02V\xf9\xa4\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2,Y\x00\x00\x01\x94\x12\xd2,Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLG9,7000.0,100,-300.0,0.0,0.0,0.0...')])])}
21:29:11,386 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02V\xf9\xa4\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2,Y\x00\x00\x01\x94\x12\xd2,Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLG9,7000.0,100,-300.0,0.0,0.0,0.0...')])])
21:29:11,386 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02V\xf9\xa4\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2,Y\x00\x00\x01\x94\x12\xd2,Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLG9,7000.0,100,-300.0,0.0,0.0,0.0...')])])
21:29:11,386 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 474: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02V\xf9\xa4\xe4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2,Y\x00\x00\x01\x94\x12\xd2,Y\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLG9,7000.0,100,-300.0,0.0,0.0,0.0...')])])
21:29:11,389 <kafka.protocol.parser>[DEBUG]: Received correlation id: 474
21:29:11,389 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:11,389 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 474 (2.9854774475097656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=472, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:11,389 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=472, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:11,389 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 472 log start offset 0 and error None.
21:29:11,391 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:12,566 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LIG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:12,569 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LIG,3000.0,25700,0.0,0.0,0.0,0.0,False,100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:12,569 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:12,569 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:12,569 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:12,569 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:12,569 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8}r^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd20\xf9\x00\x00\x01\x94\x12\xd20\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIG,3000.0,25700,0.0,0.0,0.0,0.0,...')])])}
21:29:12,570 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8}r^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd20\xf9\x00\x00\x01\x94\x12\xd20\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIG,3000.0,25700,0.0,0.0,0.0,0.0,...')])])
21:29:12,570 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8}r^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd20\xf9\x00\x00\x01\x94\x12\xd20\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIG,3000.0,25700,0.0,0.0,0.0,0.0,...')])])
21:29:12,570 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:12,570 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 475: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xa8}r^\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd20\xf9\x00\x00\x01\x94\x12\xd20\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLIG,3000.0,25700,0.0,0.0,0.0,0.0,...')])])
21:29:12,573 <kafka.protocol.parser>[DEBUG]: Received correlation id: 475
21:29:12,573 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:12,573 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 475 (2.961397171020508 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=473, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:12,573 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=473, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:12,573 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 473 log start offset 0 and error None.
21:29:12,574 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:12,921 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LLM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:12,923 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LLM,16800.0,100,1000.0,0.1,0.0,0.0,False,0.0,09:27:13' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:12,923 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:12,923 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:12,923 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:12,924 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:12,924 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0fX\xe3\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd22[\x00\x00\x01\x94\x12\xd22[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLLM,16800.0,100,1000.0,0.1,0.0,0....')])])}
21:29:12,924 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0fX\xe3\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd22[\x00\x00\x01\x94\x12\xd22[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLLM,16800.0,100,1000.0,0.1,0.0,0....')])])
21:29:12,924 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0fX\xe3\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd22[\x00\x00\x01\x94\x12\xd22[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLLM,16800.0,100,1000.0,0.1,0.0,0....')])])
21:29:12,924 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 476: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x0fX\xe3\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd22[\x00\x00\x01\x94\x12\xd22[\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jLLM,16800.0,100,1000.0,0.1,0.0,0....')])])
21:29:12,924 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:12,927 <kafka.protocol.parser>[DEBUG]: Received correlation id: 476
21:29:12,927 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:12,927 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 476 (3.123760223388672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=474, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:12,927 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=474, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:12,927 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 474 log start offset 0 and error None.
21:29:12,929 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:13,261 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LAI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:13,262 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LAI,34700.0,500,900.0,0.0,0.0,0.0,False,-300.0,14:37:29' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,262 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,263 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:13,263 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:13,263 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:13,263 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x0ek2\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd23\xaf\x00\x00\x01\x94\x12\xd23\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLAI,34700.0,500,900.0,0.0,0.0,0.0...')])])}
21:29:13,263 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x0ek2\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd23\xaf\x00\x00\x01\x94\x12\xd23\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLAI,34700.0,500,900.0,0.0,0.0,0.0...')])])
21:29:13,263 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x0ek2\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd23\xaf\x00\x00\x01\x94\x12\xd23\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLAI,34700.0,500,900.0,0.0,0.0,0.0...')])])
21:29:13,264 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 477: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x0ek2\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd23\xaf\x00\x00\x01\x94\x12\xd23\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLAI,34700.0,500,900.0,0.0,0.0,0.0...')])])
21:29:13,264 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,266 <kafka.protocol.parser>[DEBUG]: Received correlation id: 477
21:29:13,266 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:13,266 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 477 (1.9965171813964844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=475, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:13,267 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=475, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:13,267 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 475 log start offset 0 and error None.
21:29:13,268 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:13,587 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/AMS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:13,592 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'AMS,9800.0,2100,300.0,0.0,0.0,0.0,False,300.0,14:59:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,593 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,593 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:13,593 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:13,593 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:13,594 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02f\xb5\x83I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd24\xf9\x00\x00\x01\x94\x12\xd24\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAMS,9800.0,2100,300.0,0.0,0.0,0.0...')])])}
21:29:13,594 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,594 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02f\xb5\x83I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd24\xf9\x00\x00\x01\x94\x12\xd24\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAMS,9800.0,2100,300.0,0.0,0.0,0.0...')])])
21:29:13,594 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02f\xb5\x83I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd24\xf9\x00\x00\x01\x94\x12\xd24\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAMS,9800.0,2100,300.0,0.0,0.0,0.0...')])])
21:29:13,594 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 478: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02f\xb5\x83I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd24\xf9\x00\x00\x01\x94\x12\xd24\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lAMS,9800.0,2100,300.0,0.0,0.0,0.0...')])])
21:29:13,627 <kafka.protocol.parser>[DEBUG]: Received correlation id: 478
21:29:13,627 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:13,627 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 478 (32.76824951171875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=476, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:13,627 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=476, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:13,627 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 476 log start offset 0 and error None.
21:29:13,629 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:13,967 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LIX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:13,984 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LIX,33800.0,300,400.0,0.0,0.0,0.0,False,0.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,984 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,984 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:13,984 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:13,984 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:13,984 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:13,984 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x98\x0eZ\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd26\x80\x00\x00\x01\x94\x12\xd26\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLIX,33800.0,300,400.0,0.0,0.0,0.0...')])])}
21:29:13,984 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x98\x0eZ\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd26\x80\x00\x00\x01\x94\x12\xd26\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLIX,33800.0,300,400.0,0.0,0.0,0.0...')])])
21:29:13,984 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x98\x0eZ\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd26\x80\x00\x00\x01\x94\x12\xd26\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLIX,33800.0,300,400.0,0.0,0.0,0.0...')])])
21:29:13,984 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 479: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb5\x98\x0eZ\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd26\x80\x00\x00\x01\x94\x12\xd26\x80\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hLIX,33800.0,300,400.0,0.0,0.0,0.0...')])])
21:29:13,990 <kafka.protocol.parser>[DEBUG]: Received correlation id: 479
21:29:13,990 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:13,990 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 479 (6.029605865478516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=477, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:13,990 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=477, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:13,990 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 477 log start offset 0 and error None.
21:29:13,990 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:14,289 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LKW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:14,291 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:15,290 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LM3/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:15,292 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LM3,3500.0,100,0.0,0.0,0.0,0.0,False,0.0,10:03:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:15,292 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:15,293 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:15,293 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:15,293 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:15,293 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x024\x1d\xf6\xb2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2;\x9c\x00\x00\x01\x94\x12\xd2;\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bLM3,3500.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:29:15,293 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:15,293 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x024\x1d\xf6\xb2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2;\x9c\x00\x00\x01\x94\x12\xd2;\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bLM3,3500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:15,294 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x024\x1d\xf6\xb2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2;\x9c\x00\x00\x01\x94\x12\xd2;\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bLM3,3500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:15,294 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 480: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x024\x1d\xf6\xb2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2;\x9c\x00\x00\x01\x94\x12\xd2;\x9c\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bLM3,3500.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:15,296 <kafka.protocol.parser>[DEBUG]: Received correlation id: 480
21:29:15,296 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:15,296 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 480 (2.014636993408203 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=478, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:15,297 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=478, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:15,297 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 478 log start offset 0 and error None.
21:29:15,298 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:16,108 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LM7/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:16,195 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:16,500 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LM8/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:16,502 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:17,829 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LMH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:17,831 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LMH,900.0,100,0.0,0.0,0.0,0.0,False,0.0,14:43:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:17,831 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:17,831 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:17,832 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:17,832 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xd4\x99\x16\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2E\x87\x00\x00\x01\x94\x12\xd2E\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LMH,900.0,100,0.0,0.0,0.0,0.0,Fal...')])])}
21:29:17,832 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xd4\x99\x16\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2E\x87\x00\x00\x01\x94\x12\xd2E\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LMH,900.0,100,0.0,0.0,0.0,0.0,Fal...')])])
21:29:17,832 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:17,832 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xd4\x99\x16\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2E\x87\x00\x00\x01\x94\x12\xd2E\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LMH,900.0,100,0.0,0.0,0.0,0.0,Fal...')])])
21:29:17,833 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 481: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xd4\x99\x16\x98\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2E\x87\x00\x00\x01\x94\x12\xd2E\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LMH,900.0,100,0.0,0.0,0.0,0.0,Fal...')])])
21:29:17,833 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:17,835 <kafka.protocol.parser>[DEBUG]: Received correlation id: 481
21:29:17,835 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:17,835 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 481 (2.008199691772461 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=479, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:17,836 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=479, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:17,836 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 479 log start offset 0 and error None.
21:29:17,837 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:19,178 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LNC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:19,180 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:19,672 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LO5/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:20,58 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LO5,800.0,2000,100.0,0.1,0.0,0.0,False,0.0,14:37:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,58 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,58 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:20,58 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:20,59 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:20,59 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,59 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xf6\xf8I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2N:\x00\x00\x01\x94\x12\xd2N:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLO5,800.0,2000,100.0,0.1,0.0,0.0,...')])])}
21:29:20,59 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xf6\xf8I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2N:\x00\x00\x01\x94\x12\xd2N:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLO5,800.0,2000,100.0,0.1,0.0,0.0,...')])])
21:29:20,59 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xf6\xf8I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2N:\x00\x00\x01\x94\x12\xd2N:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLO5,800.0,2000,100.0,0.1,0.0,0.0,...')])])
21:29:20,59 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 482: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\x02\xf6\xf8I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2N:\x00\x00\x01\x94\x12\xd2N:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLO5,800.0,2000,100.0,0.1,0.0,0.0,...')])])
21:29:20,62 <kafka.protocol.parser>[DEBUG]: Received correlation id: 482
21:29:20,62 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:20,62 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 482 (1.9872188568115234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=480, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:20,62 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=480, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:20,62 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 480 log start offset 0 and error None.
21:29:20,63 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:20,497 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LSS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:20,499 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LSS,11850.0,32500,-50.0,0.0,0.0,0.0,True,50.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,499 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,499 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:20,499 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:20,500 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:20,500 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9c\x05wH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2O\xf3\x00\x00\x01\x94\x12\xd2O\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLSS,11850.0,32500,-50.0,0.0,0.0,0...')])])}
21:29:20,500 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9c\x05wH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2O\xf3\x00\x00\x01\x94\x12\xd2O\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLSS,11850.0,32500,-50.0,0.0,0.0,0...')])])
21:29:20,500 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,500 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9c\x05wH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2O\xf3\x00\x00\x01\x94\x12\xd2O\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLSS,11850.0,32500,-50.0,0.0,0.0,0...')])])
21:29:20,501 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 483: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9c\x05wH\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2O\xf3\x00\x00\x01\x94\x12\xd2O\xf3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lLSS,11850.0,32500,-50.0,0.0,0.0,0...')])])
21:29:20,503 <kafka.protocol.parser>[DEBUG]: Received correlation id: 483
21:29:20,503 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:20,503 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 483 (1.9869804382324219 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=481, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:20,503 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=481, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:20,504 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 481 log start offset 0 and error None.
21:29:20,505 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:20,830 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LTC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:20,832 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LTC,2100.0,200,200.0,0.1,0.0,0.0,False,0.0,13:47:39' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,832 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,832 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:20,832 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:20,833 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02ES(`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2Q@\x00\x00\x01\x94\x12\xd2Q@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTC,2100.0,200,200.0,0.1,0.0,0.0,...')])])}
21:29:20,833 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:20,833 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02ES(`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2Q@\x00\x00\x01\x94\x12\xd2Q@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTC,2100.0,200,200.0,0.1,0.0,0.0,...')])])
21:29:20,833 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02ES(`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2Q@\x00\x00\x01\x94\x12\xd2Q@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTC,2100.0,200,200.0,0.1,0.0,0.0,...')])])
21:29:20,833 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:20,833 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 484: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02ES(`\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2Q@\x00\x00\x01\x94\x12\xd2Q@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fLTC,2100.0,200,200.0,0.1,0.0,0.0,...')])])
21:29:20,837 <kafka.protocol.parser>[DEBUG]: Received correlation id: 484
21:29:20,837 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:20,837 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 484 (2.9981136322021484 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=482, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:20,837 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=482, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:20,837 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 482 log start offset 0 and error None.
21:29:20,839 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:21,161 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LUT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:21,165 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LUT,600.0,500,0.0,0.0,0.0,0.0,False,0.0,13:49:38' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:21,165 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:21,165 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:21,165 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:21,166 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:21,166 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:21,166 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xcd\xf0z\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2R\x8d\x00\x00\x01\x94\x12\xd2R\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LUT,600.0,500,0.0,0.0,0.0,0.0,Fal...')])])}
21:29:21,166 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xcd\xf0z\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2R\x8d\x00\x00\x01\x94\x12\xd2R\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LUT,600.0,500,0.0,0.0,0.0,0.0,Fal...')])])
21:29:21,167 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xcd\xf0z\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2R\x8d\x00\x00\x01\x94\x12\xd2R\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LUT,600.0,500,0.0,0.0,0.0,0.0,Fal...')])])
21:29:21,167 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 485: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xcd\xf0z\xdc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2R\x8d\x00\x00\x01\x94\x12\xd2R\x8d\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`LUT,600.0,500,0.0,0.0,0.0,0.0,Fal...')])])
21:29:21,170 <kafka.protocol.parser>[DEBUG]: Received correlation id: 485
21:29:21,171 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:21,171 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 485 (4.010438919067383 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=483, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:21,171 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=483, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:21,171 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 483 log start offset 0 and error None.
21:29:21,173 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:21,584 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/LPB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:21,586 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'LPB,31000.0,143300,2000.0,0.1,0.0,0.0,True,0.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:21,587 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:21,587 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:21,587 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:21,587 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:21,587 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:21,587 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc8\xe4\xbbX\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2T3\x00\x00\x01\x94\x12\xd2T3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLPB,31000.0,143300,2000.0,0.1,0.0...')])])}
21:29:21,588 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc8\xe4\xbbX\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2T3\x00\x00\x01\x94\x12\xd2T3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLPB,31000.0,143300,2000.0,0.1,0.0...')])])
21:29:21,588 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc8\xe4\xbbX\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2T3\x00\x00\x01\x94\x12\xd2T3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLPB,31000.0,143300,2000.0,0.1,0.0...')])])
21:29:21,588 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 486: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc8\xe4\xbbX\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2T3\x00\x00\x01\x94\x12\xd2T3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nLPB,31000.0,143300,2000.0,0.1,0.0...')])])
21:29:21,590 <kafka.protocol.parser>[DEBUG]: Received correlation id: 486
21:29:21,590 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:21,590 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 486 (1.9924640655517578 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=484, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:21,590 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=484, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:21,590 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 484 log start offset 0 and error None.
21:29:21,592 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:23,589 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MAC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:23,591 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:23,892 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MA1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:23,894 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:24,192 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:24,194 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MAS,37700.0,300,2200.0,0.1,0.0,0.0,False,4800.0,14:45:00' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:24,194 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:24,194 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:24,194 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:24,195 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:24,195 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:24,195 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc2Z\x02\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2^b\x00\x00\x01\x94\x12\xd2^b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMAS,37700.0,300,2200.0,0.1,0.0,0....')])])}
21:29:24,195 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc2Z\x02\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2^b\x00\x00\x01\x94\x12\xd2^b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMAS,37700.0,300,2200.0,0.1,0.0,0....')])])
21:29:24,195 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc2Z\x02\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2^b\x00\x00\x01\x94\x12\xd2^b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMAS,37700.0,300,2200.0,0.1,0.0,0....')])])
21:29:24,195 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 487: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xc2Z\x02\xbd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2^b\x00\x00\x01\x94\x12\xd2^b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMAS,37700.0,300,2200.0,0.1,0.0,0....')])])
21:29:24,198 <kafka.protocol.parser>[DEBUG]: Received correlation id: 487
21:29:24,198 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:24,198 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 487 (2.001047134399414 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=485, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:24,198 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=485, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:24,198 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 485 log start offset 0 and error None.
21:29:24,200 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:24,585 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MBB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:24,587 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MBB,25050.0,726000,150.0,0.0,0.0,0.0,True,-50.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:24,587 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:24,587 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:24,587 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:24,587 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:24,588 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:24,588 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02F\xa9\xaf\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2_\xeb\x00\x00\x01\x94\x12\xd2_\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMBB,25050.0,726000,150.0,0.0,0.0,...')])])}
21:29:24,588 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02F\xa9\xaf\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2_\xeb\x00\x00\x01\x94\x12\xd2_\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMBB,25050.0,726000,150.0,0.0,0.0,...')])])
21:29:24,588 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02F\xa9\xaf\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2_\xeb\x00\x00\x01\x94\x12\xd2_\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMBB,25050.0,726000,150.0,0.0,0.0,...')])])
21:29:24,588 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 488: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02F\xa9\xaf\xf3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2_\xeb\x00\x00\x01\x94\x12\xd2_\xeb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMBB,25050.0,726000,150.0,0.0,0.0,...')])])
21:29:24,591 <kafka.protocol.parser>[DEBUG]: Received correlation id: 488
21:29:24,591 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:24,591 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 488 (3.0014514923095703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=486, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:24,592 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=486, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:24,592 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 486 log start offset 0 and error None.
21:29:24,593 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:24,890 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:24,892 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:25,267 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:25,269 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MCF,8600.0,200,0.0,0.0,0.0,0.0,False,0.0,14:28:16' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:25,269 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:25,269 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:25,269 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:25,270 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:25,270 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x028.\x80\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2b\x95\x00\x00\x01\x94\x12\xd2b\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMCF,8600.0,200,0.0,0.0,0.0,0.0,Fa...')])])}
21:29:25,270 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x028.\x80\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2b\x95\x00\x00\x01\x94\x12\xd2b\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMCF,8600.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:29:25,270 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:25,270 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x028.\x80\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2b\x95\x00\x00\x01\x94\x12\xd2b\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMCF,8600.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:29:25,271 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 489: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x028.\x80\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2b\x95\x00\x00\x01\x94\x12\xd2b\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMCF,8600.0,200,0.0,0.0,0.0,0.0,Fa...')])])
21:29:25,273 <kafka.protocol.parser>[DEBUG]: Received correlation id: 489
21:29:25,273 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:25,273 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 489 (1.9910335540771484 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=487, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:25,273 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=487, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:25,273 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 487 log start offset 0 and error None.
21:29:25,275 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:25,724 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:25,726 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MCG,1700.0,100,0.0,0.0,0.0,0.0,False,-100.0,13:35:43' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:25,726 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:25,726 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:25,727 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:25,727 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:25,727 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1}\xcdu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2d^\x00\x00\x01\x94\x12\xd2d^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMCG,1700.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:29:25,727 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1}\xcdu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2d^\x00\x00\x01\x94\x12\xd2d^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMCG,1700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:25,727 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1}\xcdu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2d^\x00\x00\x01\x94\x12\xd2d^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMCG,1700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:25,727 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:25,727 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 490: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1}\xcdu\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2d^\x00\x00\x01\x94\x12\xd2d^\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMCG,1700.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:25,730 <kafka.protocol.parser>[DEBUG]: Received correlation id: 490
21:29:25,730 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:25,730 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 490 (1.9910335540771484 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=488, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:25,731 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=488, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:25,731 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 488 log start offset 0 and error None.
21:29:25,732 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:26,226 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:26,228 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MCM,35000.0,2000,150.0,0.0,0.0,0.0,False,-100.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:26,228 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:26,228 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:26,228 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:26,229 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:26,229 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x97\x89:\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2fT\x00\x00\x01\x94\x12\xd2fT\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMCM,35000.0,2000,150.0,0.0,0.0,0....')])])}
21:29:26,229 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x97\x89:\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2fT\x00\x00\x01\x94\x12\xd2fT\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMCM,35000.0,2000,150.0,0.0,0.0,0....')])])
21:29:26,229 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x97\x89:\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2fT\x00\x00\x01\x94\x12\xd2fT\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMCM,35000.0,2000,150.0,0.0,0.0,0....')])])
21:29:26,229 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:26,229 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 491: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x97\x89:\xad\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2fT\x00\x00\x01\x94\x12\xd2fT\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMCM,35000.0,2000,150.0,0.0,0.0,0....')])])
21:29:26,232 <kafka.protocol.parser>[DEBUG]: Received correlation id: 491
21:29:26,232 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:26,233 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 491 (2.9647350311279297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=489, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:26,233 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=489, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:26,233 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 489 log start offset 0 and error None.
21:29:26,235 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:27,898 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCO/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:27,901 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MCO,10300.0,3000,-200.0,0.0,0.0,0.0,False,-100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:27,901 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:27,901 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:27,902 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:27,902 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:27,902 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:27,902 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1e3\xf4\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2l\xdd\x00\x00\x01\x94\x12\xd2l\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMCO,10300.0,3000,-200.0,0.0,0.0,0...')])])}
21:29:27,903 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1e3\xf4\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2l\xdd\x00\x00\x01\x94\x12\xd2l\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMCO,10300.0,3000,-200.0,0.0,0.0,0...')])])
21:29:27,903 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1e3\xf4\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2l\xdd\x00\x00\x01\x94\x12\xd2l\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMCO,10300.0,3000,-200.0,0.0,0.0,0...')])])
21:29:27,903 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 492: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x1e3\xf4\xc5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2l\xdd\x00\x00\x01\x94\x12\xd2l\xdd\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMCO,10300.0,3000,-200.0,0.0,0.0,0...')])])
21:29:27,906 <kafka.protocol.parser>[DEBUG]: Received correlation id: 492
21:29:27,906 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:27,906 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 492 (2.9985904693603516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=490, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:27,906 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=490, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:27,906 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 490 log start offset 0 and error None.
21:29:27,907 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:28,319 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:28,321 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MCP,31400.0,100,0.0,0.0,0.0,0.0,False,0.0,13:22:36' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:28,322 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:28,322 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:28,322 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:28,322 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:28,322 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\t\x89\xed\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2n\x82\x00\x00\x01\x94\x12\xd2n\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMCP,31400.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:29:28,323 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\t\x89\xed\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2n\x82\x00\x00\x01\x94\x12\xd2n\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMCP,31400.0,100,0.0,0.0,0.0,0.0,F...')])])
21:29:28,323 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:28,323 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\t\x89\xed\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2n\x82\x00\x00\x01\x94\x12\xd2n\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMCP,31400.0,100,0.0,0.0,0.0,0.0,F...')])])
21:29:28,323 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 493: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\t\x89\xed\x9f\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2n\x82\x00\x00\x01\x94\x12\xd2n\x82\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMCP,31400.0,100,0.0,0.0,0.0,0.0,F...')])])
21:29:28,325 <kafka.protocol.parser>[DEBUG]: Received correlation id: 493
21:29:28,326 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:28,326 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 493 (2.511739730834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=491, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:28,326 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=491, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:28,326 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 491 log start offset 0 and error None.
21:29:28,327 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:28,632 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MDA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:28,635 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:29,223 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:29,225 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MDC,9900.0,100,0.0,0.0,0.0,0.0,False,0.0,14:23:42' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:29,225 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:29,225 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:29,225 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:29,225 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:29,225 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x84-\x9c\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2r\t\x00\x00\x01\x94\x12\xd2r\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMDC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:29:29,226 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x84-\x9c\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2r\t\x00\x00\x01\x94\x12\xd2r\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMDC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:29,226 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x84-\x9c\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2r\t\x00\x00\x01\x94\x12\xd2r\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMDC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:29,226 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 494: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x84-\x9c\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2r\t\x00\x00\x01\x94\x12\xd2r\t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bMDC,9900.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:29:29,226 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:29,228 <kafka.protocol.parser>[DEBUG]: Received correlation id: 494
21:29:29,228 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:29,228 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 494 (1.9998550415039062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=492, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:29,228 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=492, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:29,228 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 492 log start offset 0 and error None.
21:29:29,230 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:30,510 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MDF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:30,513 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:30,798 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MDG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:30,801 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:31,141 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MEC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:31,143 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MEC,5000.0,100,300.0,0.1,0.0,0.0,False,0.0,09:12:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:31,143 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:31,143 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:31,144 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:31,144 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:31,144 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\xcd\x0bc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2y\x87\x00\x00\x01\x94\x12\xd2y\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEC,5000.0,100,300.0,0.1,0.0,0.0,...')])])}
21:29:31,144 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\xcd\x0bc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2y\x87\x00\x00\x01\x94\x12\xd2y\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEC,5000.0,100,300.0,0.1,0.0,0.0,...')])])
21:29:31,144 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:31,144 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\xcd\x0bc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2y\x87\x00\x00\x01\x94\x12\xd2y\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEC,5000.0,100,300.0,0.1,0.0,0.0,...')])])
21:29:31,145 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 495: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xbf\xcd\x0bc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2y\x87\x00\x00\x01\x94\x12\xd2y\x87\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEC,5000.0,100,300.0,0.1,0.0,0.0,...')])])
21:29:31,147 <kafka.protocol.parser>[DEBUG]: Received correlation id: 495
21:29:31,147 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:31,147 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 495 (1.9817352294921875 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=493, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:31,147 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=493, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:31,148 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 493 log start offset 0 and error None.
21:29:31,149 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:31,437 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MED/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:31,439 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:31,992 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MEF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:31,993 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:33,563 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MEL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:33,648 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MEL,7400.0,100,100.0,0.0,0.0,0.0,False,0.0,09:00:14' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:33,648 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:33,648 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:33,648 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:33,649 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:33,649 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:33,649 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02X\xa9\x9dl\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x83P\x00\x00\x01\x94\x12\xd2\x83P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEL,7400.0,100,100.0,0.0,0.0,0.0,...')])])}
21:29:33,649 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02X\xa9\x9dl\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x83P\x00\x00\x01\x94\x12\xd2\x83P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEL,7400.0,100,100.0,0.0,0.0,0.0,...')])])
21:29:33,649 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02X\xa9\x9dl\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x83P\x00\x00\x01\x94\x12\xd2\x83P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEL,7400.0,100,100.0,0.0,0.0,0.0,...')])])
21:29:33,649 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 496: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02X\xa9\x9dl\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x83P\x00\x00\x01\x94\x12\xd2\x83P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fMEL,7400.0,100,100.0,0.0,0.0,0.0,...')])])
21:29:33,652 <kafka.protocol.parser>[DEBUG]: Received correlation id: 496
21:29:33,652 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:33,652 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 496 (2.967357635498047 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=494, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:33,652 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=494, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:33,653 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 494 log start offset 0 and error None.
21:29:33,654 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:34,893 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MRF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:34,895 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:36,169 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MES/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:36,171 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:36,472 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MFS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:36,474 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MFS,38500.0,100,-1000.0,0.0,0.0,0.0,False,0.0,14:59:40' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:36,474 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:36,474 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:36,475 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:36,475 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:36,475 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:36,475 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbc\x96\xe1\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x8eZ\x00\x00\x01\x94\x12\xd2\x8eZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMFS,38500.0,100,-1000.0,0.0,0.0,0...')])])}
21:29:36,475 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbc\x96\xe1\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x8eZ\x00\x00\x01\x94\x12\xd2\x8eZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMFS,38500.0,100,-1000.0,0.0,0.0,0...')])])
21:29:36,475 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbc\x96\xe1\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x8eZ\x00\x00\x01\x94\x12\xd2\x8eZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMFS,38500.0,100,-1000.0,0.0,0.0,0...')])])
21:29:36,476 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 497: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\xbc\x96\xe1\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x8eZ\x00\x00\x01\x94\x12\xd2\x8eZ\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMFS,38500.0,100,-1000.0,0.0,0.0,0...')])])
21:29:36,478 <kafka.protocol.parser>[DEBUG]: Received correlation id: 497
21:29:36,478 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:36,478 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 497 (2.001047134399414 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=495, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:36,478 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=495, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:36,478 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 495 log start offset 0 and error None.
21:29:36,480 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:38,298 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:38,302 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MHC,6850.0,100,-40.0,0.0,0.0,0.0,False,140.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:38,302 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:38,303 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:38,303 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:38,303 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:38,303 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-.Nv\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x95\x7f\x00\x00\x01\x94\x12\xd2\x95\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMHC,6850.0,100,-40.0,0.0,0.0,0.0,...')])])}
21:29:38,303 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:38,304 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-.Nv\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x95\x7f\x00\x00\x01\x94\x12\xd2\x95\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMHC,6850.0,100,-40.0,0.0,0.0,0.0,...')])])
21:29:38,304 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-.Nv\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x95\x7f\x00\x00\x01\x94\x12\xd2\x95\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMHC,6850.0,100,-40.0,0.0,0.0,0.0,...')])])
21:29:38,305 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 498: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-.Nv\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x95\x7f\x00\x00\x01\x94\x12\xd2\x95\x7f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMHC,6850.0,100,-40.0,0.0,0.0,0.0,...')])])
21:29:38,307 <kafka.protocol.parser>[DEBUG]: Received correlation id: 498
21:29:38,307 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:38,308 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 498 (3.2494068145751953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=496, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:38,308 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=496, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:38,308 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 496 log start offset 0 and error None.
21:29:38,309 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:39,853 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/JOS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:39,855 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'JOS,1100.0,100,100.0,0.1,0.0,0.0,False,100.0,14:51:36' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:39,856 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:39,856 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:39,856 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:39,856 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:39,856 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02d\xb1\xc86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x9b\x90\x00\x00\x01\x94\x12\xd2\x9b\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jJOS,1100.0,100,100.0,0.1,0.0,0.0,...')])])}
21:29:39,857 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:39,857 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02d\xb1\xc86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x9b\x90\x00\x00\x01\x94\x12\xd2\x9b\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jJOS,1100.0,100,100.0,0.1,0.0,0.0,...')])])
21:29:39,857 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02d\xb1\xc86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x9b\x90\x00\x00\x01\x94\x12\xd2\x9b\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jJOS,1100.0,100,100.0,0.1,0.0,0.0,...')])])
21:29:39,857 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 499: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02d\xb1\xc86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\x9b\x90\x00\x00\x01\x94\x12\xd2\x9b\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jJOS,1100.0,100,100.0,0.1,0.0,0.0,...')])])
21:29:39,859 <kafka.protocol.parser>[DEBUG]: Received correlation id: 499
21:29:39,860 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:39,860 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 499 (2.8171539306640625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=497, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:39,860 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=497, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:39,860 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 497 log start offset 0 and error None.
21:29:39,861 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:40,607 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MHL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:40,609 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:40,885 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MIC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:40,887 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:41,206 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MIE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:41,208 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:43,7 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MIM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:43,9 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:43,410 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MIG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:43,412 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MIG,17500.0,48600,-400.0,0.0,0.0,0.0,True,-50.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:43,412 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:43,412 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:43,413 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:43,413 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:43,413 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02_\xd92l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xa9t\x00\x00\x01\x94\x12\xd2\xa9t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMIG,17500.0,48600,-400.0,0.0,0.0,...')])])}
21:29:43,413 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02_\xd92l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xa9t\x00\x00\x01\x94\x12\xd2\xa9t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMIG,17500.0,48600,-400.0,0.0,0.0,...')])])
21:29:43,413 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02_\xd92l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xa9t\x00\x00\x01\x94\x12\xd2\xa9t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMIG,17500.0,48600,-400.0,0.0,0.0,...')])])
21:29:43,413 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:43,413 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 500: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02_\xd92l\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xa9t\x00\x00\x01\x94\x12\xd2\xa9t\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMIG,17500.0,48600,-400.0,0.0,0.0,...')])])
21:29:43,416 <kafka.protocol.parser>[DEBUG]: Received correlation id: 500
21:29:43,416 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:43,416 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 500 (2.0079612731933594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=498, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:43,416 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=498, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:43,417 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 498 log start offset 0 and error None.
21:29:43,418 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:43,760 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MTA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:43,762 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MTA,10500.0,400,-1300.0,-0.1,0.0,0.0,False,0.0,14:59:57' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:43,763 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:43,763 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:43,763 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:43,763 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:43,763 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe6~t\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xaa\xd3\x00\x00\x01\x94\x12\xd2\xaa\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nMTA,10500.0,400,-1300.0,-0.1,0.0,...')])])}
21:29:43,763 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe6~t\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xaa\xd3\x00\x00\x01\x94\x12\xd2\xaa\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nMTA,10500.0,400,-1300.0,-0.1,0.0,...')])])
21:29:43,763 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:43,764 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe6~t\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xaa\xd3\x00\x00\x01\x94\x12\xd2\xaa\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nMTA,10500.0,400,-1300.0,-0.1,0.0,...')])])
21:29:43,764 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 501: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xe6~t\x9b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xaa\xd3\x00\x00\x01\x94\x12\xd2\xaa\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nMTA,10500.0,400,-1300.0,-0.1,0.0,...')])])
21:29:43,766 <kafka.protocol.parser>[DEBUG]: Received correlation id: 501
21:29:43,766 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:43,767 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 501 (3.0019283294677734 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=499, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:43,767 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=499, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:43,768 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 499 log start offset 0 and error None.
21:29:43,769 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:44,113 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MLS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:44,115 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MLS,13400.0,300,0.0,0.0,0.0,0.0,False,-200.0,13:08:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,116 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,116 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:44,117 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:44,117 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:44,117 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x023N\xaa\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xac4\x00\x00\x01\x94\x12\xd2\xac4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMLS,13400.0,300,0.0,0.0,0.0,0.0,F...')])])}
21:29:44,117 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,117 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x023N\xaa\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xac4\x00\x00\x01\x94\x12\xd2\xac4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMLS,13400.0,300,0.0,0.0,0.0,0.0,F...')])])
21:29:44,118 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x023N\xaa\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xac4\x00\x00\x01\x94\x12\xd2\xac4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMLS,13400.0,300,0.0,0.0,0.0,0.0,F...')])])
21:29:44,118 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 502: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x023N\xaa\xca\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xac4\x00\x00\x01\x94\x12\xd2\xac4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMLS,13400.0,300,0.0,0.0,0.0,0.0,F...')])])
21:29:44,123 <kafka.protocol.parser>[DEBUG]: Received correlation id: 502
21:29:44,123 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:44,123 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 502 (4.997730255126953 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=500, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:44,124 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=500, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:44,124 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 500 log start offset 0 and error None.
21:29:44,125 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:44,466 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MKP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:44,468 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MKP,28500.0,100,-100.0,0.0,0.0,0.0,False,0.0,14:27:36' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,468 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,469 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:44,469 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:44,469 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:44,469 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,469 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x98\xd7\xed\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xad\x95\x00\x00\x01\x94\x12\xd2\xad\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKP,28500.0,100,-100.0,0.0,0.0,0....')])])}
21:29:44,469 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x98\xd7\xed\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xad\x95\x00\x00\x01\x94\x12\xd2\xad\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKP,28500.0,100,-100.0,0.0,0.0,0....')])])
21:29:44,470 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x98\xd7\xed\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xad\x95\x00\x00\x01\x94\x12\xd2\xad\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKP,28500.0,100,-100.0,0.0,0.0,0....')])])
21:29:44,470 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 503: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x98\xd7\xed\x99\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xad\x95\x00\x00\x01\x94\x12\xd2\xad\x95\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKP,28500.0,100,-100.0,0.0,0.0,0....')])])
21:29:44,472 <kafka.protocol.parser>[DEBUG]: Received correlation id: 503
21:29:44,472 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:44,472 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 503 (1.9998550415039062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=501, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:44,472 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=501, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:44,472 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 501 log start offset 0 and error None.
21:29:44,473 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:44,803 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MKV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:44,805 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MKV,9800.0,100,300.0,0.0,0.0,0.0,False,700.0,13:09:28' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,805 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,806 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:44,806 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:44,806 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:44,806 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02g\x1f-d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xae\xe6\x00\x00\x01\x94\x12\xd2\xae\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKV,9800.0,100,300.0,0.0,0.0,0.0,...')])])}
21:29:44,806 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02g\x1f-d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xae\xe6\x00\x00\x01\x94\x12\xd2\xae\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKV,9800.0,100,300.0,0.0,0.0,0.0,...')])])
21:29:44,806 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:44,806 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02g\x1f-d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xae\xe6\x00\x00\x01\x94\x12\xd2\xae\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKV,9800.0,100,300.0,0.0,0.0,0.0,...')])])
21:29:44,807 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 504: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02g\x1f-d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xae\xe6\x00\x00\x01\x94\x12\xd2\xae\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jMKV,9800.0,100,300.0,0.0,0.0,0.0,...')])])
21:29:44,809 <kafka.protocol.parser>[DEBUG]: Received correlation id: 504
21:29:44,809 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:44,809 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 504 (1.9881725311279297 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=502, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:44,809 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=502, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:44,809 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 502 log start offset 0 and error None.
21:29:44,811 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:45,538 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MLC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:45,634 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:46,231 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MML/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:46,234 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MML,24400.0,100,1300.0,0.1,0.0,0.0,False,-200.0,14:58:56' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:46,234 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:46,234 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:46,234 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:46,235 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x92\xdc\xe0o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xb4z\x00\x00\x01\x94\x12\xd2\xb4z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMML,24400.0,100,1300.0,0.1,0.0,0....')])])}
21:29:46,235 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x92\xdc\xe0o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xb4z\x00\x00\x01\x94\x12\xd2\xb4z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMML,24400.0,100,1300.0,0.1,0.0,0....')])])
21:29:46,234 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:46,235 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x92\xdc\xe0o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xb4z\x00\x00\x01\x94\x12\xd2\xb4z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMML,24400.0,100,1300.0,0.1,0.0,0....')])])
21:29:46,236 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 505: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x92\xdc\xe0o\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xb4z\x00\x00\x01\x94\x12\xd2\xb4z\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMML,24400.0,100,1300.0,0.1,0.0,0....')])])
21:29:46,236 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:46,237 <kafka.protocol.parser>[DEBUG]: Received correlation id: 505
21:29:46,238 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:46,238 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 505 (2.3717880249023438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=503, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:46,238 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=503, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:46,238 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 503 log start offset 0 and error None.
21:29:46,240 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:46,990 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MPC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:47,718 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MPC,15200.0,500,100.0,0.0,0.0,0.0,False,200.0,14:59:09' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:47,719 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:47,719 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:47,719 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:47,719 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:47,719 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02vHs\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbaG\x00\x00\x01\x94\x12\xd2\xbaG\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMPC,15200.0,500,100.0,0.0,0.0,0.0...')])])}
21:29:47,720 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:47,720 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02vHs\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbaG\x00\x00\x01\x94\x12\xd2\xbaG\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMPC,15200.0,500,100.0,0.0,0.0,0.0...')])])
21:29:47,720 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02vHs\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbaG\x00\x00\x01\x94\x12\xd2\xbaG\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMPC,15200.0,500,100.0,0.0,0.0,0.0...')])])
21:29:47,720 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 506: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02vHs\x89\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbaG\x00\x00\x01\x94\x12\xd2\xbaG\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMPC,15200.0,500,100.0,0.0,0.0,0.0...')])])
21:29:47,722 <kafka.protocol.parser>[DEBUG]: Received correlation id: 506
21:29:47,723 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:47,723 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 506 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=504, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:47,723 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=504, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:47,723 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 504 log start offset 0 and error None.
21:29:47,725 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:48,23 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MPT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:48,419 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MPT,600.0,100,0.0,0.0,0.0,0.0,False,0.0,14:21:22' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:48,419 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:48,419 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:48,419 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:48,419 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:48,420 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xc1\xd1B\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbd\x03\x00\x00\x01\x94\x12\xd2\xbd\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`MPT,600.0,100,0.0,0.0,0.0,0.0,Fal...')])])}
21:29:48,420 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xc1\xd1B\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbd\x03\x00\x00\x01\x94\x12\xd2\xbd\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`MPT,600.0,100,0.0,0.0,0.0,0.0,Fal...')])])
21:29:48,420 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:48,420 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xc1\xd1B\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbd\x03\x00\x00\x01\x94\x12\xd2\xbd\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`MPT,600.0,100,0.0,0.0,0.0,0.0,Fal...')])])
21:29:48,420 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 507: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\xc1\xd1B\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xbd\x03\x00\x00\x01\x94\x12\xd2\xbd\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`MPT,600.0,100,0.0,0.0,0.0,0.0,Fal...')])])
21:29:48,422 <kafka.protocol.parser>[DEBUG]: Received correlation id: 507
21:29:48,423 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:48,423 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 507 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=505, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:48,423 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=505, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:48,423 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 505 log start offset 0 and error None.
21:29:48,424 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:49,154 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MPY/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:49,155 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:49,714 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MQB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:49,716 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:50,187 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MSB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:50,189 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MSB,11700.0,348600,150.0,0.0,0.0,0.0,True,0.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:50,189 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:50,189 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:50,190 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:50,190 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02SH\x8f0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc3\xed\x00\x00\x01\x94\x12\xd2\xc3\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMSB,11700.0,348600,150.0,0.0,0.0,...')])])}
21:29:50,190 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02SH\x8f0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc3\xed\x00\x00\x01\x94\x12\xd2\xc3\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMSB,11700.0,348600,150.0,0.0,0.0,...')])])
21:29:50,190 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:50,190 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02SH\x8f0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc3\xed\x00\x00\x01\x94\x12\xd2\xc3\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMSB,11700.0,348600,150.0,0.0,0.0,...')])])
21:29:50,190 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 508: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02SH\x8f0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc3\xed\x00\x00\x01\x94\x12\xd2\xc3\xed\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMSB,11700.0,348600,150.0,0.0,0.0,...')])])
21:29:50,191 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:50,192 <kafka.protocol.parser>[DEBUG]: Received correlation id: 508
21:29:50,192 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:50,193 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 508 (3.0007362365722656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=506, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:50,193 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=506, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:50,193 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 506 log start offset 0 and error None.
21:29:50,194 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:50,521 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MCH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:50,523 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MCH,236500.0,3000,4700.0,0.0,0.0,0.0,True,0.0,14:59:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:50,523 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:50,523 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:50,523 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:50,524 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:50,524 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022f\x97\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc5;\x00\x00\x01\x94\x12\xd2\xc5;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMCH,236500.0,3000,4700.0,0.0,0.0,...')])])}
21:29:50,524 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022f\x97\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc5;\x00\x00\x01\x94\x12\xd2\xc5;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMCH,236500.0,3000,4700.0,0.0,0.0,...')])])
21:29:50,524 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022f\x97\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc5;\x00\x00\x01\x94\x12\xd2\xc5;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMCH,236500.0,3000,4700.0,0.0,0.0,...')])])
21:29:50,524 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 509: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x022f\x97\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc5;\x00\x00\x01\x94\x12\xd2\xc5;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lMCH,236500.0,3000,4700.0,0.0,0.0,...')])])
21:29:50,525 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:50,527 <kafka.protocol.parser>[DEBUG]: Received correlation id: 509
21:29:50,527 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:50,527 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 509 (2.9671192169189453 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=507, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:50,527 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=507, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:50,528 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 507 log start offset 0 and error None.
21:29:50,529 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:51,223 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MSN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:51,224 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MSN,70400.0,348300,-100.0,0.0,0.0,0.0,True,-200.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:51,225 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:51,225 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:51,225 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:51,225 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02G\xda\x82\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc7\xf9\x00\x00\x01\x94\x12\xd2\xc7\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tMSN,70400.0,348300,-100.0,0.0,0....')])])}
21:29:51,225 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02G\xda\x82\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc7\xf9\x00\x00\x01\x94\x12\xd2\xc7\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tMSN,70400.0,348300,-100.0,0.0,0....')])])
21:29:51,226 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02G\xda\x82\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc7\xf9\x00\x00\x01\x94\x12\xd2\xc7\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tMSN,70400.0,348300,-100.0,0.0,0....')])])
21:29:51,225 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:51,226 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 510: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02G\xda\x82\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc7\xf9\x00\x00\x01\x94\x12\xd2\xc7\xf9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tMSN,70400.0,348300,-100.0,0.0,0....')])])
21:29:51,226 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:51,228 <kafka.protocol.parser>[DEBUG]: Received correlation id: 510
21:29:51,228 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:51,229 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 510 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=508, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:51,229 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=508, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:51,229 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 508 log start offset 0 and error None.
21:29:51,230 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:51,659 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MSR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:51,661 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MSR,12000.0,2000,-600.0,0.0,0.0,0.0,False,100.0,14:59:22' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:51,661 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:51,661 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:51,661 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:51,661 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:51,662 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa5\xe9\xad\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc9\xad\x00\x00\x01\x94\x12\xd2\xc9\xad\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMSR,12000.0,2000,-600.0,0.0,0.0,0...')])])}
21:29:51,662 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa5\xe9\xad\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc9\xad\x00\x00\x01\x94\x12\xd2\xc9\xad\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMSR,12000.0,2000,-600.0,0.0,0.0,0...')])])
21:29:51,662 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa5\xe9\xad\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc9\xad\x00\x00\x01\x94\x12\xd2\xc9\xad\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMSR,12000.0,2000,-600.0,0.0,0.0,0...')])])
21:29:51,662 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:51,662 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 511: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa5\xe9\xad\x94\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xc9\xad\x00\x00\x01\x94\x12\xd2\xc9\xad\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pMSR,12000.0,2000,-600.0,0.0,0.0,0...')])])
21:29:51,664 <kafka.protocol.parser>[DEBUG]: Received correlation id: 511
21:29:51,665 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:51,665 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 511 (2.4056434631347656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=509, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:51,665 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=509, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:51,665 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 509 log start offset 0 and error None.
21:29:51,667 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:52,574 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MST/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:52,576 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MST,6700.0,260700,-200.0,0.0,0.0,0.0,True,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:52,577 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:52,577 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:52,577 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:52,577 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:52,577 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X{[\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xcdA\x00\x00\x01\x94\x12\xd2\xcdA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMST,6700.0,260700,-200.0,0.0,0.0,...')])])}
21:29:52,578 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X{[\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xcdA\x00\x00\x01\x94\x12\xd2\xcdA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMST,6700.0,260700,-200.0,0.0,0.0,...')])])
21:29:52,578 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X{[\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xcdA\x00\x00\x01\x94\x12\xd2\xcdA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMST,6700.0,260700,-200.0,0.0,0.0,...')])])
21:29:52,577 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:52,578 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 512: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X{[\xbc\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xcdA\x00\x00\x01\x94\x12\xd2\xcdA\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rMST,6700.0,260700,-200.0,0.0,0.0,...')])])
21:29:52,580 <kafka.protocol.parser>[DEBUG]: Received correlation id: 512
21:29:52,581 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:52,581 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 512 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=510, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:52,581 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=510, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:52,581 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 510 log start offset 0 and error None.
21:29:52,582 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:53,884 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MTC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:53,886 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:54,428 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MTG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:54,430 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:54,849 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MTH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:54,852 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:55,783 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MTL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:55,785 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MTL,5200.0,1100,100.0,0.0,0.0,0.0,False,0.0,13:23:21' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:55,785 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:55,785 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:55,786 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:55,786 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:55,786 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02E\xa7(\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xd9\xc9\x00\x00\x01\x94\x12\xd2\xd9\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMTL,5200.0,1100,100.0,0.0,0.0,0.0...')])])}
21:29:55,786 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02E\xa7(\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xd9\xc9\x00\x00\x01\x94\x12\xd2\xd9\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMTL,5200.0,1100,100.0,0.0,0.0,0.0...')])])
21:29:55,786 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:55,787 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02E\xa7(\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xd9\xc9\x00\x00\x01\x94\x12\xd2\xd9\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMTL,5200.0,1100,100.0,0.0,0.0,0.0...')])])
21:29:55,787 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 513: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02E\xa7(\xc1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xd9\xc9\x00\x00\x01\x94\x12\xd2\xd9\xc9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hMTL,5200.0,1100,100.0,0.0,0.0,0.0...')])])
21:29:55,790 <kafka.protocol.parser>[DEBUG]: Received correlation id: 513
21:29:55,790 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:55,790 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 513 (2.9969215393066406 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=511, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:55,790 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=511, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:55,790 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 511 log start offset 0 and error None.
21:29:55,792 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:56,87 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAU/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:56,89 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:57,731 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MTP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:57,732 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MTP,12500.0,100,0.0,0.0,0.0,0.0,False,0.0,14:33:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:57,733 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:57,733 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:57,733 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:57,733 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:57,733 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:57,733 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5_\x8c-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe1e\x00\x00\x01\x94\x12\xd2\xe1e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMTP,12500.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:29:57,734 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5_\x8c-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe1e\x00\x00\x01\x94\x12\xd2\xe1e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMTP,12500.0,100,0.0,0.0,0.0,0.0,F...')])])
21:29:57,734 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5_\x8c-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe1e\x00\x00\x01\x94\x12\xd2\xe1e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMTP,12500.0,100,0.0,0.0,0.0,0.0,F...')])])
21:29:57,734 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 514: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xa5_\x8c-\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe1e\x00\x00\x01\x94\x12\xd2\xe1e\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dMTP,12500.0,100,0.0,0.0,0.0,0.0,F...')])])
21:29:57,737 <kafka.protocol.parser>[DEBUG]: Received correlation id: 514
21:29:57,737 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:57,737 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 514 (2.7055740356445312 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=512, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:57,737 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=512, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:57,737 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 512 log start offset 0 and error None.
21:29:57,738 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:59,102 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MWG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:59,104 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'MWG,61400.0,1282900,-100.0,0.0,0.0,0.0,True,-200.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:59,104 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:59,105 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:59,105 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:59,105 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:59,105 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02i]\xe7T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe6\xc1\x00\x00\x01\x94\x12\xd2\xe6\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vMWG,61400.0,1282900,-100.0,0.0,0...')])])}
21:29:59,105 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02i]\xe7T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe6\xc1\x00\x00\x01\x94\x12\xd2\xe6\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vMWG,61400.0,1282900,-100.0,0.0,0...')])])
21:29:59,106 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:59,106 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02i]\xe7T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe6\xc1\x00\x00\x01\x94\x12\xd2\xe6\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vMWG,61400.0,1282900,-100.0,0.0,0...')])])
21:29:59,106 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 515: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02i]\xe7T\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe6\xc1\x00\x00\x01\x94\x12\xd2\xe6\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vMWG,61400.0,1282900,-100.0,0.0,0...')])])
21:29:59,108 <kafka.protocol.parser>[DEBUG]: Received correlation id: 515
21:29:59,109 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:59,109 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 515 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=513, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:59,109 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=513, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:59,109 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 513 log start offset 0 and error None.
21:29:59,110 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:29:59,853 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:29:59,855 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NAB,16050.0,2528700,100.0,0.0,0.0,0.0,True,50.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:29:59,855 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:29:59,855 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:29:59,855 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:29:59,855 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:29:59,856 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:29:59,856 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87)\xfe\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe9\xaf\x00\x00\x01\x94\x12\xd2\xe9\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNAB,16050.0,2528700,100.0,0.0,0.0...')])])}
21:29:59,856 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87)\xfe\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe9\xaf\x00\x00\x01\x94\x12\xd2\xe9\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNAB,16050.0,2528700,100.0,0.0,0.0...')])])
21:29:59,856 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87)\xfe\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe9\xaf\x00\x00\x01\x94\x12\xd2\xe9\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNAB,16050.0,2528700,100.0,0.0,0.0...')])])
21:29:59,856 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 516: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x87)\xfe\xb8\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xe9\xaf\x00\x00\x01\x94\x12\xd2\xe9\xaf\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNAB,16050.0,2528700,100.0,0.0,0.0...')])])
21:29:59,858 <kafka.protocol.parser>[DEBUG]: Received correlation id: 516
21:29:59,858 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:29:59,858 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 516 (2.0029544830322266 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=514, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:59,859 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=514, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:29:59,859 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 514 log start offset 0 and error None.
21:29:59,860 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:00,274 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NDP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:00,276 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:00,569 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:00,571 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NAF,19850.0,11900,-150.0,0.0,0.0,0.0,True,0.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:00,571 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:00,571 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:00,571 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:00,572 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:00,572 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02>\x98\x87S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xec{\x00\x00\x01\x94\x12\xd2\xec{\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNAF,19850.0,11900,-150.0,0.0,0.0,...')])])}
21:30:00,572 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02>\x98\x87S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xec{\x00\x00\x01\x94\x12\xd2\xec{\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNAF,19850.0,11900,-150.0,0.0,0.0,...')])])
21:30:00,572 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02>\x98\x87S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xec{\x00\x00\x01\x94\x12\xd2\xec{\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNAF,19850.0,11900,-150.0,0.0,0.0,...')])])
21:30:00,572 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:00,572 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 517: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02>\x98\x87S\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xec{\x00\x00\x01\x94\x12\xd2\xec{\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNAF,19850.0,11900,-150.0,0.0,0.0,...')])])
21:30:00,575 <kafka.protocol.parser>[DEBUG]: Received correlation id: 517
21:30:00,575 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:00,575 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 517 (3.004312515258789 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=515, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:00,575 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=515, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:00,575 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 515 log start offset 0 and error None.
21:30:00,577 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:01,463 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:01,523 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NAG,11000.0,54000,0.0,0.0,0.0,0.0,True,100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:01,523 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:01,523 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:01,523 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:01,524 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:01,524 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xaa]\x0b\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xf03\x00\x00\x01\x94\x12\xd2\xf03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAG,11000.0,54000,0.0,0.0,0.0,0.0...')])])}
21:30:01,524 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xaa]\x0b\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xf03\x00\x00\x01\x94\x12\xd2\xf03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAG,11000.0,54000,0.0,0.0,0.0,0.0...')])])
21:30:01,524 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:01,524 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xaa]\x0b\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xf03\x00\x00\x01\x94\x12\xd2\xf03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAG,11000.0,54000,0.0,0.0,0.0,0.0...')])])
21:30:01,524 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 518: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xaa]\x0b\xe7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xf03\x00\x00\x01\x94\x12\xd2\xf03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAG,11000.0,54000,0.0,0.0,0.0,0.0...')])])
21:30:01,527 <kafka.protocol.parser>[DEBUG]: Received correlation id: 518
21:30:01,527 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:01,528 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 518 (2.445220947265625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=516, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:01,528 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=516, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:01,528 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 516 log start offset 0 and error None.
21:30:01,529 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:01,858 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NJC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:01,860 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:02,577 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:02,579 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:02,947 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/FHN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:02,950 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:03,600 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:03,602 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:03,907 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NTF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:03,909 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:04,239 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/BAB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:04,241 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'BAB,11900.0,400,0.0,0.0,0.0,0.0,False,0.0,14:21:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,241 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,241 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:04,242 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:04,242 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:04,242 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,242 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xd9L\x7f$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfa\xd1\x00\x00\x01\x94\x12\xd2\xfa\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBAB,11900.0,400,0.0,0.0,0.0,0.0,F...')])])}
21:30:04,242 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xd9L\x7f$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfa\xd1\x00\x00\x01\x94\x12\xd2\xfa\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBAB,11900.0,400,0.0,0.0,0.0,0.0,F...')])])
21:30:04,242 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xd9L\x7f$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfa\xd1\x00\x00\x01\x94\x12\xd2\xfa\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBAB,11900.0,400,0.0,0.0,0.0,0.0,F...')])])
21:30:04,243 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 519: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xd9L\x7f$\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfa\xd1\x00\x00\x01\x94\x12\xd2\xfa\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dBAB,11900.0,400,0.0,0.0,0.0,0.0,F...')])])
21:30:04,245 <kafka.protocol.parser>[DEBUG]: Received correlation id: 519
21:30:04,245 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:04,245 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 519 (1.9998550415039062 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=517, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:04,245 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=517, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:04,245 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 517 log start offset 0 and error None.
21:30:04,247 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:04,565 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:04,568 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NAS,30000.0,500,-3100.0,-0.1,0.0,0.0,False,-1000.0,14:31:21' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,568 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,568 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:04,569 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:04,569 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc5\xe3\xba\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfc\x18\x00\x00\x01\x94\x12\xd2\xfc\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vNAS,30000.0,500,-3100.0,-0.1,0.0...')])])}
21:30:04,569 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc5\xe3\xba\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfc\x18\x00\x00\x01\x94\x12\xd2\xfc\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vNAS,30000.0,500,-3100.0,-0.1,0.0...')])])
21:30:04,569 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:04,569 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc5\xe3\xba\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfc\x18\x00\x00\x01\x94\x12\xd2\xfc\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vNAS,30000.0,500,-3100.0,-0.1,0.0...')])])
21:30:04,570 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,570 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 520: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02\xc5\xe3\xba\x8b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfc\x18\x00\x00\x01\x94\x12\xd2\xfc\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vNAS,30000.0,500,-3100.0,-0.1,0.0...')])])
21:30:04,573 <kafka.protocol.parser>[DEBUG]: Received correlation id: 520
21:30:04,574 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:04,574 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 520 (3.924846649169922 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=518, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:04,574 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=518, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:04,574 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 518 log start offset 0 and error None.
21:30:04,576 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:04,937 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:04,938 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NAV,19250.0,200,-100.0,0.0,0.0,0.0,False,0.0,13:53:50' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,939 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,939 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:04,939 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:04,939 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:04,940 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\x80\xe4R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfd\x8b\x00\x00\x01\x94\x12\xd2\xfd\x8b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAV,19250.0,200,-100.0,0.0,0.0,0....')])])}
21:30:04,940 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\x80\xe4R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfd\x8b\x00\x00\x01\x94\x12\xd2\xfd\x8b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAV,19250.0,200,-100.0,0.0,0.0,0....')])])
21:30:04,940 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\x80\xe4R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfd\x8b\x00\x00\x01\x94\x12\xd2\xfd\x8b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAV,19250.0,200,-100.0,0.0,0.0,0....')])])
21:30:04,941 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 521: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02_\x80\xe4R\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfd\x8b\x00\x00\x01\x94\x12\xd2\xfd\x8b\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNAV,19250.0,200,-100.0,0.0,0.0,0....')])])
21:30:04,940 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:04,943 <kafka.protocol.parser>[DEBUG]: Received correlation id: 521
21:30:04,943 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:04,943 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 521 (1.9996166229248047 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=519, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:04,943 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=519, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:04,944 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 519 log start offset 0 and error None.
21:30:04,945 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:05,265 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VET/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:05,267 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'VET,17700.0,1900,0.0,0.0,0.0,0.0,False,0.0,09:15:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:05,267 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:05,267 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:05,268 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:05,268 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa3\xa4\x8a\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfe\xd3\x00\x00\x01\x94\x12\xd2\xfe\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVET,17700.0,1900,0.0,0.0,0.0,0.0,...')])])}
21:30:05,268 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa3\xa4\x8a\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfe\xd3\x00\x00\x01\x94\x12\xd2\xfe\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVET,17700.0,1900,0.0,0.0,0.0,0.0,...')])])
21:30:05,268 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:05,268 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa3\xa4\x8a\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfe\xd3\x00\x00\x01\x94\x12\xd2\xfe\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVET,17700.0,1900,0.0,0.0,0.0,0.0,...')])])
21:30:05,268 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 522: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xa3\xa4\x8a\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd2\xfe\xd3\x00\x00\x01\x94\x12\xd2\xfe\xd3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fVET,17700.0,1900,0.0,0.0,0.0,0.0,...')])])
21:30:05,268 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:05,270 <kafka.protocol.parser>[DEBUG]: Received correlation id: 522
21:30:05,271 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:05,271 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 522 (3.0014514923095703 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=520, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:05,271 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=520, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:05,271 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 520 log start offset 0 and error None.
21:30:05,272 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:05,556 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NAW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:05,558 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:06,229 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NBB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:06,231 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NBB,23000.0,10000,800.0,0.0,0.0,0.0,True,600.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:06,231 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:06,231 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:06,231 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:06,232 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:06,232 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x7f,%\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x02\x97\x00\x00\x01\x94\x12\xd3\x02\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNBB,23000.0,10000,800.0,0.0,0.0,0...')])])}
21:30:06,232 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x7f,%\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x02\x97\x00\x00\x01\x94\x12\xd3\x02\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNBB,23000.0,10000,800.0,0.0,0.0,0...')])])
21:30:06,232 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x7f,%\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x02\x97\x00\x00\x01\x94\x12\xd3\x02\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNBB,23000.0,10000,800.0,0.0,0.0,0...')])])
21:30:06,232 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 523: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x7f,%\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x02\x97\x00\x00\x01\x94\x12\xd3\x02\x97\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNBB,23000.0,10000,800.0,0.0,0.0,0...')])])
21:30:06,232 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:06,235 <kafka.protocol.parser>[DEBUG]: Received correlation id: 523
21:30:06,235 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:06,235 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 523 (3.000020980834961 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=521, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:06,235 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=521, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:06,235 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 521 log start offset 0 and error None.
21:30:06,237 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:07,171 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NBC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:07,173 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NBC,9300.0,3000,-100.0,0.0,0.0,0.0,False,-100.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:07,173 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:07,173 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:07,174 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:07,174 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:07,174 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9-g\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x06E\x00\x00\x01\x94\x12\xd3\x06E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNBC,9300.0,3000,-100.0,0.0,0.0,0....')])])}
21:30:07,174 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:07,175 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9-g\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x06E\x00\x00\x01\x94\x12\xd3\x06E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNBC,9300.0,3000,-100.0,0.0,0.0,0....')])])
21:30:07,175 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9-g\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x06E\x00\x00\x01\x94\x12\xd3\x06E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNBC,9300.0,3000,-100.0,0.0,0.0,0....')])])
21:30:07,175 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 524: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\xa9-g\\\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x06E\x00\x00\x01\x94\x12\xd3\x06E\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNBC,9300.0,3000,-100.0,0.0,0.0,0....')])])
21:30:07,177 <kafka.protocol.parser>[DEBUG]: Received correlation id: 524
21:30:07,177 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:07,177 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 524 (2.003192901611328 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=522, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:07,178 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=522, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:07,178 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 522 log start offset 0 and error None.
21:30:07,179 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:08,830 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NBE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:08,833 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NBE,12600.0,400,100.0,0.0,0.0,0.0,False,100.0,14:46:52' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:08,834 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:08,834 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:08,834 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:08,835 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:08,835 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02:}\xff_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x0c\xc2\x00\x00\x01\x94\x12\xd3\x0c\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNBE,12600.0,400,100.0,0.0,0.0,0.0...')])])}
21:30:08,836 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:08,836 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02:}\xff_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x0c\xc2\x00\x00\x01\x94\x12\xd3\x0c\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNBE,12600.0,400,100.0,0.0,0.0,0.0...')])])
21:30:08,836 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02:}\xff_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x0c\xc2\x00\x00\x01\x94\x12\xd3\x0c\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNBE,12600.0,400,100.0,0.0,0.0,0.0...')])])
21:30:08,836 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 525: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02:}\xff_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x0c\xc2\x00\x00\x01\x94\x12\xd3\x0c\xc2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNBE,12600.0,400,100.0,0.0,0.0,0.0...')])])
21:30:08,839 <kafka.protocol.parser>[DEBUG]: Received correlation id: 525
21:30:08,840 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:08,840 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 525 (3.9992332458496094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=523, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:08,840 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=523, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:08,840 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 523 log start offset 0 and error None.
21:30:08,842 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:09,175 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NBP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:09,177 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:09,494 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NBW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:09,497 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:09,823 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NCS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:09,827 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NCS,26300.0,500,0.0,0.0,0.0,0.0,False,0.0,11:04:20' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:09,827 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:09,827 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:09,827 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:09,828 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:09,828 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:09,828 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ss\x1e\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x10\xa3\x00\x00\x01\x94\x12\xd3\x10\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNCS,26300.0,500,0.0,0.0,0.0,0.0,F...')])])}
21:30:09,829 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ss\x1e\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x10\xa3\x00\x00\x01\x94\x12\xd3\x10\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNCS,26300.0,500,0.0,0.0,0.0,0.0,F...')])])
21:30:09,829 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ss\x1e\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x10\xa3\x00\x00\x01\x94\x12\xd3\x10\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNCS,26300.0,500,0.0,0.0,0.0,0.0,F...')])])
21:30:09,829 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 526: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02ss\x1e\xde\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x10\xa3\x00\x00\x01\x94\x12\xd3\x10\xa3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNCS,26300.0,500,0.0,0.0,0.0,0.0,F...')])])
21:30:09,831 <kafka.protocol.parser>[DEBUG]: Received correlation id: 526
21:30:09,832 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:09,832 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 526 (3.533601760864258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=524, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:09,832 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=524, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:09,832 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 524 log start offset 0 and error None.
21:30:09,835 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:10,567 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NCT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:10,570 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NCT,115800.0,100,-100.0,0.0,0.0,0.0,False,0.0,14:15:10' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:10,570 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:10,570 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:10,570 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:10,571 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:10,571 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9a\x10<\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x13\x8a\x00\x00\x01\x94\x12\xd3\x13\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNCT,115800.0,100,-100.0,0.0,0.0,0...')])])}
21:30:10,571 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:10,571 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9a\x10<\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x13\x8a\x00\x00\x01\x94\x12\xd3\x13\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNCT,115800.0,100,-100.0,0.0,0.0,0...')])])
21:30:10,571 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9a\x10<\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x13\x8a\x00\x00\x01\x94\x12\xd3\x13\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNCT,115800.0,100,-100.0,0.0,0.0,0...')])])
21:30:10,571 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 527: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9a\x10<\xf9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x13\x8a\x00\x00\x01\x94\x12\xd3\x13\x8a\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNCT,115800.0,100,-100.0,0.0,0.0,0...')])])
21:30:10,573 <kafka.protocol.parser>[DEBUG]: Received correlation id: 527
21:30:10,573 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:10,574 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 527 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=525, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:10,574 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=525, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:10,574 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 525 log start offset 0 and error None.
21:30:10,575 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:10,881 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ND2/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:10,886 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ND2,38500.0,100,500.0,0.0,0.0,0.0,False,1300.0,14:05:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:10,886 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:10,886 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:10,887 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:10,887 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:10,887 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x07\xcb_\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x14\xc6\x00\x00\x01\x94\x12\xd3\x14\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nND2,38500.0,100,500.0,0.0,0.0,0.0...')])])}
21:30:10,887 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:10,887 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x07\xcb_\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x14\xc6\x00\x00\x01\x94\x12\xd3\x14\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nND2,38500.0,100,500.0,0.0,0.0,0.0...')])])
21:30:10,888 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x07\xcb_\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x14\xc6\x00\x00\x01\x94\x12\xd3\x14\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nND2,38500.0,100,500.0,0.0,0.0,0.0...')])])
21:30:10,888 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 528: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x07\xcb_\xeb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x14\xc6\x00\x00\x01\x94\x12\xd3\x14\xc6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nND2,38500.0,100,500.0,0.0,0.0,0.0...')])])
21:30:10,890 <kafka.protocol.parser>[DEBUG]: Received correlation id: 528
21:30:10,890 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:10,891 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 528 (1.9965171813964844 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=526, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:10,891 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=526, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:10,891 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 526 log start offset 0 and error None.
21:30:10,892 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:11,204 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:11,206 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NDC,117000.0,300,-1000.0,0.0,0.0,0.0,False,0.0,11:10:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:11,206 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:11,206 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:11,207 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:11,207 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:11,207 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa3\x16\xfa\xb1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x16\x06\x00\x00\x01\x94\x12\xd3\x16\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNDC,117000.0,300,-1000.0,0.0,0.0,...')])])}
21:30:11,207 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa3\x16\xfa\xb1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x16\x06\x00\x00\x01\x94\x12\xd3\x16\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNDC,117000.0,300,-1000.0,0.0,0.0,...')])])
21:30:11,207 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:11,207 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa3\x16\xfa\xb1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x16\x06\x00\x00\x01\x94\x12\xd3\x16\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNDC,117000.0,300,-1000.0,0.0,0.0,...')])])
21:30:11,208 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 529: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xa3\x16\xfa\xb1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x16\x06\x00\x00\x01\x94\x12\xd3\x16\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNDC,117000.0,300,-1000.0,0.0,0.0,...')])])
21:30:11,210 <kafka.protocol.parser>[DEBUG]: Received correlation id: 529
21:30:11,210 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:11,210 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 529 (2.0017623901367188 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=527, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:11,210 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=527, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:11,210 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 527 log start offset 0 and error None.
21:30:11,212 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:11,493 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MND/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:11,494 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:11,773 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NDF/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:11,775 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:13,202 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/HND/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:13,204 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'HND,12900.0,1000,200.0,0.0,0.0,0.0,False,0.0,14:23:21' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:13,204 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:13,205 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:13,205 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:13,205 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:13,205 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02~1!F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x1d\xd5\x00\x00\x01\x94\x12\xd3\x1d\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHND,12900.0,1000,200.0,0.0,0.0,0....')])])}
21:30:13,205 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:13,205 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02~1!F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x1d\xd5\x00\x00\x01\x94\x12\xd3\x1d\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHND,12900.0,1000,200.0,0.0,0.0,0....')])])
21:30:13,206 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02~1!F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x1d\xd5\x00\x00\x01\x94\x12\xd3\x1d\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHND,12900.0,1000,200.0,0.0,0.0,0....')])])
21:30:13,206 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 530: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02~1!F\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x1d\xd5\x00\x00\x01\x94\x12\xd3\x1d\xd5\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jHND,12900.0,1000,200.0,0.0,0.0,0....')])])
21:30:13,208 <kafka.protocol.parser>[DEBUG]: Received correlation id: 530
21:30:13,208 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:13,208 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 530 (2.008199691772461 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=528, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:13,209 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=528, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:13,209 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 528 log start offset 0 and error None.
21:30:13,210 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:15,668 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NDN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:15,675 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NDN,9200.0,4400,-300.0,0.0,0.0,0.0,False,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:15,676 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:15,676 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:15,677 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:15,677 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:15,678 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe8\x1f9\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3'|\x00\x00\x01\x94\x12\xd3'|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNDN,9200.0,4400,-300.0,0.0,0.0,0....")])])}
21:30:15,678 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe8\x1f9\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3'|\x00\x00\x01\x94\x12\xd3'|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNDN,9200.0,4400,-300.0,0.0,0.0,0....")])])
21:30:15,679 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe8\x1f9\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3'|\x00\x00\x01\x94\x12\xd3'|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNDN,9200.0,4400,-300.0,0.0,0.0,0....")])])
21:30:15,679 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 531: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xe8\x1f9\xd9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3'|\x00\x00\x01\x94\x12\xd3'|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNDN,9200.0,4400,-300.0,0.0,0.0,0....")])])
21:30:15,680 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:15,684 <kafka.protocol.parser>[DEBUG]: Received correlation id: 531
21:30:15,684 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:15,685 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 531 (4.961967468261719 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=529, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:15,685 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=529, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:15,685 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 529 log start offset 0 and error None.
21:30:15,688 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:16,10 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NDW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:16,12 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:16,323 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NDX/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:16,325 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NDX,5200.0,400,-100.0,0.0,0.0,0.0,False,0.0,11:13:29' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,325 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,325 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:16,325 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:16,325 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:16,325 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa3b\xdd\x95\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3*\x05\x00\x00\x01\x94\x12\xd3*\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNDX,5200.0,400,-100.0,0.0,0.0,0.0...')])])}
21:30:16,325 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa3b\xdd\x95\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3*\x05\x00\x00\x01\x94\x12\xd3*\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNDX,5200.0,400,-100.0,0.0,0.0,0.0...')])])
21:30:16,326 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa3b\xdd\x95\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3*\x05\x00\x00\x01\x94\x12\xd3*\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNDX,5200.0,400,-100.0,0.0,0.0,0.0...')])])
21:30:16,326 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,326 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 532: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xa3b\xdd\x95\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3*\x05\x00\x00\x01\x94\x12\xd3*\x05\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNDX,5200.0,400,-100.0,0.0,0.0,0.0...')])])
21:30:16,328 <kafka.protocol.parser>[DEBUG]: Received correlation id: 532
21:30:16,328 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:16,328 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 532 (2.0177364349365234 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=530, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:16,328 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=530, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:16,328 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 530 log start offset 0 and error None.
21:30:16,330 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:16,631 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NED/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:16,634 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NED,6900.0,2000,-200.0,0.0,0.0,0.0,False,0.0,14:48:39' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,634 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,634 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:16,635 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:16,635 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:16,635 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd4\xdc\x07K\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3+:\x00\x00\x01\x94\x12\xd3+:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNED,6900.0,2000,-200.0,0.0,0.0,0....')])])}
21:30:16,635 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd4\xdc\x07K\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3+:\x00\x00\x01\x94\x12\xd3+:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNED,6900.0,2000,-200.0,0.0,0.0,0....')])])
21:30:16,635 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,636 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd4\xdc\x07K\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3+:\x00\x00\x01\x94\x12\xd3+:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNED,6900.0,2000,-200.0,0.0,0.0,0....')])])
21:30:16,636 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 533: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xd4\xdc\x07K\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3+:\x00\x00\x01\x94\x12\xd3+:\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNED,6900.0,2000,-200.0,0.0,0.0,0....')])])
21:30:16,639 <kafka.protocol.parser>[DEBUG]: Received correlation id: 533
21:30:16,639 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:16,639 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 533 (2.99072265625 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=531, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:16,639 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=531, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:16,639 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 531 log start offset 0 and error None.
21:30:16,641 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:16,954 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NET/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:16,956 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NET,77500.0,200,0.0,0.0,0.0,0.0,False,400.0,14:26:18' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,956 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,956 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:16,957 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:16,957 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:16,957 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02;\xcf\x95[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3,|\x00\x00\x01\x94\x12\xd3,|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNET,77500.0,200,0.0,0.0,0.0,0.0,F...')])])}
21:30:16,957 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02;\xcf\x95[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3,|\x00\x00\x01\x94\x12\xd3,|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNET,77500.0,200,0.0,0.0,0.0,0.0,F...')])])
21:30:16,957 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02;\xcf\x95[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3,|\x00\x00\x01\x94\x12\xd3,|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNET,77500.0,200,0.0,0.0,0.0,0.0,F...')])])
21:30:16,958 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 534: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02;\xcf\x95[\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3,|\x00\x00\x01\x94\x12\xd3,|\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNET,77500.0,200,0.0,0.0,0.0,0.0,F...')])])
21:30:16,958 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:16,960 <kafka.protocol.parser>[DEBUG]: Received correlation id: 534
21:30:16,961 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:16,961 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 534 (2.978801727294922 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=532, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:16,961 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=532, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:16,961 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 532 log start offset 0 and error None.
21:30:16,963 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:18,356 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NRC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:18,750 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NRC,4900.0,60000,0.0,0.0,0.0,0.0,True,100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:18,750 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:18,750 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:18,750 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:18,751 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:18,751 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1~$\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd33~\x00\x00\x01\x94\x12\xd33~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNRC,4900.0,60000,0.0,0.0,0.0,0.0,...')])])}
21:30:18,752 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1~$\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd33~\x00\x00\x01\x94\x12\xd33~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNRC,4900.0,60000,0.0,0.0,0.0,0.0,...')])])
21:30:18,752 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1~$\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd33~\x00\x00\x01\x94\x12\xd33~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNRC,4900.0,60000,0.0,0.0,0.0,0.0,...')])])
21:30:18,752 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 535: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xb1~$\xbe\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd33~\x00\x00\x01\x94\x12\xd33~\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNRC,4900.0,60000,0.0,0.0,0.0,0.0,...')])])
21:30:18,753 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:18,756 <kafka.protocol.parser>[DEBUG]: Received correlation id: 535
21:30:18,756 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:18,757 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 535 (3.988981246948242 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=533, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:18,757 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=533, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:18,757 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 533 log start offset 0 and error None.
21:30:18,760 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:19,388 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NFC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:19,391 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NFC,16300.0,100,-1700.0,-0.1,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:19,391 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:19,391 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:19,391 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:19,391 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:19,391 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:19,392 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02f&\x84\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd35\xff\x00\x00\x01\x94\x12\xd35\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNFC,16300.0,100,-1700.0,-0.1,0.0,...')])])}
21:30:19,392 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02f&\x84\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd35\xff\x00\x00\x01\x94\x12\xd35\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNFC,16300.0,100,-1700.0,-0.1,0.0,...')])])
21:30:19,392 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02f&\x84\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd35\xff\x00\x00\x01\x94\x12\xd35\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNFC,16300.0,100,-1700.0,-0.1,0.0,...')])])
21:30:19,392 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 536: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02f&\x84\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd35\xff\x00\x00\x01\x94\x12\xd35\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNFC,16300.0,100,-1700.0,-0.1,0.0,...')])])
21:30:19,394 <kafka.protocol.parser>[DEBUG]: Received correlation id: 536
21:30:19,394 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:19,394 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 536 (1.9922256469726562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=534, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:19,394 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=534, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:19,394 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 534 log start offset 0 and error None.
21:30:19,396 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:19,705 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NGC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:19,707 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:20,350 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NHA/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:20,352 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NHA,28600.0,21500,-250.0,0.0,0.0,0.0,True,50.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:20,353 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:20,353 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:20,353 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:20,353 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:20,353 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85\xe5\x84\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd39\xc1\x00\x00\x01\x94\x12\xd39\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNHA,28600.0,21500,-250.0,0.0,0.0,...')])])}
21:30:20,353 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85\xe5\x84\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd39\xc1\x00\x00\x01\x94\x12\xd39\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNHA,28600.0,21500,-250.0,0.0,0.0,...')])])
21:30:20,353 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85\xe5\x84\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd39\xc1\x00\x00\x01\x94\x12\xd39\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNHA,28600.0,21500,-250.0,0.0,0.0,...')])])
21:30:20,354 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 537: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x85\xe5\x84\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd39\xc1\x00\x00\x01\x94\x12\xd39\xc1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNHA,28600.0,21500,-250.0,0.0,0.0,...')])])
21:30:20,354 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:20,356 <kafka.protocol.parser>[DEBUG]: Received correlation id: 537
21:30:20,356 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:20,356 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 537 (1.9927024841308594 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=535, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:20,356 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=535, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:20,357 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 535 log start offset 0 and error None.
21:30:20,358 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:20,657 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/MNB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:20,660 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:20,964 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VCE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:20,967 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:21,263 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NHC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:21,264 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NHC,29700.0,1200,2600.0,0.1,0.0,0.0,False,5300.0,14:26:19' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:21,264 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:21,264 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:21,265 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:21,265 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:21,265 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X\xb0\xbct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3=P\x00\x00\x01\x94\x12\xd3=P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNHC,29700.0,1200,2600.0,0.1,0.0,0...')])])}
21:30:21,265 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X\xb0\xbct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3=P\x00\x00\x01\x94\x12\xd3=P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNHC,29700.0,1200,2600.0,0.1,0.0,0...')])])
21:30:21,265 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:21,266 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X\xb0\xbct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3=P\x00\x00\x01\x94\x12\xd3=P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNHC,29700.0,1200,2600.0,0.1,0.0,0...')])])
21:30:21,266 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 538: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02X\xb0\xbct\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3=P\x00\x00\x01\x94\x12\xd3=P\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNHC,29700.0,1200,2600.0,0.1,0.0,0...')])])
21:30:21,269 <kafka.protocol.parser>[DEBUG]: Received correlation id: 538
21:30:21,269 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:21,269 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 538 (2.036571502685547 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=536, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:21,269 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=536, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:21,269 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 536 log start offset 0 and error None.
21:30:21,270 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:22,266 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NHH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:22,268 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NHH,13500.0,1000,0.0,0.0,0.0,0.0,False,50.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:22,269 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:22,269 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:22,269 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:22,269 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:22,269 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe4\xa2`\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3A=\x00\x00\x01\x94\x12\xd3A=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNHH,13500.0,1000,0.0,0.0,0.0,0.0,...')])])}
21:30:22,269 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe4\xa2`\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3A=\x00\x00\x01\x94\x12\xd3A=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNHH,13500.0,1000,0.0,0.0,0.0,0.0,...')])])
21:30:22,270 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe4\xa2`\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3A=\x00\x00\x01\x94\x12\xd3A=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNHH,13500.0,1000,0.0,0.0,0.0,0.0,...')])])
21:30:22,270 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 539: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02\xe4\xa2`\xb9\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3A=\x00\x00\x01\x94\x12\xd3A=\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNHH,13500.0,1000,0.0,0.0,0.0,0.0,...')])])
21:30:22,270 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:22,272 <kafka.protocol.parser>[DEBUG]: Received correlation id: 539
21:30:22,272 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:22,273 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 539 (2.9687881469726562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=537, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:22,273 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=537, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:22,273 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 537 log start offset 0 and error None.
21:30:22,274 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:22,612 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/VHM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:22,614 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'VHM,40350.0,591300,-300.0,0.0,0.0,0.0,True,-300.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:22,614 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:22,614 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:22,614 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:22,615 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:22,615 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xdc\xb4X\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3B\x96\x00\x00\x01\x94\x12\xd3B\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tVHM,40350.0,591300,-300.0,0.0,0....')])])}
21:30:22,615 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xdc\xb4X\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3B\x96\x00\x00\x01\x94\x12\xd3B\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tVHM,40350.0,591300,-300.0,0.0,0....')])])
21:30:22,615 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:22,615 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xdc\xb4X\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3B\x96\x00\x00\x01\x94\x12\xd3B\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tVHM,40350.0,591300,-300.0,0.0,0....')])])
21:30:22,615 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 540: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xdc\xb4X\xd6\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3B\x96\x00\x00\x01\x94\x12\xd3B\x96\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tVHM,40350.0,591300,-300.0,0.0,0....')])])
21:30:22,618 <kafka.protocol.parser>[DEBUG]: Received correlation id: 540
21:30:22,618 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:22,618 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 540 (1.9953250885009766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=538, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:22,618 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=538, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:22,618 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 538 log start offset 0 and error None.
21:30:22,620 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:22,918 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NHP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:22,920 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:23,221 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NHT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:23,223 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NHT,10900.0,100,-50.0,0.0,0.0,0.0,False,-50.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:23,223 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:23,223 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:23,224 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:23,224 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:23,224 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8b\xb4\n\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3D\xf7\x00\x00\x01\x94\x12\xd3D\xf7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNHT,10900.0,100,-50.0,0.0,0.0,0.0...')])])}
21:30:23,224 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8b\xb4\n\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3D\xf7\x00\x00\x01\x94\x12\xd3D\xf7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNHT,10900.0,100,-50.0,0.0,0.0,0.0...')])])
21:30:23,224 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8b\xb4\n\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3D\xf7\x00\x00\x01\x94\x12\xd3D\xf7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNHT,10900.0,100,-50.0,0.0,0.0,0.0...')])])
21:30:23,224 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 541: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x8b\xb4\n\x81\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3D\xf7\x00\x00\x01\x94\x12\xd3D\xf7\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNHT,10900.0,100,-50.0,0.0,0.0,0.0...')])])
21:30:23,225 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:23,227 <kafka.protocol.parser>[DEBUG]: Received correlation id: 541
21:30:23,227 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:23,227 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 541 (2.987384796142578 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=539, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:23,227 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=539, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:23,227 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 539 log start offset 0 and error None.
21:30:23,229 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:24,533 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NHV/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:24,535 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NHV,700.0,400,0.0,0.0,0.0,0.0,False,0.0,14:17:23' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:24,535 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:24,536 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:24,536 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:24,536 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:24,536 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:24,536 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\x17\xcdF\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3J\x18\x00\x00\x01\x94\x12\xd3J\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`NHV,700.0,400,0.0,0.0,0.0,0.0,Fal...')])])}
21:30:24,536 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\x17\xcdF\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3J\x18\x00\x00\x01\x94\x12\xd3J\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`NHV,700.0,400,0.0,0.0,0.0,0.0,Fal...')])])
21:30:24,537 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\x17\xcdF\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3J\x18\x00\x00\x01\x94\x12\xd3J\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`NHV,700.0,400,0.0,0.0,0.0,0.0,Fal...')])])
21:30:24,537 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 542: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00h\x00\x00\x00\x00\x02\x17\xcdF\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3J\x18\x00\x00\x01\x94\x12\xd3J\x18\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01l\x00\x00\x00\x01`NHV,700.0,400,0.0,0.0,0.0,0.0,Fal...')])])
21:30:24,539 <kafka.protocol.parser>[DEBUG]: Received correlation id: 542
21:30:24,539 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:24,539 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 542 (2.0294189453125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=540, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:24,540 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=540, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:24,540 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 540 log start offset 0 and error None.
21:30:24,541 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:25,71 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NKG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:25,73 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NKG,14600.0,433200,-150.0,0.0,0.0,0.0,True,-100.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:25,73 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:25,74 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:25,74 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:25,75 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xed\xe1#I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3L2\x00\x00\x01\x94\x12\xd3L2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tNKG,14600.0,433200,-150.0,0.0,0....')])])}
21:30:25,75 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:25,75 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xed\xe1#I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3L2\x00\x00\x01\x94\x12\xd3L2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tNKG,14600.0,433200,-150.0,0.0,0....')])])
21:30:25,75 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:25,75 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xed\xe1#I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3L2\x00\x00\x01\x94\x12\xd3L2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tNKG,14600.0,433200,-150.0,0.0,0....')])])
21:30:25,75 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 543: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xed\xe1#I\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3L2\x00\x00\x01\x94\x12\xd3L2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tNKG,14600.0,433200,-150.0,0.0,0....')])])
21:30:25,78 <kafka.protocol.parser>[DEBUG]: Received correlation id: 543
21:30:25,78 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:25,78 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 543 (2.518892288208008 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=541, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:25,78 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=541, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:25,78 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 541 log start offset 0 and error None.
21:30:25,80 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:25,521 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NLG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:25,524 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NLG,36400.0,299100,200.0,0.0,0.0,0.0,True,200.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:25,524 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:25,524 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:25,524 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:25,525 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:25,525 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\x7fh\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3M\xf4\x00\x00\x01\x94\x12\xd3M\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNLG,36400.0,299100,200.0,0.0,0.0,...')])])}
21:30:25,526 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\x7fh\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3M\xf4\x00\x00\x01\x94\x12\xd3M\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNLG,36400.0,299100,200.0,0.0,0.0,...')])])
21:30:25,526 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\x7fh\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3M\xf4\x00\x00\x01\x94\x12\xd3M\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNLG,36400.0,299100,200.0,0.0,0.0,...')])])
21:30:25,526 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 544: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x13\x7fh\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3M\xf4\x00\x00\x01\x94\x12\xd3M\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNLG,36400.0,299100,200.0,0.0,0.0,...')])])
21:30:25,526 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:25,530 <kafka.protocol.parser>[DEBUG]: Received correlation id: 544
21:30:25,530 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:25,530 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 544 (4.006862640380859 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=542, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:25,530 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=542, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:25,531 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 542 log start offset 0 and error None.
21:30:25,533 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:26,963 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NLS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:26,966 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:30,428 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NNC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:30,434 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NNC,23500.0,1200,0.0,0.0,0.0,0.0,False,100.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:30,434 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:30,435 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:30,435 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:30,436 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:30,436 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x11\x82\xcb\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3a"\x00\x00\x01\x94\x12\xd3a"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNNC,23500.0,1200,0.0,0.0,0.0,0.0,...')])])}
21:30:30,437 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x11\x82\xcb\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3a"\x00\x00\x01\x94\x12\xd3a"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNNC,23500.0,1200,0.0,0.0,0.0,0.0,...')])])
21:30:30,437 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x11\x82\xcb\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3a"\x00\x00\x01\x94\x12\xd3a"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNNC,23500.0,1200,0.0,0.0,0.0,0.0,...')])])
21:30:30,438 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 545: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x11\x82\xcb\xf1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3a"\x00\x00\x01\x94\x12\xd3a"\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNNC,23500.0,1200,0.0,0.0,0.0,0.0,...')])])
21:30:30,439 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:30,444 <kafka.protocol.parser>[DEBUG]: Received correlation id: 545
21:30:30,445 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:30,445 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 545 (7.030963897705078 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=543, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:30,446 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=543, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:30,446 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 543 log start offset 0 and error None.
21:30:30,451 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:30,765 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NNG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:30,767 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:33,223 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NNT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:33,228 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:33,983 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NOS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:33,985 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NOS,700.0,1300,0.0,0.0,0.0,0.0,False,0.0,14:46:22' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:33,985 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:33,985 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:33,985 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:33,985 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:33,985 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x8d\\\x00\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3o\x01\x00\x00\x01\x94\x12\xd3o\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bNOS,700.0,1300,0.0,0.0,0.0,0.0,Fa...')])])}
21:30:33,986 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x8d\\\x00\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3o\x01\x00\x00\x01\x94\x12\xd3o\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bNOS,700.0,1300,0.0,0.0,0.0,0.0,Fa...')])])
21:30:33,986 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x8d\\\x00\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3o\x01\x00\x00\x01\x94\x12\xd3o\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bNOS,700.0,1300,0.0,0.0,0.0,0.0,Fa...')])])
21:30:33,986 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 546: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\x8d\\\x00\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3o\x01\x00\x00\x01\x94\x12\xd3o\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bNOS,700.0,1300,0.0,0.0,0.0,0.0,Fa...')])])
21:30:33,986 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:33,989 <kafka.protocol.parser>[DEBUG]: Received correlation id: 546
21:30:33,989 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:33,989 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 546 (2.965688705444336 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=544, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:33,989 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=544, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:33,989 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 544 log start offset 0 and error None.
21:30:33,991 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:34,372 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NVL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:34,374 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NVL,10200.0,425400,-200.0,0.0,0.0,0.0,True,-50.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:34,374 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:34,374 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:34,374 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:34,375 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:34,375 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x029U\x0e\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3p\x86\x00\x00\x01\x94\x12\xd3p\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNVL,10200.0,425400,-200.0,0.0,0.0...')])])}
21:30:34,375 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x029U\x0e\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3p\x86\x00\x00\x01\x94\x12\xd3p\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNVL,10200.0,425400,-200.0,0.0,0.0...')])])
21:30:34,375 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:34,375 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x029U\x0e\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3p\x86\x00\x00\x01\x94\x12\xd3p\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNVL,10200.0,425400,-200.0,0.0,0.0...')])])
21:30:34,376 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 547: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x029U\x0e\x8d\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3p\x86\x00\x00\x01\x94\x12\xd3p\x86\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNVL,10200.0,425400,-200.0,0.0,0.0...')])])
21:30:34,378 <kafka.protocol.parser>[DEBUG]: Received correlation id: 547
21:30:34,378 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:34,378 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 547 (2.007722854614258 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=545, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:34,378 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=545, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:34,379 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 545 log start offset 0 and error None.
21:30:34,380 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:34,753 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PMB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:34,754 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PMB,9400.0,2000,-200.0,0.0,0.0,0.0,False,-100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:34,755 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:34,755 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:34,755 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:34,755 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:34,755 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:34,755 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xd2\xf8\xfd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3r\x03\x00\x00\x01\x94\x12\xd3r\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPMB,9400.0,2000,-200.0,0.0,0.0,0....')])])}
21:30:34,756 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xd2\xf8\xfd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3r\x03\x00\x00\x01\x94\x12\xd3r\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPMB,9400.0,2000,-200.0,0.0,0.0,0....')])])
21:30:34,756 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xd2\xf8\xfd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3r\x03\x00\x00\x01\x94\x12\xd3r\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPMB,9400.0,2000,-200.0,0.0,0.0,0....')])])
21:30:34,756 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 548: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02:\xd2\xf8\xfd\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3r\x03\x00\x00\x01\x94\x12\xd3r\x03\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pPMB,9400.0,2000,-200.0,0.0,0.0,0....')])])
21:30:34,758 <kafka.protocol.parser>[DEBUG]: Received correlation id: 548
21:30:34,758 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:34,758 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 548 (2.008199691772461 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=546, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:34,759 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=546, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:34,759 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 546 log start offset 0 and error None.
21:30:34,760 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:35,587 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NQB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:35,590 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:35,886 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NQT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:35,887 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:36,619 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NS2/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:36,621 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:37,18 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NSC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:37,21 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:37,865 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PSH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:37,867 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PSH,3270.0,65100,-190.0,-0.1,0.0,0.0,True,0.0,14:45:06' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:37,867 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:37,867 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:37,867 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:37,868 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:37,868 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:37,868 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02a\xe8o\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3~+\x00\x00\x01\x94\x12\xd3~+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lPSH,3270.0,65100,-190.0,-0.1,0.0,...')])])}
21:30:37,868 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02a\xe8o\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3~+\x00\x00\x01\x94\x12\xd3~+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lPSH,3270.0,65100,-190.0,-0.1,0.0,...')])])
21:30:37,868 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02a\xe8o\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3~+\x00\x00\x01\x94\x12\xd3~+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lPSH,3270.0,65100,-190.0,-0.1,0.0,...')])])
21:30:37,868 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 549: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02a\xe8o\xd1\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3~+\x00\x00\x01\x94\x12\xd3~+\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lPSH,3270.0,65100,-190.0,-0.1,0.0,...')])])
21:30:37,870 <kafka.protocol.parser>[DEBUG]: Received correlation id: 549
21:30:37,871 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:37,871 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 549 (2.0008087158203125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=547, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:37,871 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=547, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:37,871 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 547 log start offset 0 and error None.
21:30:37,872 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:38,182 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NST/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:38,185 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:42,501 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NT2/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:42,596 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NT2,20850.0,9000,-50.0,0.0,0.0,0.0,False,-50.0,14:45:03' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:42,596 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:42,596 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:42,596 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:42,597 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:42,597 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:42,597 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x8d\xc0,\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x90\xa4\x00\x00\x01\x94\x12\xd3\x90\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNT2,20850.0,9000,-50.0,0.0,0.0,0....')])])}
21:30:42,598 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x8d\xc0,\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x90\xa4\x00\x00\x01\x94\x12\xd3\x90\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNT2,20850.0,9000,-50.0,0.0,0.0,0....')])])
21:30:42,598 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x8d\xc0,\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x90\xa4\x00\x00\x01\x94\x12\xd3\x90\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNT2,20850.0,9000,-50.0,0.0,0.0,0....')])])
21:30:42,598 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 550: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x8d\xc0,\xa5\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x90\xa4\x00\x00\x01\x94\x12\xd3\x90\xa4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nNT2,20850.0,9000,-50.0,0.0,0.0,0....')])])
21:30:42,602 <kafka.protocol.parser>[DEBUG]: Received correlation id: 550
21:30:42,602 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:42,602 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 550 (2.9604434967041016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=548, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:42,603 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=548, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:42,603 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 548 log start offset 0 and error None.
21:30:42,605 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:43,329 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NTB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:43,330 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:43,622 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NTC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:43,624 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NTC,214400.0,500,-100.0,0.0,0.0,0.0,False,800.0,14:57:35' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:43,624 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:43,624 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:43,624 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:43,624 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:43,625 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:43,625 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0f\xda\xc4\xea\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x94\xa8\x00\x00\x01\x94\x12\xd3\x94\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNTC,214400.0,500,-100.0,0.0,0.0,0...')])])}
21:30:43,625 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0f\xda\xc4\xea\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x94\xa8\x00\x00\x01\x94\x12\xd3\x94\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNTC,214400.0,500,-100.0,0.0,0.0,0...')])])
21:30:43,625 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0f\xda\xc4\xea\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x94\xa8\x00\x00\x01\x94\x12\xd3\x94\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNTC,214400.0,500,-100.0,0.0,0.0,0...')])])
21:30:43,625 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 551: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00p\x00\x00\x00\x00\x02\x0f\xda\xc4\xea\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x94\xa8\x00\x00\x01\x94\x12\xd3\x94\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01|\x00\x00\x00\x01pNTC,214400.0,500,-100.0,0.0,0.0,0...')])])
21:30:43,628 <kafka.protocol.parser>[DEBUG]: Received correlation id: 551
21:30:43,628 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:43,628 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 551 (2.9973983764648438 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=549, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:43,628 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=549, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:43,628 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 549 log start offset 0 and error None.
21:30:43,629 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:43,934 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NTT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:43,936 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NTT,8900.0,4800,-500.0,-0.1,0.0,0.0,False,0.0,14:46:36' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:43,936 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:43,936 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:43,936 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:43,936 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:43,936 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x03\x19D"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x95\xe0\x00\x00\x01\x94\x12\xd3\x95\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNTT,8900.0,4800,-500.0,-0.1,0.0,0...')])])}
21:30:43,937 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x03\x19D"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x95\xe0\x00\x00\x01\x94\x12\xd3\x95\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNTT,8900.0,4800,-500.0,-0.1,0.0,0...')])])
21:30:43,937 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:43,937 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x03\x19D"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x95\xe0\x00\x00\x01\x94\x12\xd3\x95\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNTT,8900.0,4800,-500.0,-0.1,0.0,0...')])])
21:30:43,937 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 552: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x03\x19D"\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x95\xe0\x00\x00\x01\x94\x12\xd3\x95\xe0\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNTT,8900.0,4800,-500.0,-0.1,0.0,0...')])])
21:30:43,940 <kafka.protocol.parser>[DEBUG]: Received correlation id: 552
21:30:43,940 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:43,940 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 552 (2.9549598693847656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=550, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:43,940 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=550, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:43,940 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 550 log start offset 0 and error None.
21:30:43,942 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:44,640 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NTL/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:44,642 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NTL,18900.0,90700,-250.0,0.0,0.0,0.0,True,-100.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:44,642 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:44,642 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:44,643 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:44,643 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:44,643 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Ge\xa6\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x98\xa2\x00\x00\x01\x94\x12\xd3\x98\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNTL,18900.0,90700,-250.0,0.0,0.0,...')])])}
21:30:44,643 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Ge\xa6\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x98\xa2\x00\x00\x01\x94\x12\xd3\x98\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNTL,18900.0,90700,-250.0,0.0,0.0,...')])])
21:30:44,643 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:44,643 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Ge\xa6\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x98\xa2\x00\x00\x01\x94\x12\xd3\x98\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNTL,18900.0,90700,-250.0,0.0,0.0,...')])])
21:30:44,644 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 553: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02Ge\xa6\x87\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x98\xa2\x00\x00\x01\x94\x12\xd3\x98\xa2\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rNTL,18900.0,90700,-250.0,0.0,0.0,...')])])
21:30:44,645 <kafka.protocol.parser>[DEBUG]: Received correlation id: 553
21:30:44,646 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:44,646 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 553 (2.2857189178466797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=551, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:44,646 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=551, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:44,646 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 551 log start offset 0 and error None.
21:30:44,647 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:45,175 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NTP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:45,177 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NTP,64400.0,500,-900.0,0.0,0.0,0.0,False,0.0,14:56:45' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:45,177 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:45,177 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:45,177 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:45,178 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:45,178 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-\xf7\x86\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x9a\xb9\x00\x00\x01\x94\x12\xd3\x9a\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNTP,64400.0,500,-900.0,0.0,0.0,0....')])])}
21:30:45,178 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-\xf7\x86\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x9a\xb9\x00\x00\x01\x94\x12\xd3\x9a\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNTP,64400.0,500,-900.0,0.0,0.0,0....')])])
21:30:45,178 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-\xf7\x86\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x9a\xb9\x00\x00\x01\x94\x12\xd3\x9a\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNTP,64400.0,500,-900.0,0.0,0.0,0....')])])
21:30:45,178 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:45,178 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 554: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02-\xf7\x86\x91\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\x9a\xb9\x00\x00\x01\x94\x12\xd3\x9a\xb9\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jNTP,64400.0,500,-900.0,0.0,0.0,0....')])])
21:30:45,181 <kafka.protocol.parser>[DEBUG]: Received correlation id: 554
21:30:45,181 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:45,181 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 554 (3.356456756591797 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=552, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:45,181 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=552, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:45,181 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 552 log start offset 0 and error None.
21:30:45,183 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:45,568 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NUE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:45,571 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:46,855 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NTW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:46,858 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:48,422 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NVB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:48,424 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NVB,8900.0,2100,0.0,0.0,0.0,0.0,False,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:48,424 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:48,424 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:48,424 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:48,425 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:48,425 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe8\x11v_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa7h\x00\x00\x01\x94\x12\xd3\xa7h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNVB,8900.0,2100,0.0,0.0,0.0,0.0,F...')])])}
21:30:48,425 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe8\x11v_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa7h\x00\x00\x01\x94\x12\xd3\xa7h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNVB,8900.0,2100,0.0,0.0,0.0,0.0,F...')])])
21:30:48,425 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe8\x11v_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa7h\x00\x00\x01\x94\x12\xd3\xa7h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNVB,8900.0,2100,0.0,0.0,0.0,0.0,F...')])])
21:30:48,425 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:48,425 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 555: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe8\x11v_\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa7h\x00\x00\x01\x94\x12\xd3\xa7h\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dNVB,8900.0,2100,0.0,0.0,0.0,0.0,F...')])])
21:30:48,427 <kafka.protocol.parser>[DEBUG]: Received correlation id: 555
21:30:48,428 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:48,428 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 555 (1.9948482513427734 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=553, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:48,428 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=553, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:48,428 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 553 log start offset 0 and error None.
21:30:48,429 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:48,717 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NVT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:48,719 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NVT,7960.0,100,-20.0,0.0,0.0,0.0,False,10.0,14:23:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:48,719 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:48,719 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:48,719 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:48,719 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:48,720 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02|\x1c\x1a\x86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa8\x8f\x00\x00\x01\x94\x12\xd3\xa8\x8f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNVT,7960.0,100,-20.0,0.0,0.0,0.0,...')])])}
21:30:48,720 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02|\x1c\x1a\x86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa8\x8f\x00\x00\x01\x94\x12\xd3\xa8\x8f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNVT,7960.0,100,-20.0,0.0,0.0,0.0,...')])])
21:30:48,720 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02|\x1c\x1a\x86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa8\x8f\x00\x00\x01\x94\x12\xd3\xa8\x8f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNVT,7960.0,100,-20.0,0.0,0.0,0.0,...')])])
21:30:48,720 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 556: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02|\x1c\x1a\x86\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xa8\x8f\x00\x00\x01\x94\x12\xd3\xa8\x8f\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hNVT,7960.0,100,-20.0,0.0,0.0,0.0,...')])])
21:30:48,720 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:48,723 <kafka.protocol.parser>[DEBUG]: Received correlation id: 556
21:30:48,723 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:48,723 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 556 (2.8803348541259766 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=554, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:48,723 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=554, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:48,723 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 554 log start offset 0 and error None.
21:30:48,724 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:49,89 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NWT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:49,91 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:52,388 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/NXT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:52,390 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'NXT,6200.0,100,200.0,0.0,0.0,0.0,False,1100.0,13:27:26' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:52,390 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:52,390 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:52,390 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:52,391 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:52,391 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02E\x17l\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb6\xe6\x00\x00\x01\x94\x12\xd3\xb6\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNXT,6200.0,100,200.0,0.0,0.0,0.0,...')])])}
21:30:52,391 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02E\x17l\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb6\xe6\x00\x00\x01\x94\x12\xd3\xb6\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNXT,6200.0,100,200.0,0.0,0.0,0.0,...')])])
21:30:52,391 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02E\x17l\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb6\xe6\x00\x00\x01\x94\x12\xd3\xb6\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNXT,6200.0,100,200.0,0.0,0.0,0.0,...')])])
21:30:52,391 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 557: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02E\x17l\x84\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb6\xe6\x00\x00\x01\x94\x12\xd3\xb6\xe6\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lNXT,6200.0,100,200.0,0.0,0.0,0.0,...')])])
21:30:52,391 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:52,394 <kafka.protocol.parser>[DEBUG]: Received correlation id: 557
21:30:52,394 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:52,394 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 557 (3.178834915161133 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=555, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:52,394 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=555, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:52,394 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 555 log start offset 0 and error None.
21:30:52,395 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:53,153 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/OCB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:53,155 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'OCB,10950.0,213800,50.0,0.0,0.0,0.0,True,-50.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:53,155 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:53,155 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:53,155 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:53,155 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:53,155 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:53,156 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xec\xb9\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb9\xe3\x00\x00\x01\x94\x12\xd3\xb9\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nOCB,10950.0,213800,50.0,0.0,0.0,0...')])])}
21:30:53,156 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xec\xb9\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb9\xe3\x00\x00\x01\x94\x12\xd3\xb9\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nOCB,10950.0,213800,50.0,0.0,0.0,0...')])])
21:30:53,156 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xec\xb9\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb9\xe3\x00\x00\x01\x94\x12\xd3\xb9\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nOCB,10950.0,213800,50.0,0.0,0.0,0...')])])
21:30:53,156 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 558: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xec\xb9\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xb9\xe3\x00\x00\x01\x94\x12\xd3\xb9\xe3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nOCB,10950.0,213800,50.0,0.0,0.0,0...')])])
21:30:53,158 <kafka.protocol.parser>[DEBUG]: Received correlation id: 558
21:30:53,158 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:53,159 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 558 (3.000974655151367 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=556, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:53,159 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=556, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:53,159 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 556 log start offset 0 and error None.
21:30:53,160 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:53,679 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/OCH/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:53,681 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'OCH,5700.0,300,0.0,0.0,0.0,0.0,False,100.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:53,681 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:53,681 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:53,681 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:53,682 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:53,682 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Y\xae+b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbb\xf1\x00\x00\x01\x94\x12\xd3\xbb\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fOCH,5700.0,300,0.0,0.0,0.0,0.0,Fa...')])])}
21:30:53,682 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Y\xae+b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbb\xf1\x00\x00\x01\x94\x12\xd3\xbb\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fOCH,5700.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:30:53,682 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:53,683 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Y\xae+b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbb\xf1\x00\x00\x01\x94\x12\xd3\xbb\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fOCH,5700.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:30:53,683 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 559: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02Y\xae+b\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbb\xf1\x00\x00\x01\x94\x12\xd3\xbb\xf1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fOCH,5700.0,300,0.0,0.0,0.0,0.0,Fa...')])])
21:30:53,686 <kafka.protocol.parser>[DEBUG]: Received correlation id: 559
21:30:53,686 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:53,686 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 559 (2.999544143676758 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=557, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:53,686 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=557, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:53,686 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 557 log start offset 0 and error None.
21:30:53,688 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:54,275 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/EVS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:54,277 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'EVS,5800.0,600,100.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:54,277 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:54,277 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:54,278 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:54,278 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc1\xb9f\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbeE\x00\x00\x01\x94\x12\xd3\xbeE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fEVS,5800.0,600,100.0,0.0,0.0,0.0,...')])])}
21:30:54,278 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc1\xb9f\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbeE\x00\x00\x01\x94\x12\xd3\xbeE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fEVS,5800.0,600,100.0,0.0,0.0,0.0,...')])])
21:30:54,278 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc1\xb9f\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbeE\x00\x00\x01\x94\x12\xd3\xbeE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fEVS,5800.0,600,100.0,0.0,0.0,0.0,...')])])
21:30:54,278 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:54,278 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 560: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc1\xb9f\xcb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xbeE\x00\x00\x01\x94\x12\xd3\xbeE\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fEVS,5800.0,600,100.0,0.0,0.0,0.0,...')])])
21:30:54,279 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:54,280 <kafka.protocol.parser>[DEBUG]: Received correlation id: 560
21:30:54,281 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:54,281 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 560 (3.0057430267333984 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=558, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:54,281 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=558, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:54,281 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 558 log start offset 0 and error None.
21:30:54,283 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:55,299 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/OGC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:55,400 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'OGC,4540.0,29500,270.0,0.1,0.0,0.0,False,40.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:55,400 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:55,400 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:55,401 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:55,402 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:55,403 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9dPk\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xc2\xa8\x00\x00\x01\x94\x12\xd3\xc2\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lOGC,4540.0,29500,270.0,0.1,0.0,0....')])])}
21:30:55,403 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:55,404 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9dPk\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xc2\xa8\x00\x00\x01\x94\x12\xd3\xc2\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lOGC,4540.0,29500,270.0,0.1,0.0,0....')])])
21:30:55,404 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9dPk\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xc2\xa8\x00\x00\x01\x94\x12\xd3\xc2\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lOGC,4540.0,29500,270.0,0.1,0.0,0....')])])
21:30:55,404 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 561: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00n\x00\x00\x00\x00\x02\x9dPk\xd3\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xc2\xa8\x00\x00\x01\x94\x12\xd3\xc2\xa8\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01x\x00\x00\x00\x01lOGC,4540.0,29500,270.0,0.1,0.0,0....')])])
21:30:55,408 <kafka.protocol.parser>[DEBUG]: Received correlation id: 561
21:30:55,408 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:55,408 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 561 (3.0045509338378906 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=559, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:55,409 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=559, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:55,409 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 559 log start offset 0 and error None.
21:30:55,411 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:56,987 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/TOW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:56,989 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:57,712 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ONE/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:57,715 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ONE,5100.0,2100,0.0,0.0,0.0,0.0,False,0.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:57,715 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:57,715 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:57,715 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:57,716 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:57,716 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe3\xe4:\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xcb\xb3\x00\x00\x01\x94\x12\xd3\xcb\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dONE,5100.0,2100,0.0,0.0,0.0,0.0,F...')])])}
21:30:57,716 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:57,716 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe3\xe4:\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xcb\xb3\x00\x00\x01\x94\x12\xd3\xcb\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dONE,5100.0,2100,0.0,0.0,0.0,0.0,F...')])])
21:30:57,717 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe3\xe4:\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xcb\xb3\x00\x00\x01\x94\x12\xd3\xcb\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dONE,5100.0,2100,0.0,0.0,0.0,0.0,F...')])])
21:30:57,717 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 562: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02\xe3\xe4:\xee\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xcb\xb3\x00\x00\x01\x94\x12\xd3\xcb\xb3\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dONE,5100.0,2100,0.0,0.0,0.0,0.0,F...')])])
21:30:57,719 <kafka.protocol.parser>[DEBUG]: Received correlation id: 562
21:30:57,719 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:57,719 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 562 (2.0067691802978516 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=560, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:57,720 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=560, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:57,720 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 560 log start offset 0 and error None.
21:30:57,722 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:59,149 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ONW/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:59,152 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:30:59,505 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/OPC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:30:59,508 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'OPC,23700.0,100,-50.0,0.0,0.0,0.0,False,0.0,13:40:54' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:30:59,508 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:30:59,508 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:30:59,509 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:30:59,509 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:30:59,509 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02&\xd8\xb7:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd2\xb4\x00\x00\x01\x94\x12\xd3\xd2\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hOPC,23700.0,100,-50.0,0.0,0.0,0.0...')])])}
21:30:59,509 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02&\xd8\xb7:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd2\xb4\x00\x00\x01\x94\x12\xd3\xd2\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hOPC,23700.0,100,-50.0,0.0,0.0,0.0...')])])
21:30:59,509 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02&\xd8\xb7:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd2\xb4\x00\x00\x01\x94\x12\xd3\xd2\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hOPC,23700.0,100,-50.0,0.0,0.0,0.0...')])])
21:30:59,509 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:30:59,510 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 563: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02&\xd8\xb7:\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd2\xb4\x00\x00\x01\x94\x12\xd3\xd2\xb4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hOPC,23700.0,100,-50.0,0.0,0.0,0.0...')])])
21:30:59,557 <kafka.protocol.parser>[DEBUG]: Received correlation id: 563
21:30:59,557 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:30:59,557 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 563 (46.99850082397461 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=561, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:59,557 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=561, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:30:59,557 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 561 log start offset 0 and error None.
21:30:59,560 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:00,43 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/ORS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:00,45 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'ORS,14400.0,253500,100.0,0.0,0.0,0.0,True,-100.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:00,45 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:00,46 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:00,46 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:00,46 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:00,46 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:00,46 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdcI'\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd4\xce\x00\x00\x01\x94\x12\xd3\xd4\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rORS,14400.0,253500,100.0,0.0,0.0,...")])])}
21:31:00,47 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdcI'\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd4\xce\x00\x00\x01\x94\x12\xd3\xd4\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rORS,14400.0,253500,100.0,0.0,0.0,...")])])
21:31:00,47 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdcI'\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd4\xce\x00\x00\x01\x94\x12\xd3\xd4\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rORS,14400.0,253500,100.0,0.0,0.0,...")])])
21:31:00,47 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 564: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\xdcI'\xdf\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd4\xce\x00\x00\x01\x94\x12\xd3\xd4\xce\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rORS,14400.0,253500,100.0,0.0,0.0,...")])])
21:31:00,50 <kafka.protocol.parser>[DEBUG]: Received correlation id: 564
21:31:00,50 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:00,50 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 564 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=562, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:00,50 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=562, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:00,50 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 562 log start offset 0 and error None.
21:31:00,52 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:00,355 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PAC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:00,725 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PAC,43000.0,12800,-350.0,0.0,0.0,0.0,True,-300.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:00,726 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:00,726 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:00,727 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:00,727 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:00,727 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:00,727 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02{\xc9Q%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd7v\x00\x00\x01\x94\x12\xd3\xd7v\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPAC,43000.0,12800,-350.0,0.0,0.0,...')])])}
21:31:00,727 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02{\xc9Q%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd7v\x00\x00\x01\x94\x12\xd3\xd7v\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPAC,43000.0,12800,-350.0,0.0,0.0,...')])])
21:31:00,727 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02{\xc9Q%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd7v\x00\x00\x01\x94\x12\xd3\xd7v\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPAC,43000.0,12800,-350.0,0.0,0.0,...')])])
21:31:00,728 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 565: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02{\xc9Q%\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xd7v\x00\x00\x01\x94\x12\xd3\xd7v\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPAC,43000.0,12800,-350.0,0.0,0.0,...')])])
21:31:00,730 <kafka.protocol.parser>[DEBUG]: Received correlation id: 565
21:31:00,730 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:00,730 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 565 (2.2225379943847656 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=563, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:00,730 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=563, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:00,730 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 563 log start offset 0 and error None.
21:31:00,732 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:01,76 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PAI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:01,79 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:01,417 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PAN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:01,435 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PAN,23550.0,64200,0.0,0.0,0.0,0.0,True,0.0,14:45:04' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:01,435 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:01,435 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:01,436 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:01,436 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:01,436 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc3d\x16\xd7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xda;\x00\x00\x01\x94\x12\xd3\xda;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fPAN,23550.0,64200,0.0,0.0,0.0,0.0...')])])}
21:31:01,436 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc3d\x16\xd7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xda;\x00\x00\x01\x94\x12\xd3\xda;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fPAN,23550.0,64200,0.0,0.0,0.0,0.0...')])])
21:31:01,436 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:01,436 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc3d\x16\xd7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xda;\x00\x00\x01\x94\x12\xd3\xda;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fPAN,23550.0,64200,0.0,0.0,0.0,0.0...')])])
21:31:01,437 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 566: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00k\x00\x00\x00\x00\x02\xc3d\x16\xd7\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xda;\x00\x00\x01\x94\x12\xd3\xda;\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01r\x00\x00\x00\x01fPAN,23550.0,64200,0.0,0.0,0.0,0.0...')])])
21:31:01,470 <kafka.protocol.parser>[DEBUG]: Received correlation id: 566
21:31:01,470 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:01,470 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 566 (33.01286697387695 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=564, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:01,470 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=564, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:01,471 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 564 log start offset 0 and error None.
21:31:01,472 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:03,97 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PAP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:03,99 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PAP,24000.0,100,-1300.0,-0.1,0.0,0.0,False,0.0,11:08:30' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:03,99 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:03,100 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:03,100 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:03,100 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:03,100 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:03,100 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x16`*e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe0\xbb\x00\x00\x01\x94\x12\xd3\xe0\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAP,24000.0,100,-1300.0,-0.1,0.0,...')])])}
21:31:03,100 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x16`*e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe0\xbb\x00\x00\x01\x94\x12\xd3\xe0\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAP,24000.0,100,-1300.0,-0.1,0.0,...')])])
21:31:03,101 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x16`*e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe0\xbb\x00\x00\x01\x94\x12\xd3\xe0\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAP,24000.0,100,-1300.0,-0.1,0.0,...')])])
21:31:03,101 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 567: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x16`*e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe0\xbb\x00\x00\x01\x94\x12\xd3\xe0\xbb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAP,24000.0,100,-1300.0,-0.1,0.0,...')])])
21:31:03,103 <kafka.protocol.parser>[DEBUG]: Received correlation id: 567
21:31:03,103 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:03,103 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 567 (2.000570297241211 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=565, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:03,103 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=565, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:03,103 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 565 log start offset 0 and error None.
21:31:03,104 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:03,415 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PAS/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:03,417 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PAS,3100.0,500,-100.0,0.0,0.0,0.0,False,-100.0,14:58:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:03,418 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:03,418 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:03,418 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:03,418 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:03,418 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:03,418 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xcagF\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe1\xfa\x00\x00\x01\x94\x12\xd3\xe1\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAS,3100.0,500,-100.0,0.0,0.0,0.0...')])])}
21:31:03,419 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xcagF\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe1\xfa\x00\x00\x01\x94\x12\xd3\xe1\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAS,3100.0,500,-100.0,0.0,0.0,0.0...')])])
21:31:03,419 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xcagF\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe1\xfa\x00\x00\x01\x94\x12\xd3\xe1\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAS,3100.0,500,-100.0,0.0,0.0,0.0...')])])
21:31:03,419 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 568: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\x06\xcagF\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xe1\xfa\x00\x00\x01\x94\x12\xd3\xe1\xfa\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPAS,3100.0,500,-100.0,0.0,0.0,0.0...')])])
21:31:03,422 <kafka.protocol.parser>[DEBUG]: Received correlation id: 568
21:31:03,422 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:03,422 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 568 (3.004312515258789 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=566, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:03,422 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=566, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:03,423 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 566 log start offset 0 and error None.
21:31:03,425 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:06,507 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PBP/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:07,227 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PBP,13200.0,300,-100.0,0.0,0.0,0.0,False,0.0,14:29:59' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:07,227 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:07,227 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:07,227 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:07,227 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03(\x8b\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf0\xdb\x00\x00\x01\x94\x12\xd3\xf0\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPBP,13200.0,300,-100.0,0.0,0.0,0....')])])}
21:31:07,228 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03(\x8b\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf0\xdb\x00\x00\x01\x94\x12\xd3\xf0\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPBP,13200.0,300,-100.0,0.0,0.0,0....')])])
21:31:07,228 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:07,228 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03(\x8b\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf0\xdb\x00\x00\x01\x94\x12\xd3\xf0\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPBP,13200.0,300,-100.0,0.0,0.0,0....')])])
21:31:07,228 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 569: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\x03(\x8b\xec\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf0\xdb\x00\x00\x01\x94\x12\xd3\xf0\xdb\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPBP,13200.0,300,-100.0,0.0,0.0,0....')])])
21:31:07,229 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:07,230 <kafka.protocol.parser>[DEBUG]: Received correlation id: 569
21:31:07,231 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:07,231 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 569 (2.9993057250976562 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=567, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:07,231 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=567, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:07,231 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 567 log start offset 0 and error None.
21:31:07,232 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:07,921 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PC1/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:07,923 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PC1,22800.0,136700,-250.0,0.0,0.0,0.0,True,-200.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:07,923 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:07,923 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:07,924 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:07,924 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:07,924 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc4\x82\x1a@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf3\x93\x00\x00\x01\x94\x12\xd3\xf3\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tPC1,22800.0,136700,-250.0,0.0,0....')])])}
21:31:07,924 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc4\x82\x1a@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf3\x93\x00\x00\x01\x94\x12\xd3\xf3\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tPC1,22800.0,136700,-250.0,0.0,0....')])])
21:31:07,924 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc4\x82\x1a@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf3\x93\x00\x00\x01\x94\x12\xd3\xf3\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tPC1,22800.0,136700,-250.0,0.0,0....')])])
21:31:07,924 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:07,925 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 570: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00s\x00\x00\x00\x00\x02\xc4\x82\x1a@\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xf3\x93\x00\x00\x01\x94\x12\xd3\xf3\x93\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x80\x01\x00\x00\x00\x01tPC1,22800.0,136700,-250.0,0.0,0....')])])
21:31:07,927 <kafka.protocol.parser>[DEBUG]: Received correlation id: 570
21:31:07,927 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:07,927 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 570 (2.0008087158203125 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=568, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:07,927 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=568, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:07,928 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 568 log start offset 0 and error None.
21:31:07,929 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:10,387 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PCC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:10,389 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:10,833 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PCG/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:10,835 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PCG,4000.0,100,0.0,0.0,0.0,0.0,False,0.0,14:45:02' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:10,836 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:10,836 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:10,836 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:10,836 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:10,837 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:10,837 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa7\xbb\xa1E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xfe\xf4\x00\x00\x01\x94\x12\xd3\xfe\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bPCG,4000.0,100,0.0,0.0,0.0,0.0,Fa...')])])}
21:31:10,837 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa7\xbb\xa1E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xfe\xf4\x00\x00\x01\x94\x12\xd3\xfe\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bPCG,4000.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:31:10,837 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa7\xbb\xa1E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xfe\xf4\x00\x00\x01\x94\x12\xd3\xfe\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bPCG,4000.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:31:10,837 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 571: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00i\x00\x00\x00\x00\x02\xa7\xbb\xa1E\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd3\xfe\xf4\x00\x00\x01\x94\x12\xd3\xfe\xf4\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01n\x00\x00\x00\x01bPCG,4000.0,100,0.0,0.0,0.0,0.0,Fa...')])])
21:31:10,840 <kafka.protocol.parser>[DEBUG]: Received correlation id: 571
21:31:10,840 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:10,841 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 571 (1.9974708557128906 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=569, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:10,841 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=569, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:10,841 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 569 log start offset 0 and error None.
21:31:10,842 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:11,136 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PCM/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:11,138 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:11,421 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/CSI/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:11,423 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'CSI,33500.0,100,700.0,0.0,0.0,0.0,False,0.0,14:56:15' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:11,424 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:11,424 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:11,424 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:11,424 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:11,424 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:11,424 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02LL\xc6e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x01@\x00\x00\x01\x94\x12\xd4\x01@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCSI,33500.0,100,700.0,0.0,0.0,0.0...')])])}
21:31:11,425 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02LL\xc6e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x01@\x00\x00\x01\x94\x12\xd4\x01@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCSI,33500.0,100,700.0,0.0,0.0,0.0...')])])
21:31:11,425 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02LL\xc6e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x01@\x00\x00\x01\x94\x12\xd4\x01@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCSI,33500.0,100,700.0,0.0,0.0,0.0...')])])
21:31:11,425 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 572: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00l\x00\x00\x00\x00\x02LL\xc6e\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x01@\x00\x00\x01\x94\x12\xd4\x01@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01t\x00\x00\x00\x01hCSI,33500.0,100,700.0,0.0,0.0,0.0...')])])
21:31:11,427 <kafka.protocol.parser>[DEBUG]: Received correlation id: 572
21:31:11,427 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:11,427 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 572 (2.0003318786621094 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=570, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:11,427 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=570, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:11,428 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 570 log start offset 0 and error None.
21:31:11,429 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:11,716 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PCT/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:11,719 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PCT,12600.0,1300,-200.0,0.0,0.0,0.0,False,-200.0,14:45:01' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:11,719 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:11,719 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:11,719 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:11,719 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:11,720 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:11,720 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x00)T\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x02g\x00\x00\x01\x94\x12\xd4\x02g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPCT,12600.0,1300,-200.0,0.0,0.0,0...')])])}
21:31:11,720 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x00)T\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x02g\x00\x00\x01\x94\x12\xd4\x02g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPCT,12600.0,1300,-200.0,0.0,0.0,0...')])])
21:31:11,720 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x00)T\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x02g\x00\x00\x01\x94\x12\xd4\x02g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPCT,12600.0,1300,-200.0,0.0,0.0,0...')])])
21:31:11,720 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 573: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00q\x00\x00\x00\x00\x02\x00)T\xfb\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x02g\x00\x00\x01\x94\x12\xd4\x02g\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01~\x00\x00\x00\x01rPCT,12600.0,1300,-200.0,0.0,0.0,0...')])])
21:31:11,723 <kafka.protocol.parser>[DEBUG]: Received correlation id: 573
21:31:11,723 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:11,723 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 573 (2.0279884338378906 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=571, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:11,723 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=571, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:11,724 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 571 log start offset 0 and error None.
21:31:11,725 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:12,899 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PDB/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:12,901 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PDB,10200.0,100,0.0,0.0,0.0,0.0,False,0.0,14:14:47' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:12,902 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:12,902 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:12,902 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:12,902 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:12,902 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02 H\xe5\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x07\x06\x00\x00\x01\x94\x12\xd4\x07\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPDB,10200.0,100,0.0,0.0,0.0,0.0,F...')])])}
21:31:12,902 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02 H\xe5\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x07\x06\x00\x00\x01\x94\x12\xd4\x07\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPDB,10200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:31:12,903 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:12,903 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02 H\xe5\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x07\x06\x00\x00\x01\x94\x12\xd4\x07\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPDB,10200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:31:12,903 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 574: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00j\x00\x00\x00\x00\x02 H\xe5\xef\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x07\x06\x00\x00\x01\x94\x12\xd4\x07\x06\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01p\x00\x00\x00\x01dPDB,10200.0,100,0.0,0.0,0.0,0.0,F...')])])
21:31:12,905 <kafka.protocol.parser>[DEBUG]: Received correlation id: 574
21:31:12,906 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:12,906 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 574 (3.001689910888672 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=572, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:12,906 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=572, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:12,906 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 572 log start offset 0 and error None.
21:31:12,907 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:13,614 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PDC/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:13,616 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PDC,5100.0,1400,-200.0,0.0,0.0,0.0,False,0.0,14:54:32' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:13,617 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:13,617 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:13,618 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:13,618 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:13,618 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xdf\xa0\xdf\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\t\xd1\x00\x00\x01\x94\x12\xd4\t\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPDC,5100.0,1400,-200.0,0.0,0.0,0....')])])}
21:31:13,618 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xdf\xa0\xdf\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\t\xd1\x00\x00\x01\x94\x12\xd4\t\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPDC,5100.0,1400,-200.0,0.0,0.0,0....')])])
21:31:13,618 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xdf\xa0\xdf\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\t\xd1\x00\x00\x01\x94\x12\xd4\t\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPDC,5100.0,1400,-200.0,0.0,0.0,0....')])])
21:31:13,618 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:13,618 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 575: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00m\x00\x00\x00\x00\x02\xdf\xa0\xdf\xf0\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\t\xd1\x00\x00\x01\x94\x12\xd4\t\xd1\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01v\x00\x00\x00\x01jPDC,5100.0,1400,-200.0,0.0,0.0,0....')])])
21:31:13,620 <kafka.protocol.parser>[DEBUG]: Received correlation id: 575
21:31:13,621 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:13,621 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 575 (2.5167465209960938 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=573, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:13,621 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=573, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:13,621 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 573 log start offset 0 and error None.
21:31:13,623 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:13,982 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PDN/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:13,984 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PDN,104000.0,400,-1000.0,0.0,0.0,0.0,False,-1000.0,14:06:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:13,984 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:13,984 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:13,984 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:13,985 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:13,985 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02y\x0b\x84z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0b@\x00\x00\x01\x94\x12\xd4\x0b@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vPDN,104000.0,400,-1000.0,0.0,0.0...')])])}
21:31:13,985 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02y\x0b\x84z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0b@\x00\x00\x01\x94\x12\xd4\x0b@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vPDN,104000.0,400,-1000.0,0.0,0.0...')])])
21:31:13,985 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02y\x0b\x84z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0b@\x00\x00\x01\x94\x12\xd4\x0b@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vPDN,104000.0,400,-1000.0,0.0,0.0...')])])
21:31:13,985 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:13,985 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 576: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00t\x00\x00\x00\x00\x02y\x0b\x84z\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0b@\x00\x00\x01\x94\x12\xd4\x0b@\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01\x82\x01\x00\x00\x00\x01vPDN,104000.0,400,-1000.0,0.0,0.0...')])])
21:31:13,988 <kafka.protocol.parser>[DEBUG]: Received correlation id: 576
21:31:13,988 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:13,988 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 576 (1.9686222076416016 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=574, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:13,988 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=574, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:13,989 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 574 log start offset 0 and error None.
21:31:13,990 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:14,318 <urllib3.connectionpool>[DEBUG]: https://apipubaws.tcbs.com.vn:443 "GET /stock-insight/v1/intraday/PDR/his/paging?page=0&size=1&headIndex=-1 HTTP/1.1" 200 None
21:31:14,320 <kafka.producer.kafka>[DEBUG]: Sending (key=None value=b'PDR,20600.0,482800,-150.0,0.0,0.0,0.0,True,0.0,14:45:05' headers=[]) to TopicPartition(topic='realtimeStockData', partition=0)
21:31:14,320 <kafka.producer.record_accumulator>[DEBUG]: Allocating a new 16384 byte message buffer for TopicPartition(topic='realtimeStockData', partition=0)
21:31:14,320 <kafka.producer.kafka>[DEBUG]: Waking up the sender since TopicPartition(topic='realtimeStockData', partition=0) is either full or getting a new batch
21:31:14,321 <kafka.producer.kafka>[DEBUG]: Flushing accumulated records in producer.
21:31:14,321 <kafka.producer.sender>[DEBUG]: Nodes with data ready to send: {2}
21:31:14,321 <kafka.producer.sender>[DEBUG]: Created 1 produce requests: {2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc2\xd9\xb3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0c\x90\x00\x00\x01\x94\x12\xd4\x0c\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPDR,20600.0,482800,-150.0,0.0,0.0...')])])}
21:31:14,321 <kafka.producer.sender>[DEBUG]: Sending Produce Request: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc2\xd9\xb3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0c\x90\x00\x00\x01\x94\x12\xd4\x0c\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPDR,20600.0,482800,-150.0,0.0,0.0...')])])
21:31:14,321 <kafka.protocol.parser>[DEBUG]: Sending request ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc2\xd9\xb3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0c\x90\x00\x00\x01\x94\x12\xd4\x0c\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPDR,20600.0,482800,-150.0,0.0,0.0...')])])
21:31:14,321 <kafka.producer.record_accumulator>[DEBUG]: Waiting on produce to TopicPartition(topic='realtimeStockData', partition=0)
21:31:14,321 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 577: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=30000, topics=[(topic='realtimeStockData', partitions=[(partition=0, messages=b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00o\x00\x00\x00\x00\x02\xc2\xd9\xb3\xb4\x00\x00\x00\x00\x00\x00\x00\x00\x01\x94\x12\xd4\x0c\x90\x00\x00\x01\x94\x12\xd4\x0c\x90\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\xff\x00\x00\x00\x01z\x00\x00\x00\x01nPDR,20600.0,482800,-150.0,0.0,0.0...')])])
21:31:14,324 <kafka.protocol.parser>[DEBUG]: Received correlation id: 577
21:31:14,324 <kafka.protocol.parser>[DEBUG]: Processing response ProduceResponse_v7
21:31:14,324 <kafka.conn>[DEBUG]: <BrokerConnection node_id=2 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 577 (1.9581317901611328 ms): ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=575, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:14,325 <kafka.producer.sender>[DEBUG]: Parsing produce response: ProduceResponse_v7(topics=[(topic='realtimeStockData', partitions=[(partition=0, error_code=0, offset=575, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)
21:31:14,325 <kafka.producer.record_accumulator>[DEBUG]: Produced messages to topic-partition TopicPartition(topic='realtimeStockData', partition=0) with base offset 575 log start offset 0 and error None.
21:31:14,326 <urllib3.connectionpool>[DEBUG]: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
21:31:16,475 <kafka.producer.kafka>[INFO]: Closing the Kafka producer with 0 secs timeout.
21:31:16,475 <kafka.producer.kafka>[INFO]: Proceeding to force close the producer since pending requests could not be completed within timeout 0.
21:31:16,475 <kafka.producer.kafka>[DEBUG]: The Kafka producer has closed.
